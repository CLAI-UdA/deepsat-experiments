{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2587481-565c-4de6-b28d-4fb744f4039b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-26T15:59:27.939190Z",
     "iopub.status.busy": "2025-06-26T15:59:27.938029Z",
     "iopub.status.idle": "2025-06-26T15:59:34.160639Z",
     "shell.execute_reply": "2025-06-26T15:59:34.159747Z",
     "shell.execute_reply.started": "2025-06-26T15:59:27.939133Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "from typing import Dict, Tuple, List, Set, Union, Type, Literal\n",
    "from itertools import product\n",
    "from dataclasses import dataclass\n",
    "from collections import Counter\n",
    "import re\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics import Accuracy\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchinfo import summary\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Importing Formula Class ---\n",
    "# Go two levels up: from ICTCS_notebooks → theorem_prover_core → project root\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"..\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from logic_utils import Normalizer, Metavariable, Normalizer, CustomTokenizer, assign_embedding_indices, print_tree_with_embeddings\n",
    "from data_setup import (generate_normalized_dataset, add_new_tautologies_to_dataset, parse_dimacs_files, prepare_formula_dataset, \n",
    "                        FormulaDataset, FormulaTreeNode, prepare_balanced_tree_dataloaders, prepare_tree_dataloaders, TreeFormulaDataset,\n",
    "                        tree_collate_fn)\n",
    "from train_utils import (set_seeds, compute_vocab_size, train, save_results, save_model, train_tree, eval_model, analyze_model_errors,\n",
    "                         evaluate_confusion_matrix, count_parameters)\n",
    "from models import AsymmetricFocalLoss, TreeLSTMClassifierV1, TreeLSTMClassifierV2\n",
    "\n",
    "from theorem_prover_core.formula import (Formula, Letter, Falsity, Conjunction, Disjunction, Implication,\n",
    "                                         Negation, BinaryConnectiveFormula, UnaryConnectiveFormula, bottom)\n",
    "from theorem_prover_core.sequent import Sequent \n",
    "from theorem_prover_core.proofgraph import ProofGraph\n",
    "from theorem_prover_core.mcts import MCTS\n",
    "from models import TreeLSTMClassifierV1\n",
    "from logic_utils import FormulaTreeNode, CustomTokenizer, assign_embedding_indices, parse_formula_string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310e263c-28bf-4715-b6b5-b7532a076cc9",
   "metadata": {},
   "source": [
    "---\n",
    "#### **Some Tests on Specific Sequents for MCTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d453f3a6-10e5-41c1-9fba-7ef728c9aa35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T12:45:46.578275Z",
     "iopub.status.busy": "2025-06-19T12:45:46.576705Z",
     "iopub.status.idle": "2025-06-19T12:45:46.587647Z",
     "shell.execute_reply": "2025-06-19T12:45:46.585913Z",
     "shell.execute_reply.started": "2025-06-19T12:45:46.578234Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed: the sequent axiom was recognized correctly.\n"
     ]
    }
   ],
   "source": [
    "# --- MCTS Test - Trivial Sequent ---\n",
    "\n",
    "# Axiom sequent: A |- A\n",
    "A = Letter(0)\n",
    "axiom_sequent = Sequent(premises=(A,), conclusion=A)\n",
    "\n",
    "# Dummy policy (it's non needed a real poliy for an axiom)\n",
    "def dummy_policy(sequent):\n",
    "    return [], 1.0  # No moves, maximum value\n",
    "\n",
    "# Build proof graph and MCTS\n",
    "pg = ProofGraph(axiom_sequent)\n",
    "mcts = MCTS(policy_value_fn=dummy_policy, proof_graph=pg, n_playout=10)\n",
    "\n",
    "# Set MCTS root\n",
    "mcts.set_root(axiom_sequent)\n",
    "\n",
    "# Check if MCTS recognises the squent as an axiom\n",
    "assert mcts._proof_complete, \"Root should be promptly marked as proven\"\n",
    "\n",
    "# Confirmation output\n",
    "print(\"Test passed: the sequent axiom was recognized correctly.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c617c5c3-b17c-43ae-9940-79732f65e4bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T12:45:46.590156Z",
     "iopub.status.busy": "2025-06-19T12:45:46.589602Z",
     "iopub.status.idle": "2025-06-19T12:45:46.601808Z",
     "shell.execute_reply": "2025-06-19T12:45:46.600267Z",
     "shell.execute_reply.started": "2025-06-19T12:45:46.590120Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root sequent: A1 ∨ ⊥ ⊢ A1\n",
      "Root num_moves: 0\n",
      "Child sequents and costs:\n",
      "   A1 ⊢ A1 , cost: 0\n",
      "   ⊥ ⊢ A1 , cost: 0\n"
     ]
    }
   ],
   "source": [
    "# --- Test OR in Premises - Provable sequent ---\n",
    "\n",
    "# --- Propositional Letter ---\n",
    "A = Letter(1)\n",
    "\n",
    "# --- Define the formula and target sequent ---\n",
    "# Create the formula A |/ bottom\n",
    "# Define the goal sequent: A \\/ bottom |- A\n",
    "disj = Disjunction(A, bottom)\n",
    "goal = Sequent(premises=(disj,), conclusion=A)\n",
    "\n",
    "# --- Construct the proof graph ---\n",
    "pg = ProofGraph(goal)\n",
    "root = pg.root\n",
    "\n",
    "# --- Apply a rule: specifically OR-left to the only premise ---\n",
    "# We look for the move whose position (pos) is 0, i.e., targeting the first premise\n",
    "# Apply the rule to generate child sequents\n",
    "# Add the children to the proof graph under the current root\n",
    "move = next(m for m in root.sequent.moves() if m.pos == 0)\n",
    "children = root.sequent.rule(move)\n",
    "child_nodes = pg.add_children(root, move, children)\n",
    "\n",
    "# --- Check each generated child sequent: ----\n",
    "for node in child_nodes:\n",
    "    if node.sequent.is_axiom():\n",
    "        pg.set_proved(node)\n",
    "\n",
    "# --- Print results for inspection ---\n",
    "print(\"Root sequent:\", root.sequent)\n",
    "print(\"Root num_moves:\", root.num_moves.n)\n",
    "print(\"Child sequents and costs:\")\n",
    "for c in child_nodes:\n",
    "    print(\"  \", c.sequent, \", cost:\", c.num_moves.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa6a4fb3-0366-4af9-bda6-35d720ee62d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T12:45:46.604794Z",
     "iopub.status.busy": "2025-06-19T12:45:46.603692Z",
     "iopub.status.idle": "2025-06-19T12:45:46.616556Z",
     "shell.execute_reply": "2025-06-19T12:45:46.615059Z",
     "shell.execute_reply.started": "2025-06-19T12:45:46.604753Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root sequent: A1 ∧ A2 ⊢ A1\n",
      "Root num_moves: 0\n",
      "Child sequents and costs:\n",
      "   A1, A2 ⊢ A1 , cost: 0\n"
     ]
    }
   ],
   "source": [
    "# --- Test AND in Premises - Provable Sequent ---\n",
    "\n",
    "# --- Propositional Letters ---\n",
    "A = Letter(1)\n",
    "B = Letter(2)\n",
    "\n",
    "# --- Define the formula and target sequent ---\n",
    "# We want to prove: A /\\ B |- A\n",
    "# That is, from the conjunction A /\\ B, derive A\n",
    "conj = Conjunction(A, B)\n",
    "sequent = Sequent(premises=(), conclusion=conj)\n",
    "target = Sequent(premises=(conj,), conclusion=A)\n",
    "\n",
    "# --- Construct the proof graph ---\n",
    "pg = ProofGraph(target)\n",
    "root = pg.root\n",
    "\n",
    "# --- Apply a rule: specifically AND-left ---\n",
    "# Get all possible inference moves for the root sequent\n",
    "# Select the move that applies to the conjunctive formula A /\\ B\n",
    "# Apply the rule to generate child sequents (premises of the inference)\n",
    "moves = root.sequent.moves()\n",
    "move = next(m for m in moves if root.sequent.premises[m.pos] == conj)\n",
    "children = root.sequent.rule(move)\n",
    "\n",
    "# Add the resulting child sequents as children of the root in the proof graph\n",
    "child_nodes = pg.add_children(root, move, children)\n",
    "\n",
    "# --- Mark as proved if any child is an axiom ---\n",
    "# A node is considered proved if it matches the axiom schema \n",
    "for node in child_nodes:\n",
    "    if node.sequent.is_axiom():\n",
    "        pg.set_proved(node)\n",
    "\n",
    "# --- Print results for inspection ---\n",
    "print(\"Root sequent:\", root.sequent)\n",
    "print(\"Root num_moves:\", root.num_moves.n)\n",
    "print(\"Child sequents and costs:\")\n",
    "for c in child_nodes:\n",
    "    print(\"  \", c.sequent, \", cost:\", c.num_moves.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1fdc67",
   "metadata": {},
   "source": [
    "---\n",
    "#### **Load Test Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83e9dec1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-26T15:59:43.072574Z",
     "iopub.status.busy": "2025-06-26T15:59:43.071072Z",
     "iopub.status.idle": "2025-06-26T15:59:44.917216Z",
     "shell.execute_reply": "2025-06-26T15:59:44.916187Z",
     "shell.execute_reply.started": "2025-06-26T15:59:43.072535Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Hyperparameters ---\n",
    "DATA_PATH = \"datasets/extended_dataset_with_tautologies.csv\"\n",
    "BATCH_SIZE = 1\n",
    "TEST_SIZE = 0.2\n",
    "SEED = 42\n",
    "\n",
    "# --- Load Synthetic Dataset and Tokenizer ---\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# --- Split data for the test ---\n",
    "_, test_loader, tokenizer = prepare_tree_dataloaders(df, test_size=TEST_SIZE, batch_size=BATCH_SIZE, seed=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a136f61-9391-42f8-8284-3080e73b0adc",
   "metadata": {},
   "source": [
    "----\n",
    "#### **Uniform Policy Tests**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92285d29-2967-49d3-9748-2a44a2ac9561",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-26T15:59:56.448962Z",
     "iopub.status.busy": "2025-06-26T15:59:56.448177Z",
     "iopub.status.idle": "2025-06-26T15:59:57.056427Z",
     "shell.execute_reply": "2025-06-26T15:59:57.055149Z",
     "shell.execute_reply.started": "2025-06-26T15:59:56.448918Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tautologies in test_loader: 680 over 2600 total\n"
     ]
    }
   ],
   "source": [
    "def count_tautologies_in_loader(loader):\n",
    "    total = 0\n",
    "    tautologies = 0\n",
    "\n",
    "    for _, labels in loader:\n",
    "        for label in labels:\n",
    "            total += 1\n",
    "            if label.item() == 1:\n",
    "                tautologies += 1\n",
    "\n",
    "    return tautologies, total\n",
    "\n",
    "taut_count, total_count = count_tautologies_in_loader(test_loader)\n",
    "print(f\"Tautologies in test_loader: {taut_count} over {total_count} total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8763b486-7cb6-4add-b06c-5e5051124228",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-26T15:59:57.059433Z",
     "iopub.status.busy": "2025-06-26T15:59:57.058360Z",
     "iopub.status.idle": "2025-06-26T15:59:57.668284Z",
     "shell.execute_reply": "2025-06-26T15:59:57.667346Z",
     "shell.execute_reply.started": "2025-06-26T15:59:57.059380Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 680 tautologies in test set.\n"
     ]
    }
   ],
   "source": [
    "# --- Extract Tutologies from Test Set ---\n",
    "\n",
    "tautology_formulas = []\n",
    "tautology_labels = []\n",
    "\n",
    "for roots, labels in test_loader:\n",
    "    for root, label in zip(roots, labels):\n",
    "        if label.item() == 1:\n",
    "            tautology_formulas.append(root.formula)\n",
    "            tautology_labels.append(1.0)  # Etichetta float come richiesto\n",
    "\n",
    "print(f\"Found {len(tautology_formulas)} tautologies in test set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e53c7618-4288-4607-bf09-d73ea72cf4b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-26T15:59:57.670748Z",
     "iopub.status.busy": "2025-06-26T15:59:57.669838Z",
     "iopub.status.idle": "2025-06-26T15:59:57.675123Z",
     "shell.execute_reply": "2025-06-26T15:59:57.674257Z",
     "shell.execute_reply.started": "2025-06-26T15:59:57.670712Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Create TreeFormulaDataset ---\n",
    "tautology_dataset = TreeFormulaDataset(\n",
    "    formulas=tautology_formulas,\n",
    "    labels=tautology_labels,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7f860cc-5797-46b7-ae24-d5b3697d9ebb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-26T15:59:59.716541Z",
     "iopub.status.busy": "2025-06-26T15:59:59.715693Z",
     "iopub.status.idle": "2025-06-26T15:59:59.722103Z",
     "shell.execute_reply": "2025-06-26T15:59:59.721153Z",
     "shell.execute_reply.started": "2025-06-26T15:59:59.716456Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Create DataLoader ---\n",
    "tautology_loader = DataLoader(\n",
    "    tautology_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    collate_fn=tree_collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "45443408-563f-4ea0-bd58-ab3b8d6dc38c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T13:29:47.068719Z",
     "iopub.status.busy": "2025-06-20T13:29:47.067338Z",
     "iopub.status.idle": "2025-06-20T13:30:46.259192Z",
     "shell.execute_reply": "2025-06-20T13:30:46.257635Z",
     "shell.execute_reply.started": "2025-06-20T13:29:47.068677Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= Testing: n_playout=1, max_steps=1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74c6d5370f0945488a70d6476a6608b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/680 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0000\n",
      "\n",
      "========= Testing: n_playout=1, max_steps=3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea1b3321a30444a08b3af54bbafd9781",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/680 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0500\n",
      "\n",
      "========= Testing: n_playout=1, max_steps=4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d1561fb0a8841f1848daf420d80562c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/680 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0647\n",
      "\n",
      "========= Testing: n_playout=1, max_steps=5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c755c103112d4c74959e80d4f3877796",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/680 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0794\n",
      "\n",
      "========= Testing: n_playout=2, max_steps=1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54f5180e1e8342379ab7db6bb834c026",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/680 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0176\n",
      "\n",
      "========= Testing: n_playout=2, max_steps=3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "695b0a25ac1f41fdb20d8e9a9779cf83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/680 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.1632\n",
      "\n",
      "========= Testing: n_playout=2, max_steps=4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f245bbca0894b8daa1936625e39e9e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/680 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.1765\n",
      "\n",
      "========= Testing: n_playout=2, max_steps=5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2024428d6eb2491f8d038d92aa115430",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/680 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3735\n",
      "\n",
      "========= Testing: n_playout=3, max_steps=1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebe3ffc5d9374d598310662f402fc571",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/680 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0368\n",
      "\n",
      "========= Testing: n_playout=3, max_steps=3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6c9e2b5b59b443fbc6e6bbecdeefa61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/680 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.1662\n",
      "\n",
      "========= Testing: n_playout=3, max_steps=4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ce3c81c9e1b4a03ae1f70e6c0795c7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/680 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3309\n",
      "\n",
      "========= Testing: n_playout=3, max_steps=5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84878f70fb7b4954a2f12901333ce3e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/680 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4897\n",
      "\n",
      "========= Testing: n_playout=4, max_steps=1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a6b357457f74fe5b70d6162da8cddf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/680 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0574\n",
      "\n",
      "========= Testing: n_playout=4, max_steps=3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ec75ee1a6124698a50dd8597caa735d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/680 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.1794\n",
      "\n",
      "========= Testing: n_playout=4, max_steps=4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35c93123685b4c5ea7c5ded508a0cbf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/680 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2691\n",
      "\n",
      "========= Testing: n_playout=4, max_steps=5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d215af84bac142a59c2e8e7fdb1a2be2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/680 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4588\n",
      "\n",
      "========= Testing: n_playout=5, max_steps=1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32ba5a50810c47c1b2bafff4e06cf754",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/680 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.1426\n",
      "\n",
      "========= Testing: n_playout=5, max_steps=3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2674588550a341bf95d18b9113fab317",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/680 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2132\n",
      "\n",
      "========= Testing: n_playout=5, max_steps=4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcc2b18e0dc1470582c978ff2a7658a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/680 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3779\n",
      "\n",
      "========= Testing: n_playout=5, max_steps=5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92ef83e8c9fa4062af451096ad04e71a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/680 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5676\n",
      "\n",
      "========= Testing: n_playout=10, max_steps=1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6eec9c114c04e6ebee87dde66868967",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/680 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.1750\n",
      "\n",
      "========= Testing: n_playout=10, max_steps=3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d7a6b2cbc3245d9a71068f2b1452c7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/680 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3382\n",
      "\n",
      "========= Testing: n_playout=10, max_steps=4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d35bd85362148f6ba3b8a19344c346f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/680 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4750\n",
      "\n",
      "========= Testing: n_playout=10, max_steps=5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eefcf88031d47d783b02aa90a1f0aea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/680 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6324\n"
     ]
    }
   ],
   "source": [
    "# --- Parameters Sweep Uniform Policy ---\n",
    "\n",
    "# Sweep ranges\n",
    "n_playout_values = [1, 2, 3, 4, 5, 10]\n",
    "max_steps_values = [1, 3, 4, 5]\n",
    "\n",
    "policy = uniform_policy_value  \n",
    "\n",
    "uniform_results = []\n",
    "\n",
    "for n_playout in n_playout_values:\n",
    "    for max_steps in max_steps_values:\n",
    "        print(f\"\\n========= Testing: n_playout={n_playout}, max_steps={max_steps}\")\n",
    "\n",
    "        acc = evaluate_mcts(\n",
    "            test_loader=tautology_loader,\n",
    "            policy_value_fn=policy,\n",
    "            device=device,\n",
    "            n_playout=n_playout,\n",
    "            max_steps=max_steps,\n",
    "        )\n",
    "\n",
    "        print(f\"Accuracy: {acc:.4f}\")\n",
    "        uniform_results.append({\n",
    "            \"n_playout\": n_playout,\n",
    "            \"max_steps\": max_steps,\n",
    "            \"accuracy\": acc,\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "789c73d7-704a-4d62-b173-c85bb9d67cad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T13:37:12.053224Z",
     "iopub.status.busy": "2025-06-20T13:37:12.052791Z",
     "iopub.status.idle": "2025-06-20T13:37:12.065607Z",
     "shell.execute_reply": "2025-06-20T13:37:12.064499Z",
     "shell.execute_reply.started": "2025-06-20T13:37:12.053192Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Risults saved in datasets/uniform_policy_sweep_results.csv\n",
      "\n",
      "Best Results:\n",
      "    n_playout  max_steps  accuracy\n",
      "23         10          5  0.632353\n",
      "19          5          5  0.567647\n",
      "11          3          5  0.489706\n",
      "22         10          4  0.475000\n",
      "15          4          5  0.458824\n",
      "18          5          4  0.377941\n",
      "7           2          5  0.373529\n",
      "21         10          3  0.338235\n",
      "10          3          4  0.330882\n",
      "14          4          4  0.269118\n",
      "17          5          3  0.213235\n",
      "13          4          3  0.179412\n",
      "6           2          4  0.176471\n",
      "20         10          1  0.175000\n",
      "9           3          3  0.166176\n",
      "5           2          3  0.163235\n",
      "16          5          1  0.142647\n",
      "3           1          5  0.079412\n",
      "2           1          4  0.064706\n",
      "12          4          1  0.057353\n",
      "1           1          3  0.050000\n",
      "8           3          1  0.036765\n",
      "4           2          1  0.017647\n",
      "0           1          1  0.000000\n"
     ]
    }
   ],
   "source": [
    "# Save results to CSV\n",
    "datapath = \"datasets/uniform_policy_sweep_results.csv\"\n",
    "df_results = pd.DataFrame(uniform_results)\n",
    "df_results.to_csv(datapath, index=False)\n",
    "print(f\"\\nRisults saved in {datapath}\")\n",
    "\n",
    "# Print sorted by accuracy\n",
    "print(\"\\nBest Results:\")\n",
    "print(df_results.sort_values(by=\"accuracy\", ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83e0b4c",
   "metadata": {},
   "source": [
    "---\n",
    "#### **Load the Tree-LSTM Classifier to guide the MCTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47a76ee2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-26T16:00:05.910251Z",
     "iopub.status.busy": "2025-06-26T16:00:05.909770Z",
     "iopub.status.idle": "2025-06-26T16:00:06.065898Z",
     "shell.execute_reply": "2025-06-26T16:00:06.064340Z",
     "shell.execute_reply.started": "2025-06-26T16:00:05.910215Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77f50f18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-26T16:00:12.908930Z",
     "iopub.status.busy": "2025-06-26T16:00:12.908456Z",
     "iopub.status.idle": "2025-06-26T16:00:13.206584Z",
     "shell.execute_reply": "2025-06-26T16:00:13.205246Z",
     "shell.execute_reply.started": "2025-06-26T16:00:12.908895Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size (including padding token): 108\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TreeLSTMClassifierV1(\n",
       "  (encoder): TreeLSTMEncoder(\n",
       "    (embedding): Embedding(108, 32, padding_idx=0)\n",
       "    (cell): BinaryTreeLSTMCell(\n",
       "      (W_iou): Linear(in_features=32, out_features=384, bias=True)\n",
       "      (U_iou): Linear(in_features=256, out_features=384, bias=True)\n",
       "      (W_f): Linear(in_features=32, out_features=256, bias=True)\n",
       "      (U_f): Linear(in_features=256, out_features=256, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (fc1): Linear(in_features=128, out_features=32, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Load Tree-LSTM model without Dropout--- \n",
    "\n",
    "# Hyperparametrs \n",
    "VOCAB_SIZE = compute_vocab_size(tokenizer)\n",
    "print(f\"Vocabulary size (including padding token): {VOCAB_SIZE}\")\n",
    "\n",
    "EMBEDDING_DIM = 32\n",
    "HIDDEN_SIZE = 128\n",
    "FC_SIZE = 32\n",
    "\n",
    "# Seed for reproducibilty\n",
    "set_seeds()\n",
    "\n",
    "# Tree-LSTM Model\n",
    "model = TreeLSTMClassifierV1(vocab_size=VOCAB_SIZE,        \n",
    "                             embedding_dim=EMBEDDING_DIM,\n",
    "                             hidden_size=HIDDEN_SIZE,\n",
    "                             fc_size=FC_SIZE)\n",
    "\n",
    "# Load in the saved state_dict()\n",
    "model.load_state_dict(torch.load(f=\"models/New_Tree_lstm_without_dropout.pth\"))  \n",
    "\n",
    "# Send model to GPU\n",
    "model = model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "289f94b6-76e8-43a0-a865-d5a713441c91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-26T11:26:21.352024Z",
     "iopub.status.busy": "2025-06-26T11:26:21.350926Z",
     "iopub.status.idle": "2025-06-26T11:26:21.510883Z",
     "shell.execute_reply": "2025-06-26T11:26:21.509527Z",
     "shell.execute_reply.started": "2025-06-26T11:26:21.351987Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Estimate probability (tautology) = 0.7580 for the formula: ¬(A0 ∧ ¬A0)\n"
     ]
    }
   ],
   "source": [
    "# --- Formula Test with Tokenizer ---\n",
    "\n",
    "# Test Formula\n",
    "A = Letter(0)\n",
    "formula = ~(A & (~ A))\n",
    "\n",
    "# Build the Formula Tree and Assign Embedding Indices \n",
    "tree = FormulaTreeNode(formula)\n",
    "assign_embedding_indices(tree, tokenizer)\n",
    "\n",
    "# Model Prdiction\n",
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    logit = model(tree)\n",
    "    pred = torch.sigmoid(logit).item()\n",
    "\n",
    "print(f\"\\nEstimate probability (tautology) = {pred:.4f} for the formula: {formula}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fdf7424-aea9-443a-ae8d-f4f606ad007b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-26T16:00:24.747401Z",
     "iopub.status.busy": "2025-06-26T16:00:24.746929Z",
     "iopub.status.idle": "2025-06-26T16:00:24.773683Z",
     "shell.execute_reply": "2025-06-26T16:00:24.772356Z",
     "shell.execute_reply.started": "2025-06-26T16:00:24.747368Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Tree-LSTM Model Policy ---\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "def build_implication(premises, conclusion):\n",
    "    \"\"\"\n",
    "    Builds a single implication formula from a list of premises and a conclusion.\n",
    "\n",
    "    This function ensures the formula is in the form:\n",
    "        (A1 ∧ A2 ∧ ... ∧ An) → B\n",
    "\n",
    "    This format matches the structure expected by the Tree-LSTM model.\n",
    "\n",
    "    Args:\n",
    "        premises (list of Formula): A list of premise formulas.\n",
    "        conclusion (Formula): The conclusion formula.\n",
    "\n",
    "    Returns:\n",
    "        Formula: The implication formula combining premises and conclusion.\n",
    "    \"\"\"\n",
    "    if not premises:\n",
    "        return conclusion\n",
    "    elif len(premises) == 1:\n",
    "        return Implication(premises[0], conclusion)\n",
    "    else:\n",
    "        # Use reduce to combine all the premises into one big conjunction:\n",
    "        conj = reduce(lambda a, b: Conjunction(a, b), premises)\n",
    "        return Implication(conj, conclusion)\n",
    "\n",
    "\n",
    "def tree_model_policy_value(sequent: Sequent) -> Tuple[List[Tuple[Sequent.Move, float]], float]:\n",
    "    \"\"\"\n",
    "    Predicts the policy and value for a given sequent using a Tree-LSTM model.\n",
    "\n",
    "    The value is the estimated probability that the full sequent is a tautology.\n",
    "    The policy assigns a prior probability to each legal inference move,\n",
    "    based on the model’s prediction on the subgoal formulas after applying the move.\n",
    "\n",
    "    Args:\n",
    "        premises (list of Formula): A list of premise formulas.\n",
    "        conclusion (Formula): The conclusion formula.\n",
    "\n",
    "    Returns:\n",
    "        - List of (move, probability) tuples: prior over moves.\n",
    "        - Float: value estimate for the full sequent.\n",
    "    \"\"\"\n",
    "    # --- Value ---\n",
    "    full_formula = build_implication(sequent.premises, sequent.conclusion)\n",
    "    formula_tree = FormulaTreeNode(full_formula)\n",
    "    assign_embedding_indices(formula_tree, tokenizer)\n",
    "    with torch.inference_mode():\n",
    "        logit = model(formula_tree)\n",
    "        value = torch.sigmoid(logit).item()\n",
    "\n",
    "    # --- Policy ---\n",
    "    moves = sequent.moves()\n",
    "    move_scores = []\n",
    "\n",
    "    for move in moves:\n",
    "        try:\n",
    "            subgoals = sequent.rule(move)\n",
    "            if subgoals is None:\n",
    "                continue\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "        subgoal_probs = []\n",
    "        for sg in subgoals:\n",
    "            try:\n",
    "                sg_formula = build_implication(sg.premises, sg.conclusion)\n",
    "                sg_tree = FormulaTreeNode(sg_formula)\n",
    "                assign_embedding_indices(sg_tree, tokenizer)\n",
    "                with torch.inference_mode():\n",
    "                    sg_logit = model(sg_tree)\n",
    "                    sg_prob = torch.sigmoid(sg_logit).item()\n",
    "                    subgoal_probs.append(sg_prob)\n",
    "            except Exception as e:\n",
    "                print(f\"[WARN] Subgoal prediction failed for move {move}: {e}\")\n",
    "                continue  # Skip subgoal\n",
    "                \n",
    "        # --- Logic Aggregation (following aggrgate_by_connective) ---\n",
    "        if subgoal_probs:\n",
    "            f = (\n",
    "                sequent.conclusion if move.pos == -1\n",
    "                else sequent.premises[move.pos]\n",
    "            )\n",
    "\n",
    "            if isinstance(f, Conjunction):\n",
    "                score = min(subgoal_probs)\n",
    "            elif isinstance(f, Disjunction) and move.pos == -1:  \n",
    "                score = max(subgoal_probs)\n",
    "            elif isinstance(f, Disjunction) and move.pos >= 0:  \n",
    "                score = min(subgoal_probs)\n",
    "            elif isinstance(f, (Implication, Negation)):\n",
    "                score = subgoal_probs[0]  \n",
    "            else:\n",
    "                print(f\"[SKIP] Move {move} ignored — unsupported formula type: {type(f).__name__}\")\n",
    "                continue  # Skip the move\n",
    "                \n",
    "            move_scores.append((move, score))\n",
    "\n",
    "    # --- Normalization ---\n",
    "    if move_scores:\n",
    "        scores = torch.tensor([s for _, s in move_scores])\n",
    "        probs = torch.softmax(scores, dim=0).tolist()\n",
    "        move_priors = list(zip([m for m, _ in move_scores], probs))\n",
    "        \n",
    "        # DEBUG:\n",
    "        assert all(isinstance(mp, tuple) and len(mp) == 2 for mp in move_priors), \\\n",
    "        f\"[ERROR] Malformed move_priors: {move_priors}\"\n",
    "    else:\n",
    "        # There are no moves with valid score, no moves applicable\n",
    "        return [], value\n",
    "\n",
    "    return move_priors, value\n",
    "\n",
    "\n",
    "# --- Function to Evaluate MCTS Agent ---\n",
    "def evaluate_mcts(test_loader, policy_value_fn, device, n_playout, max_steps=100):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    for roots, labels in tqdm(test_loader):\n",
    "        for root, label in zip(roots, labels):\n",
    "            formula = root.formula\n",
    "            sequent = Sequent(premises=(), conclusion=formula)\n",
    "\n",
    "            # Initialize proofgraph and MCTS agent\n",
    "            pg = ProofGraph(sequent)\n",
    "            mcts = MCTS(\n",
    "                policy_value_fn=policy_value_fn,\n",
    "                proof_graph=pg,\n",
    "                n_playout=n_playout,\n",
    "                verbose=False\n",
    "            )\n",
    "\n",
    "            mcts.set_root(sequent)\n",
    "\n",
    "            steps = 0\n",
    "            while not mcts._proof_complete and steps < max_steps:\n",
    "                move_probs = mcts.get_move_probs(mcts._root.sequent)\n",
    "\n",
    "                if not move_probs or not all(isinstance(mp, tuple) and len(mp) == 2 for mp in move_probs):\n",
    "                    # print(f\"[STOP] No valid moves for sequent: {mcts._root.sequent}\")\n",
    "                    break\n",
    "\n",
    "                best_move = max(move_probs, key=lambda p: p[1])[0]\n",
    "                mcts.update_with_move(best_move)\n",
    "                steps += 1\n",
    "\n",
    "            #if steps >= max_steps:\n",
    "            #    print(f\"[WARN] Max steps exceeded for: {sequent}\")\n",
    "\n",
    "            prediction = 1 if mcts._proof_complete else 0\n",
    "            y_pred.append(prediction)\n",
    "            y_true.append(int(label.item()))\n",
    "\n",
    "    accuracy = sum(p == t for p, t in zip(y_pred, y_true)) / len(y_true)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc062a1",
   "metadata": {},
   "source": [
    "---\n",
    "#### **Tests for Model Policy and MCTS Agent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72004e50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-26T16:00:28.496152Z",
     "iopub.status.busy": "2025-06-26T16:00:28.495646Z",
     "iopub.status.idle": "2025-06-26T16:00:28.661967Z",
     "shell.execute_reply": "2025-06-26T16:00:28.660406Z",
     "shell.execute_reply.started": "2025-06-26T16:00:28.496117Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy: [(Sequent.Move(pos=-1, param='right'), 1.0)]\n",
      "Value: 0.7579830288887024\n"
     ]
    }
   ],
   "source": [
    "# --- Tree Model Policy Test ---\n",
    "\n",
    "A = Letter(0)\n",
    "form = ~(A & (~A))\n",
    "seq = Sequent(premises=(), conclusion=form)  # ⊢ A /\\ ~ A (taut)\n",
    "\n",
    "priors, value = tree_model_policy_value(seq)\n",
    "print(\"Policy:\", priors)\n",
    "print(\"Value:\", value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da9a0e39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-26T16:00:36.053183Z",
     "iopub.status.busy": "2025-06-26T16:00:36.051804Z",
     "iopub.status.idle": "2025-06-26T16:00:36.061163Z",
     "shell.execute_reply": "2025-06-26T16:00:36.059956Z",
     "shell.execute_reply.started": "2025-06-26T16:00:36.053139Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sequent to prove:  ⊢ A1 ∧ A2 → A1\n"
     ]
    }
   ],
   "source": [
    "# --- MCTS guided by Tree-LSTM model Test ---\n",
    "\n",
    "# Propositional letters\n",
    "A = Letter(1)\n",
    "B = Letter(2)\n",
    "\n",
    "# Tautology 1: A -> A\n",
    "f1 = A.implies(A)\n",
    "\n",
    "# Tautology 2: (A /\\ B) -> A\n",
    "f2 = (A & B).implies(A)\n",
    "\n",
    "# Non-Tautology: A -> (A /\\ B)\n",
    "f3 = A.implies(A & B)\n",
    "\n",
    "# --- Choosen formula ---\n",
    "chosen = f2  # change with: f1, f2, f3\n",
    "\n",
    "sequent = Sequent(premises=(), conclusion=chosen)\n",
    "print(f\"\\nSequent to prove: {sequent}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4773ec68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-26T16:00:38.126887Z",
     "iopub.status.busy": "2025-06-26T16:00:38.125375Z",
     "iopub.status.idle": "2025-06-26T16:00:38.164486Z",
     "shell.execute_reply": "2025-06-26T16:00:38.162736Z",
     "shell.execute_reply.started": "2025-06-26T16:00:38.126813Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MCTS start] root sequent ≡  ⊢ A1 ∧ A2 → A1\n",
      "[expand] Node:  ⊢ A1 ∧ A2 → A1, Moves: [(Sequent.Move(pos=-1, param='right'), 1.0)]\n",
      "[MCTS start] root sequent ≡  ⊢ A1 ∧ A2 → A1\n",
      "[expand] Node: A1 ∧ A2 ⊢ A1, Moves: [(Sequent.Move(pos=0, param='left'), 1.0)]\n",
      "[MCTS start] root sequent ≡  ⊢ A1 ∧ A2 → A1\n",
      "Complete proof found during MCTS simulation.\n"
     ]
    }
   ],
   "source": [
    "# --- Build the proof graph ---\n",
    "proof_graph = ProofGraph(sequent)\n",
    "\n",
    "# --- Initialize MCTS ---\n",
    "mcts = MCTS(\n",
    "    policy_value_fn=tree_model_policy_value,\n",
    "    proof_graph=proof_graph,\n",
    "    c_puct=5,                 \n",
    "    n_playout=1600,            \n",
    "    verbose=True               \n",
    ")\n",
    "mcts.set_root(sequent)\n",
    "\n",
    "# ---Run MCTS ---\n",
    "probs = mcts.get_move_probs(sequent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3fd5715f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-26T16:00:40.739745Z",
     "iopub.status.busy": "2025-06-26T16:00:40.738428Z",
     "iopub.status.idle": "2025-06-26T16:00:40.745370Z",
     "shell.execute_reply": "2025-06-26T16:00:40.744146Z",
     "shell.execute_reply.started": "2025-06-26T16:00:40.739704Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-  ⊢ A1 ∧ A2 → A1 [proved] (Q=0.19, N=3)\n",
      "  |_ Move: Sequent.Move(pos=-1, param='right')\n",
      "    - A1 ∧ A2 ⊢ A1 [proved] (Q=0.52, N=2)\n",
      "      |_ Move: Sequent.Move(pos=0, param='left')\n",
      "        - A1, A2 ⊢ A1 [proved] (Q=1.00, N=1)\n"
     ]
    }
   ],
   "source": [
    "# --- Print the Proof Tree --- \n",
    "mcts._root.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ecb6fd4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-26T16:00:43.055021Z",
     "iopub.status.busy": "2025-06-26T16:00:43.054499Z",
     "iopub.status.idle": "2025-06-26T16:00:43.080470Z",
     "shell.execute_reply": "2025-06-26T16:00:43.079411Z",
     "shell.execute_reply.started": "2025-06-26T16:00:43.054982Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MCTS start] root sequent ≡  ⊢ A0 ∧ A1 → A0\n",
      "[expand] Node:  ⊢ A0 ∧ A1 → A0, Moves: [(Sequent.Move(pos=-1, param='right'), 1.0)]\n",
      "[MCTS start] root sequent ≡  ⊢ A0 ∧ A1 → A0\n",
      "[expand] Node: A0 ∧ A1 ⊢ A0, Moves: [(Sequent.Move(pos=0, param='left'), 1.0)]\n",
      "[MCTS start] root sequent ≡  ⊢ A0 ∧ A1 → A0\n",
      "Complete proof found during MCTS simulation.\n",
      "\n",
      "Proved: True\n",
      "\n",
      "=== MCTS Tree ===\n",
      "-  ⊢ A0 ∧ A1 → A0 [proved] (Q=0.69, N=3)\n",
      "  |_ Move: Sequent.Move(pos=-1, param='right')\n",
      "    - A0 ∧ A1 ⊢ A0 [proved] (Q=0.82, N=2)\n",
      "      |_ Move: Sequent.Move(pos=0, param='left')\n",
      "        - A0, A1 ⊢ A0 [proved] (Q=1.00, N=1)\n"
     ]
    }
   ],
   "source": [
    "# --- 3 Playouts are enough to demonstrate the formula ---\n",
    "\n",
    "A = Letter(0)\n",
    "B = Letter(1)\n",
    "formula = (A & B).implies(A)\n",
    "sequent = Sequent(premises=(), conclusion=formula)\n",
    "\n",
    "pg = ProofGraph(sequent)\n",
    "\n",
    "mcts = MCTS(\n",
    "    policy_value_fn=tree_model_policy_value,  \n",
    "    proof_graph=pg,\n",
    "    n_playout=3,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "mcts.set_root(sequent)\n",
    "mcts.get_move_probs(sequent)\n",
    "proved = mcts._proof_complete\n",
    "# _, proved = mcts.playout(sequent)\n",
    "\n",
    "print(f\"\\nProved: {proved}\")\n",
    "print(\"\\n=== MCTS Tree ===\")\n",
    "mcts._root.print_tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e5067f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11602e8",
   "metadata": {},
   "source": [
    "#### **Evaluating MCTS Agent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05bef305-b9b3-4761-b7f8-0b8c742deead",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-21T21:26:25.483404Z",
     "iopub.status.busy": "2025-06-21T21:26:25.482827Z",
     "iopub.status.idle": "2025-06-21T21:55:16.549228Z",
     "shell.execute_reply": "2025-06-21T21:55:16.547757Z",
     "shell.execute_reply.started": "2025-06-21T21:26:25.483366Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f7a26a0485c41588f91bbabbedcb428",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Model Policy] MCTS Agent Accuracy with n_playout=10, max_step=5: 0.8912\n"
     ]
    }
   ],
   "source": [
    "acc_mcts_new_policy_1 = evaluate_mcts(\n",
    "    test_loader=test_loader,\n",
    "    policy_value_fn=tree_model_policy_value,\n",
    "    device=device,\n",
    "    n_playout=10,\n",
    "    max_steps=5\n",
    ")\n",
    "\n",
    "print(f\"[Model Policy] MCTS Agent Accuracy with n_playout=10, max_step=5: {acc_mcts_new_policy_1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ef9ae4f-58a7-42f5-9c79-8c20b459af4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-21T21:55:16.552040Z",
     "iopub.status.busy": "2025-06-21T21:55:16.551696Z",
     "iopub.status.idle": "2025-06-21T22:10:11.028616Z",
     "shell.execute_reply": "2025-06-21T22:10:11.027472Z",
     "shell.execute_reply.started": "2025-06-21T21:55:16.552010Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "969c4b2ec345440f80fdc0a02c57dd8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Model Policy] MCTS Agent Accuracy with n_playout=5, max_step=5: 0.9142\n"
     ]
    }
   ],
   "source": [
    "acc_mcts_new_policy_2 = evaluate_mcts(\n",
    "    test_loader=test_loader,\n",
    "    policy_value_fn=tree_model_policy_value,\n",
    "    device=device,\n",
    "    n_playout=5,\n",
    "    max_steps=5\n",
    ")\n",
    "\n",
    "print(f\"[Model Policy] MCTS Agent Accuracy with n_playout=5, max_step=5: {acc_mcts_new_policy_2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8827f125-2590-46a4-b8b3-b6b09865b3cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-21T22:10:11.030404Z",
     "iopub.status.busy": "2025-06-21T22:10:11.030086Z",
     "iopub.status.idle": "2025-06-21T22:21:56.244598Z",
     "shell.execute_reply": "2025-06-21T22:21:56.243261Z",
     "shell.execute_reply.started": "2025-06-21T22:10:11.030373Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be90bf83e7fb45eb81b2200eedc7292f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Model Policy] MCTS Agent Accuracy with n_playout=3, max_step=5: 0.8215\n"
     ]
    }
   ],
   "source": [
    "acc_mcts_new_policy_3 = evaluate_mcts(\n",
    "    test_loader=test_loader,\n",
    "    policy_value_fn=tree_model_policy_value,\n",
    "    device=device,\n",
    "    n_playout=3,\n",
    "    max_steps=5\n",
    ")\n",
    "\n",
    "print(f\"[Model Policy] MCTS Agent Accuracy with n_playout=3, max_step=5: {acc_mcts_new_policy_3:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b6e130f-b877-419d-8b7a-7a5e1826de79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-21T22:21:56.247542Z",
     "iopub.status.busy": "2025-06-21T22:21:56.246963Z",
     "iopub.status.idle": "2025-06-21T22:47:42.348644Z",
     "shell.execute_reply": "2025-06-21T22:47:42.347179Z",
     "shell.execute_reply.started": "2025-06-21T22:21:56.247510Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4d9f3d8b39d4a3aa7722956743c2fad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Model Policy] MCTS Agent Accuracy with n_playout=10, max_step=4: 0.8538\n"
     ]
    }
   ],
   "source": [
    "acc_mcts_new_policy_4 = evaluate_mcts(\n",
    "    test_loader=test_loader,\n",
    "    policy_value_fn=tree_model_policy_value,\n",
    "    device=device,\n",
    "    n_playout=10,\n",
    "    max_steps=4\n",
    ")\n",
    "\n",
    "print(f\"[Model Policy] MCTS Agent Accuracy with n_playout=10, max_step=4: {acc_mcts_new_policy_4:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
