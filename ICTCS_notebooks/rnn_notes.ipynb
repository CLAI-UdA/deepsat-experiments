{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bffeb050-9483-4ce4-a4b0-d8aedec34a29",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2025-05-31T12:43:07.483536Z",
     "iopub.status.busy": "2025-05-31T12:43:07.483217Z",
     "iopub.status.idle": "2025-05-31T12:43:07.511408Z",
     "shell.execute_reply": "2025-05-31T12:43:07.510051Z",
     "shell.execute_reply.started": "2025-05-31T12:43:07.483503Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import torch\n",
    "except:\n",
    "    print(\"[INFO] Couldn't find torch... installing it.\")\n",
    "    !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "    import torch\n",
    "\n",
    "try:\n",
    "    import torchmetrics\n",
    "except:\n",
    "    print(\"[INFO] Couldn't find torchmetrics... installing it.\")\n",
    "    !pip install torchmetrics\n",
    "    import torchmetrics\n",
    "\n",
    "try:\n",
    "    import torchinfo\n",
    "except:\n",
    "    print(\"[INFO] Couldn't find torchinfo... installing it.\")\n",
    "    !pip install torchinfo\n",
    "    import torchinfo\n",
    "\n",
    "try:\n",
    "    from torch.utils.tensorboard import SummaryWriter\n",
    "except:\n",
    "    print(\"[INFO] Couldn't find tensorboard... installing it.\")\n",
    "    !pip install -q tensorboard\n",
    "    from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "try: \n",
    "    import wandb\n",
    "except: \n",
    "    print(\"[INFO] Couldn't find tensorboard... installing it.\")\n",
    "    !pip install wandb\n",
    "\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "from typing import Dict, Tuple, List, Set, Union, Type, Literal\n",
    "from itertools import product\n",
    "from dataclasses import dataclass\n",
    "from collections import Counter\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics import Accuracy\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchinfo import summary\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d82ddf74-d292-45e4-8ee6-c0dd5d850f46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T12:43:07.470093Z",
     "iopub.status.busy": "2025-05-31T12:43:07.469276Z",
     "iopub.status.idle": "2025-05-31T12:43:07.481826Z",
     "shell.execute_reply": "2025-05-31T12:43:07.480619Z",
     "shell.execute_reply.started": "2025-05-31T12:43:07.470058Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Importing Formula Class ---\n",
    "# Go two levels up: from ICTCS_notebooks → theorem_prover_core → project root\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"..\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from theorem_prover_core.formula import (Formula, Letter, Falsity, Conjunction, Disjunction, Implication,\n",
    "                                         Negation, BinaryConnectiveFormula, UnaryConnectiveFormula, bottom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "572aca6b-2525-4f07-a292-c999134014f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T21:32:27.722162Z",
     "iopub.status.busy": "2025-06-02T21:32:27.721723Z",
     "iopub.status.idle": "2025-06-02T21:32:31.005686Z",
     "shell.execute_reply": "2025-06-02T21:32:31.004786Z",
     "shell.execute_reply.started": "2025-06-02T21:32:27.722129Z"
    }
   },
   "outputs": [],
   "source": [
    "from logic_utils import Normalizer, Metavariable, CustomTokenizer, FormulaTreeNode, assign_embedding_indices\n",
    "from data_setup import (generate_normalized_dataset, add_new_tautologies_to_dataset, parse_dimacs_files, \n",
    "                        prepare_formula_dataset, FormulaDataset, FormulaTreeNode)\n",
    "from train_utils import set_seeds, compute_vocab_size, train, save_results, save_model \n",
    "from models import AsymmetricFocalLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8917dd63-c6c8-4677-9b79-920134726a1b",
   "metadata": {},
   "source": [
    "---\n",
    "### **1 Generate Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c185d8bf-f669-40cc-9204-059d2350fc82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T18:07:36.926306Z",
     "iopub.status.busy": "2025-05-30T18:07:36.926000Z",
     "iopub.status.idle": "2025-05-30T18:07:39.747110Z",
     "shell.execute_reply": "2025-05-30T18:07:39.745662Z",
     "shell.execute_reply.started": "2025-05-30T18:07:36.926275Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saving Dataset to /home/labeconomia/nbalestra/theorem_prover/theorem_prover_core/ICTCS_notebooks/datasets/normalized_formulas_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# --- Generating normalized dataset ---\n",
    "SIZE = 10000\n",
    "MAX_DEPTH = 5\n",
    "NUM_LETTERS = 7\n",
    "SEED = 42\n",
    "\n",
    "random.seed(SEED)\n",
    "data_set = generate_normalized_dataset(num_formulas=SIZE, \n",
    "                                      max_depth=MAX_DEPTH,\n",
    "                                      num_letters=NUM_LETTERS)\n",
    "\n",
    "datapath = \"datasets/normalized_formulas_dataset.csv\"\n",
    "data_set.to_csv(datapath, index=False)\n",
    "print(f\"[INFO] Saving Dataset to {os.path.abspath(datapath)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2b058230-f2ab-41d5-92b5-a0cf5d4de982",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T18:07:39.750560Z",
     "iopub.status.busy": "2025-05-30T18:07:39.750184Z",
     "iopub.status.idle": "2025-05-30T18:07:39.762580Z",
     "shell.execute_reply": "2025-05-30T18:07:39.761340Z",
     "shell.execute_reply.started": "2025-05-30T18:07:39.750527Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>formula</th>\n",
       "      <th>is_tautology</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(A0 ∧ ¬(A1 ∧ A2 ∧ A3)) ∨ (A4 → A5)</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(¬(A0 → A1) → A2) ∨ A3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>⊥ ∨ A0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>¬A0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              formula  is_tautology\n",
       "0                                  A0         False\n",
       "1  (A0 ∧ ¬(A1 ∧ A2 ∧ A3)) ∨ (A4 → A5)         False\n",
       "2              (¬(A0 → A1) → A2) ∨ A3         False\n",
       "3                              ⊥ ∨ A0         False\n",
       "4                                 ¬A0         False"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4ecb51ba-8336-4d16-a2e7-8e2e2ce3edeb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T18:07:39.764883Z",
     "iopub.status.busy": "2025-05-30T18:07:39.764521Z",
     "iopub.status.idle": "2025-05-30T18:07:39.776310Z",
     "shell.execute_reply": "2025-05-30T18:07:39.775141Z",
     "shell.execute_reply.started": "2025-05-30T18:07:39.764851Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "formula         10000\n",
      "is_tautology    10000\n",
      "dtype: int64\n",
      "\n",
      "Number of True and False formulas: \n",
      "is_tautology\n",
      "False    9576\n",
      "True      424\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Percentage of tautologies in the dataset: 4.24%\n"
     ]
    }
   ],
   "source": [
    "print(data_set.count())\n",
    "count = data_set.is_tautology.value_counts()\n",
    "print(f\"\\nNumber of True and False formulas: \\n{count}\\n\")\n",
    "\n",
    "total = len(data_set)\n",
    "tautologies = data_set[\"is_tautology\"].sum()\n",
    "percentage = (tautologies / total) * 100\n",
    "print(f\"Percentage of tautologies in the dataset: {percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33a7ad1-ea24-464f-8bdd-e1ef12406961",
   "metadata": {},
   "source": [
    "#### **1.1 Data Augmentation With Common Tautologies Instantiation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "375a4a3e-96fe-4e6c-ac9e-6a52802e26e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T18:07:39.778086Z",
     "iopub.status.busy": "2025-05-30T18:07:39.777773Z",
     "iopub.status.idle": "2025-05-30T18:07:39.789307Z",
     "shell.execute_reply": "2025-05-30T18:07:39.788142Z",
     "shell.execute_reply.started": "2025-05-30T18:07:39.778055Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A ∨ ¬A\n",
      "¬(A ∧ ¬A)\n",
      "(¬(A ∧ B) → ¬A ∨ ¬B) ∧ (¬A ∨ ¬B → ¬(A ∧ B))\n",
      "(¬(A ∨ B) → ¬A ∧ ¬B) ∧ (¬A ∧ ¬B → ¬(A ∨ B))\n",
      "(A ∧ (B ∨ C) → (A ∧ B) ∨ (A ∧ C)) ∧ ((A ∧ B) ∨ (A ∧ C) → A ∧ (B ∨ C))\n",
      "(A ∨ (B ∧ C) → (A ∨ B) ∧ (A ∨ C)) ∧ ((A ∨ B) ∧ (A ∨ C) → A ∨ (B ∧ C))\n"
     ]
    }
   ],
   "source": [
    "# --- Creating Common Tautologies --- \n",
    "A = Metavariable(\"A\")\n",
    "B = Metavariable(\"B\")\n",
    "C = Metavariable(\"C\")\n",
    "\n",
    "# List of common tautologies\n",
    "tautologies = [\n",
    "\n",
    "    Disjunction(A, Negation(A)),\n",
    "\n",
    "    Negation(Conjunction(A, Negation(A))),\n",
    "\n",
    "    Conjunction(\n",
    "        Implication(Negation(Conjunction(A, B)), Disjunction(Negation(A), Negation(B))),\n",
    "        Implication(Disjunction(Negation(A), Negation(B)), Negation(Conjunction(A, B)))\n",
    "    ),\n",
    "\n",
    "    Conjunction(\n",
    "        Implication(Negation(Disjunction(A, B)), Conjunction(Negation(A), Negation(B))),\n",
    "        Implication(Conjunction(Negation(A), Negation(B)), Negation(Disjunction(A, B)))\n",
    "    ),\n",
    "\n",
    "    Conjunction(\n",
    "        Implication(Conjunction(A, Disjunction(B, C)), Disjunction(Conjunction(A, B), Conjunction(A, C))),\n",
    "        Implication(Disjunction(Conjunction(A, B), Conjunction(A, C)), Conjunction(A, Disjunction(B, C)))\n",
    "    ),\n",
    "\n",
    "    Conjunction(\n",
    "        Implication(Disjunction(A, Conjunction(B, C)), Conjunction(Disjunction(A, B), Disjunction(A, C))),\n",
    "        Implication(Conjunction(Disjunction(A, B), Disjunction(A, C)), Disjunction(A, Conjunction(B, C)))\n",
    "    )\n",
    "]\n",
    "\n",
    "for tautology in tautologies:\n",
    "    print(tautology)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3b9fc4eb-f57e-4897-a2c0-03524ce68527",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T18:07:39.790979Z",
     "iopub.status.busy": "2025-05-30T18:07:39.790679Z",
     "iopub.status.idle": "2025-05-30T18:08:19.596359Z",
     "shell.execute_reply": "2025-05-30T18:08:19.594895Z",
     "shell.execute_reply.started": "2025-05-30T18:07:39.790949Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saving Dataset to /home/labeconomia/nbalestra/theorem_prover/theorem_prover_core/ICTCS_notebooks/datasets/extended_dataset_with_tautologies.csv\n"
     ]
    }
   ],
   "source": [
    "# --- Adding 3,000 (30% of dataaset) new tatologies to the dataset ---\n",
    "num_samples = 3000\n",
    "seed_value = 42\n",
    "\n",
    "dataset = add_new_tautologies_to_dataset(dataset=data_set,\n",
    "                                         tautologies=tautologies,\n",
    "                                         num_samples=num_samples,\n",
    "                                         max_depth=MAX_DEPTH,\n",
    "                                         num_letters=NUM_LETTERS,\n",
    "                                         seed=seed_value)\n",
    "\n",
    "datapath = \"datasets/extended_dataset_with_tautologies.csv\"\n",
    "dataset.to_csv(datapath, index=False)\n",
    "print(f\"[INFO] Saving Dataset to {os.path.abspath(datapath)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "929b55a6-70fc-4e2f-950d-76d5c87a3143",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T18:08:19.599118Z",
     "iopub.status.busy": "2025-05-30T18:08:19.598078Z",
     "iopub.status.idle": "2025-05-30T18:08:19.612234Z",
     "shell.execute_reply": "2025-05-30T18:08:19.610967Z",
     "shell.execute_reply.started": "2025-05-30T18:08:19.599076Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "formula         13000\n",
      "is_tautology    13000\n",
      "dtype: int64\n",
      "\n",
      "Number of True and False formulas: \n",
      "is_tautology\n",
      "False    9576\n",
      "True     3424\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Percentage of tautologies in the dataset: 26.34%\n"
     ]
    }
   ],
   "source": [
    "# --- Get Dataset Info ---\n",
    "print(dataset.count())\n",
    "count = dataset.is_tautology.value_counts()\n",
    "print(f\"\\nNumber of True and False formulas: \\n{count}\\n\")\n",
    "\n",
    "total = len(dataset)\n",
    "tautologies = dataset[\"is_tautology\"].sum()\n",
    "percentage = (tautologies / total) * 100\n",
    "print(f\"Percentage of tautologies in the dataset: {percentage:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0567b3c7-b737-467a-9361-924a786aadf7",
   "metadata": {},
   "source": [
    "#### **1.2 Data Augmentation With Common Tautologies Instantiation and DIMACS format formulas**\n",
    "\n",
    "Extending Dataset with [SATLIB - Benchmark Problems](https://www.cs.ubc.ca/~hoos/SATLIB/benchm.html), using propositional formulas in Dimacs format.\n",
    "\n",
    "Formulas Downloaded from SATLIB: \n",
    "- uf20-91: 20 variables, 91 clauses - 1000 instances, all satisfiable\n",
    "- uf50-218 / uuf50-218: 50 variables, 218 clauses - 1000 instances, all sat/unsat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "13240f0e-3545-436e-ab2f-c05f318e908a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T18:08:19.614046Z",
     "iopub.status.busy": "2025-05-30T18:08:19.613734Z",
     "iopub.status.idle": "2025-05-30T18:08:29.549049Z",
     "shell.execute_reply": "2025-05-30T18:08:29.547649Z",
     "shell.execute_reply.started": "2025-05-30T18:08:19.614014Z"
    }
   },
   "outputs": [],
   "source": [
    "base_dir = \"dimacs_formulas_datasets/\"\n",
    "dataset_satlib = parse_dimacs_files(base_dir=base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f1508d2e-7106-40bf-8b0b-dd1d2bc1f438",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T18:08:29.551510Z",
     "iopub.status.busy": "2025-05-30T18:08:29.551146Z",
     "iopub.status.idle": "2025-05-30T18:08:29.561749Z",
     "shell.execute_reply": "2025-05-30T18:08:29.560520Z",
     "shell.execute_reply.started": "2025-05-30T18:08:29.551475Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_tautology\n",
       "True     2000\n",
       "False    1000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_satlib.is_tautology.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0e46f369-a6f8-416e-8b87-50b1a158c9f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T18:08:29.563330Z",
     "iopub.status.busy": "2025-05-30T18:08:29.563027Z",
     "iopub.status.idle": "2025-05-30T18:08:38.905517Z",
     "shell.execute_reply": "2025-05-30T18:08:38.904047Z",
     "shell.execute_reply.started": "2025-05-30T18:08:29.563298Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Normalizing new formulas ---\n",
    "dataset_satlib['formula'] = dataset_satlib['formula'].apply(lambda f: str(Normalizer().normalize(f)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0f74742e-2349-4dcc-a861-47aa165394e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T18:08:38.907772Z",
     "iopub.status.busy": "2025-05-30T18:08:38.907404Z",
     "iopub.status.idle": "2025-05-30T18:08:38.919802Z",
     "shell.execute_reply": "2025-05-30T18:08:38.918197Z",
     "shell.execute_reply.started": "2025-05-30T18:08:38.907739Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Concateating datasets and shuffling ---\n",
    "dataset_composed = pd.concat([dataset, dataset_satlib], ignore_index=True)\n",
    "dataset_composed = dataset_composed.sample(frac=1, random_state=42).reset_index(drop=True) # frac=1 means shuffle all rows\n",
    "                                                                                           # reset_index(drop=True) removes the old index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b56f38d1-c68c-4d1d-a516-14c2cade9803",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T18:08:38.924999Z",
     "iopub.status.busy": "2025-05-30T18:08:38.924630Z",
     "iopub.status.idle": "2025-05-30T18:08:39.293041Z",
     "shell.execute_reply": "2025-05-30T18:08:39.291833Z",
     "shell.execute_reply.started": "2025-05-30T18:08:38.924965Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saving Dataset to /home/labeconomia/nbalestra/theorem_prover/theorem_prover_core/ICTCS_notebooks/datasets/extended_dataset_with_dimacs_formulas.csv\n"
     ]
    }
   ],
   "source": [
    "# --- Adding a column 'source' to combined dataset to distinguish between synthetic formulas and dimacs formulas ---\n",
    "dataset['source'] = 'synthetic'\n",
    "dataset_satlib['source'] = 'satlib'\n",
    "\n",
    "# --- Concateating datasets and shuffling ---\n",
    "dataset_composed = pd.concat([dataset, dataset_satlib], ignore_index=True)\n",
    "dataset_composed = dataset_composed.sample(frac=1, random_state=42).reset_index(drop=True) # frac=1 means shuffle all rows\n",
    "                                                                                           # reset_index(drop=True) removes the old index\n",
    "# --- Adding indices to dataset---\n",
    "dataset_composed['index'] = dataset_composed.index\n",
    "\n",
    "datapath = \"datasets/extended_dataset_with_dimacs_formulas.csv\"\n",
    "dataset_composed.to_csv(datapath, index=False)\n",
    "print(f\"[INFO] Saving Dataset to {os.path.abspath(datapath)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "55cc4394-1bc7-4a1a-b844-423707be5d82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T18:08:39.294637Z",
     "iopub.status.busy": "2025-05-30T18:08:39.294293Z",
     "iopub.status.idle": "2025-05-30T18:08:39.308206Z",
     "shell.execute_reply": "2025-05-30T18:08:39.306971Z",
     "shell.execute_reply.started": "2025-05-30T18:08:39.294588Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>formula</th>\n",
       "      <th>is_tautology</th>\n",
       "      <th>source</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>((A0 ∧ A1) ∨ ((A0 ∨ ⊥) ∧ ((A0 ∧ A1) ∨ (((A2 ∧ ...</td>\n",
       "      <td>True</td>\n",
       "      <td>synthetic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(¬((A0 → A1 ∨ A2 ∨ A3) ∨ A0) → ¬(A0 → A1 ∨ A2 ...</td>\n",
       "      <td>True</td>\n",
       "      <td>synthetic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>¬A0 ∧ ((⊥ ∧ A1) ∨ (¬A2 ∧ A3)) ∧ A4</td>\n",
       "      <td>False</td>\n",
       "      <td>synthetic</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(A0 ∨ (A1 ∧ ¬A2 ∧ A3)) ∧ (A4 ∨ A5 ∨ ¬(A6 ∧ A7 ...</td>\n",
       "      <td>False</td>\n",
       "      <td>synthetic</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0 ∨ (¬(A1 ∨ A2) → ¬(A3 ∨ A4))</td>\n",
       "      <td>False</td>\n",
       "      <td>synthetic</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             formula  is_tautology     source  \\\n",
       "0  ((A0 ∧ A1) ∨ ((A0 ∨ ⊥) ∧ ((A0 ∧ A1) ∨ (((A2 ∧ ...          True  synthetic   \n",
       "1  (¬((A0 → A1 ∨ A2 ∨ A3) ∨ A0) → ¬(A0 → A1 ∨ A2 ...          True  synthetic   \n",
       "2                 ¬A0 ∧ ((⊥ ∧ A1) ∨ (¬A2 ∧ A3)) ∧ A4         False  synthetic   \n",
       "3  (A0 ∨ (A1 ∧ ¬A2 ∧ A3)) ∧ (A4 ∨ A5 ∨ ¬(A6 ∧ A7 ...         False  synthetic   \n",
       "4                     A0 ∨ (¬(A1 ∨ A2) → ¬(A3 ∨ A4))         False  synthetic   \n",
       "\n",
       "   index  \n",
       "0      0  \n",
       "1      1  \n",
       "2      2  \n",
       "3      3  \n",
       "4      4  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_composed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fa88d4bc-992b-4deb-aff3-bc1f09ab8a2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T18:08:39.309906Z",
     "iopub.status.busy": "2025-05-30T18:08:39.309594Z",
     "iopub.status.idle": "2025-05-30T18:08:39.325102Z",
     "shell.execute_reply": "2025-05-30T18:08:39.323662Z",
     "shell.execute_reply.started": "2025-05-30T18:08:39.309875Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "formula         16000\n",
      "is_tautology    16000\n",
      "source          16000\n",
      "index           16000\n",
      "dtype: int64\n",
      "\n",
      "Number of True and False formulas: \n",
      "is_tautology\n",
      "False    10576\n",
      "True      5424\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Percentage of tautologies in the composed dataset: 41.72%\n"
     ]
    }
   ],
   "source": [
    "# --- Get Dataset Info ---\n",
    "print(dataset_composed.count())\n",
    "count = dataset_composed.is_tautology.value_counts()\n",
    "print(f\"\\nNumber of True and False formulas: \\n{count}\\n\")\n",
    "\n",
    "total = len(dataset)\n",
    "tautologies = dataset_composed[\"is_tautology\"].sum()\n",
    "percentage = (tautologies / total) * 100\n",
    "print(f\"Percentage of tautologies in the composed dataset: {percentage:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b269ccaf-3089-42d9-88d7-0aaa634d9ae9",
   "metadata": {},
   "source": [
    "---\n",
    "### **2 Preparing the Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b5333ec2-d9da-4b16-b10c-bf17a39987cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T18:08:39.327007Z",
     "iopub.status.busy": "2025-05-30T18:08:39.326708Z",
     "iopub.status.idle": "2025-05-30T18:08:43.523802Z",
     "shell.execute_reply": "2025-05-30T18:08:43.522358Z",
     "shell.execute_reply.started": "2025-05-30T18:08:39.326975Z"
    }
   },
   "outputs": [],
   "source": [
    "TEST_SIZE = 0.2\n",
    "BATCH_SIZE = 16\n",
    "SEED = 42\n",
    "\n",
    "(train_dataloader, test_dataloader, \n",
    " X_train, X_test, \n",
    " y_train, y_test, idx_test)  = prepare_formula_dataset(dataset = dataset,\n",
    "                                                                 test_size=TEST_SIZE,\n",
    "                                                                 batch_size=BATCH_SIZE,\n",
    "                                                                 seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ecb96d76-e7df-4219-99e7-da5d499e86a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T18:08:43.525757Z",
     "iopub.status.busy": "2025-05-30T18:08:43.525421Z",
     "iopub.status.idle": "2025-05-30T18:08:43.534372Z",
     "shell.execute_reply": "2025-05-30T18:08:43.533154Z",
     "shell.execute_reply.started": "2025-05-30T18:08:43.525724Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 10400 samples\n",
      "Test set: 2600 samples\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training set: {len(X_train)} samples\")\n",
    "print(f\"Test set: {len(X_test)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "606f7cd8-2e0a-4a6f-8036-d81ec9597929",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T18:08:43.536325Z",
     "iopub.status.busy": "2025-05-30T18:08:43.535990Z",
     "iopub.status.idle": "2025-05-30T18:08:43.914829Z",
     "shell.execute_reply": "2025-05-30T18:08:43.913373Z",
     "shell.execute_reply.started": "2025-05-30T18:08:43.536294Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique letters: 8\n",
      "Number of unique connectives: 4\n",
      "Number of spacial tokens: 2\n"
     ]
    }
   ],
   "source": [
    "tokenizer = CustomTokenizer()\n",
    "tokenizer.fit(X_train)\n",
    "\n",
    "num_letters = sum(1 for formula in tokenizer.formula_to_token if isinstance(formula, Letter))\n",
    "num_connectives = len(tokenizer.connective_map)\n",
    "num_parenthesis = sum(1 for formula in tokenizer.special_map)\n",
    "\n",
    "print(f\"Number of unique letters: {num_letters}\")\n",
    "print(f\"Number of unique connectives: {num_connectives}\")\n",
    "print(f\"Number of spacial tokens: {num_parenthesis}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3ea70dcd-287e-473c-8c96-209779aa85a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T18:08:43.916650Z",
     "iopub.status.busy": "2025-05-30T18:08:43.916310Z",
     "iopub.status.idle": "2025-05-30T18:08:43.925231Z",
     "shell.execute_reply": "2025-05-30T18:08:43.924033Z",
     "shell.execute_reply.started": "2025-05-30T18:08:43.916596Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train class counts: Counter({False: 7662, True: 2738})\n",
      "Test class counts: Counter({False: 1914, True: 686})\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "train_class_counts = collections.Counter(y_train)\n",
    "test_class_counts = collections.Counter(y_test)\n",
    "\n",
    "print(f\"Train class counts: {train_class_counts}\")\n",
    "print(f\"Test class counts: {test_class_counts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "befaae9e-8e50-4fe3-9848-0ae9e8642b3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T18:08:43.927065Z",
     "iopub.status.busy": "2025-05-30T18:08:43.926750Z",
     "iopub.status.idle": "2025-05-30T18:08:43.933844Z",
     "shell.execute_reply": "2025-05-30T18:08:43.932746Z",
     "shell.execute_reply.started": "2025-05-30T18:08:43.927035Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set (10400 samples): False = 73.67 % and True = 26.33 %\n",
      "Test set (2600samples): False = 73.62 % and True = 26.38 %\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train set (10400 samples): False = {(7662/10400)*100:.2f} % and True = {(2738/10400)* 100:.2f} %\")\n",
    "print(f\"Test set (2600samples): False = {(1914/2600)*100:.2f} % and True = {(686/2600)*100:.2f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f28afacb-52a1-4576-bb99-8cfb7c6c6f76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T18:08:43.936026Z",
     "iopub.status.busy": "2025-05-30T18:08:43.935721Z",
     "iopub.status.idle": "2025-05-30T18:08:43.942419Z",
     "shell.execute_reply": "2025-05-30T18:08:43.941253Z",
     "shell.execute_reply.started": "2025-05-30T18:08:43.935994Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloaders: (<torch.utils.data.dataloader.DataLoader object at 0x7f669783f8e0>, <torch.utils.data.dataloader.DataLoader object at 0x7f6697840610>)\n",
      "Length of train dataloader: 650 batches of 16\n",
      "Length of test dataloader: 163 batches of 16\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dataloaders: {train_dataloader, test_dataloader}\") \n",
    "print(f\"Length of train dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}\")\n",
    "print(f\"Length of test dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "16584e8a-0bca-4597-b286-9d598ee30a5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T18:08:43.944253Z",
     "iopub.status.busy": "2025-05-30T18:08:43.943939Z",
     "iopub.status.idle": "2025-05-30T18:08:43.953383Z",
     "shell.execute_reply": "2025-05-30T18:08:43.952117Z",
     "shell.execute_reply.started": "2025-05-30T18:08:43.944222Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(torch.Size([16, 603]), torch.Size([16])) -> [batch_size, num_of_tokens_per_formula], [bach_size]\n"
     ]
    }
   ],
   "source": [
    "# Check out what's inside the training dataloader\n",
    "train_features_batch, train_labels_batch = next(iter(train_dataloader)) # next() grabs the first batch from the iterator\n",
    "print(f\"{train_features_batch.shape, train_labels_batch.shape} -> [batch_size, num_of_tokens_per_formula], [bach_size]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d6d015-b84a-4375-834c-773b9e36f341",
   "metadata": {},
   "source": [
    "----\n",
    "### **3 Set up device-agnostic code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "933d6ee1-c2c3-48da-b87f-386cc1786581",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T18:08:43.955756Z",
     "iopub.status.busy": "2025-05-30T18:08:43.955430Z",
     "iopub.status.idle": "2025-05-30T18:08:43.962788Z",
     "shell.execute_reply": "2025-05-30T18:08:43.961705Z",
     "shell.execute_reply.started": "2025-05-30T18:08:43.955725Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962d7af9-9963-4db4-a390-21e2d8afbbc2",
   "metadata": {},
   "source": [
    "---\n",
    "### **4 Build, Train and Test Models on Synthetic Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b21bd68f-29eb-4966-88bb-1ab7a3ee9219",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T18:08:43.964943Z",
     "iopub.status.busy": "2025-05-30T18:08:43.964644Z",
     "iopub.status.idle": "2025-05-30T18:08:43.972625Z",
     "shell.execute_reply": "2025-05-30T18:08:43.971419Z",
     "shell.execute_reply.started": "2025-05-30T18:08:43.964913Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size (including padding token): 108\n",
      "Max index in batch: 107\n"
     ]
    }
   ],
   "source": [
    "# --- Hyperparameters --- \n",
    "# Determine the vocabulary size for the embedding layer and add 1 for padding index (0)\n",
    "VOCAB_SIZE = compute_vocab_size(tokenizer)\n",
    "print(f\"Vocabulary size (including padding token): {VOCAB_SIZE}\")\n",
    "print(\"Max index in batch:\", train_features_batch.max().item())\n",
    "assert train_features_batch.max().item() < VOCAB_SIZE, \"Some token indices exceed the embedding size!\"\n",
    "\n",
    "EMBEDDING_DIM = 32\n",
    "LR = 0.0005\n",
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd93b29-5f36-46a6-90a2-dcb4fcbb500d",
   "metadata": {},
   "source": [
    "#### **4.1 Model 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c9991c4f-8513-493c-891d-770a6f7e9bb0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T16:20:20.132115Z",
     "iopub.status.busy": "2025-05-30T16:20:20.131665Z",
     "iopub.status.idle": "2025-05-30T16:20:20.140567Z",
     "shell.execute_reply": "2025-05-30T16:20:20.139502Z",
     "shell.execute_reply.started": "2025-05-30T16:20:20.132081Z"
    }
   },
   "outputs": [],
   "source": [
    "class RNN_V1(nn.Module):\n",
    "    def __init__(self, vocab_size :int, embedding_dim :int, hidden_units: int, output_size :int):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim)\n",
    "        self.rnn = nn.RNN(input_size=embedding_dim, hidden_size=hidden_units, batch_first=True)\n",
    "        self.linear = nn.Linear(in_features=hidden_units, out_features=output_size)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.embedding(x)               # [batch_size, seq_len, embed_dim]\n",
    "        _, h_n = self.rnn(x)                # [num_layers, batch_size, hidden_dim]\n",
    "        last_hidden = h_n.squeeze(0)        # remove the first dimension, which is num_layers=1 \n",
    "        output = self.linear(last_hidden)   # [batch_size, output_size] == [32, 1]\n",
    "        output = output.squeeze(1)          # Reshape output to match label shape [32]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "09a47d7f-346e-4255-ac9d-aa67991a625f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T16:20:24.177826Z",
     "iopub.status.busy": "2025-05-30T16:20:24.177325Z",
     "iopub.status.idle": "2025-05-30T16:20:24.504976Z",
     "shell.execute_reply": "2025-05-30T16:20:24.503887Z",
     "shell.execute_reply.started": "2025-05-30T16:20:24.177788Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_1 is on the model device: cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RNN_V1(\n",
       "  (embedding): Embedding(108, 32)\n",
       "  (rnn): RNN(32, 64, batch_first=True)\n",
       "  (linear): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Model 1 ---\n",
    "model_1 = RNN_V1(vocab_size=VOCAB_SIZE, \n",
    "                 embedding_dim=EMBEDDING_DIM,\n",
    "                 hidden_units=64,\n",
    "                 output_size=1\n",
    ").to(device) \n",
    "\n",
    "print(f\"Model_1 is on the model device: {next(model_1.parameters()).device}\")\n",
    "model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6af414d8-9fb2-4a80-8b06-190dbf2ff747",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T16:20:27.505620Z",
     "iopub.status.busy": "2025-05-30T16:20:27.504503Z",
     "iopub.status.idle": "2025-05-30T16:20:27.511143Z",
     "shell.execute_reply": "2025-05-30T16:20:27.510056Z",
     "shell.execute_reply.started": "2025-05-30T16:20:27.505579Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Loss and Optimizer Functions ---\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(params=model_1.parameters(), \n",
    "                            lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ac864a4c-d4e6-41db-ab35-3b0bffd3ef69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T16:20:30.123722Z",
     "iopub.status.busy": "2025-05-30T16:20:30.122243Z",
     "iopub.status.idle": "2025-05-30T16:20:30.254493Z",
     "shell.execute_reply": "2025-05-30T16:20:30.253353Z",
     "shell.execute_reply.started": "2025-05-30T16:20:30.123681Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "========================================================================================================================\n",
       "Layer (type (var_name))                  Input Shape          Output Shape         Param #              Trainable\n",
       "========================================================================================================================\n",
       "RNN_V1 (RNN_V1)                          [16, 603]            [16, 1]              --                   True\n",
       "├─Embedding (embedding)                  [16, 603]            [16, 603, 32]        3,456                True\n",
       "├─RNN (rnn)                              [16, 603, 32]        [16, 603, 64]        6,272                True\n",
       "├─Linear (linear)                        [16, 64]             [16, 1]              65                   True\n",
       "========================================================================================================================\n",
       "Total params: 9,793\n",
       "Trainable params: 9,793\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 60.57\n",
       "========================================================================================================================\n",
       "Input size (MB): 0.08\n",
       "Forward/backward pass size (MB): 7.41\n",
       "Params size (MB): 0.04\n",
       "Estimated Total Size (MB): 7.53\n",
       "========================================================================================================================"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a summary of Model_1 \n",
    "summary(model_1, \n",
    "         input_size=train_features_batch.shape,\n",
    "         dtypes=[torch.long],\n",
    "         verbose=0,\n",
    "         col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "         col_width=20,\n",
    "         row_settings=[\"var_names\"],\n",
    "         device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "92addf65-186b-4c07-8586-144624e2bd61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T16:20:33.700495Z",
     "iopub.status.busy": "2025-05-30T16:20:33.699355Z",
     "iopub.status.idle": "2025-05-30T16:20:47.669305Z",
     "shell.execute_reply": "2025-05-30T16:20:47.667980Z",
     "shell.execute_reply.started": "2025-05-30T16:20:33.700457Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ae2ecb9933545c2a29e5574c5f14a8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epochs:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 0.5785 | train_acc: 0.7367 | test_loss: 0.5768 | test_acc: 0.7362\n",
      "Epoch: 2 | train_loss: 0.5777 | train_acc: 0.7367 | test_loss: 0.5773 | test_acc: 0.7362\n",
      "Epoch: 3 | train_loss: 0.5772 | train_acc: 0.7367 | test_loss: 0.5767 | test_acc: 0.7362\n",
      "Epoch: 4 | train_loss: 0.5773 | train_acc: 0.7367 | test_loss: 0.5768 | test_acc: 0.7370\n",
      "Epoch: 5 | train_loss: 0.5770 | train_acc: 0.7369 | test_loss: 0.5765 | test_acc: 0.7370\n"
     ]
    }
   ],
   "source": [
    "# --- Train and Test Model_1 ---\n",
    "set_seeds()\n",
    "model_1_results = train(model=model_1,\n",
    "                        train_dataloader=train_dataloader,\n",
    "                        test_dataloader=test_dataloader,\n",
    "                        optimizer=optimizer,\n",
    "                        loss_fn=loss_fn,\n",
    "                        epochs=5,\n",
    "                        device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "69581339-47a2-4ef0-a02a-241a88f65c7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T16:20:54.420596Z",
     "iopub.status.busy": "2025-05-30T16:20:54.420082Z",
     "iopub.status.idle": "2025-05-30T16:20:54.430469Z",
     "shell.execute_reply": "2025-05-30T16:20:54.429161Z",
     "shell.execute_reply.started": "2025-05-30T16:20:54.420558Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Results saved to: models_results/Model_1_vanilla_rnn_results.csv\n"
     ]
    }
   ],
   "source": [
    "save_results(model_1_results, target_dir=\"models_results\", filename=\"Model_1_vanilla_rnn_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "47ebe0ad-d5cc-4c17-94ad-67cbb973779f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T16:21:07.242927Z",
     "iopub.status.busy": "2025-05-30T16:21:07.241958Z",
     "iopub.status.idle": "2025-05-30T16:21:07.248823Z",
     "shell.execute_reply": "2025-05-30T16:21:07.247852Z",
     "shell.execute_reply.started": "2025-05-30T16:21:07.242882Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Given the data distribution and Model performances, model_1 predicts False every time — and that would still be right ~74% of the time.\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nGiven the data distribution and Model performances, model_1 predicts False every time — and that would still be right ~74% of the time.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ea6e9f-221f-423e-9c6a-c0f930060e5f",
   "metadata": {},
   "source": [
    "#### **4.2 Model 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c0c6dc2b-fb9d-41ca-8697-d6dffabe8e29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T16:21:18.152001Z",
     "iopub.status.busy": "2025-05-30T16:21:18.150345Z",
     "iopub.status.idle": "2025-05-30T16:21:18.162606Z",
     "shell.execute_reply": "2025-05-30T16:21:18.161367Z",
     "shell.execute_reply.started": "2025-05-30T16:21:18.151920Z"
    }
   },
   "outputs": [],
   "source": [
    "class GRU(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim=EMBEDDING_DIM):\n",
    "        super().__init__()\n",
    "\n",
    "        # Embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "\n",
    "        # First bidirectional GRU layer\n",
    "        self.gru1 = nn.GRU(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=128,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "\n",
    "        # Second bidirectional GRU layer\n",
    "        self.gru2 = nn.GRU(\n",
    "            input_size=128 * 2,  # Because bidirectional doubles output size\n",
    "            hidden_size=64,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(64 * 2, 32)  # Because bidirectional doubles output size\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(32, 1)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [batch_size, seq_len]\n",
    "        x = self.embedding(x)              # [batch_size, seq_len, embed_dim]\n",
    "\n",
    "        out1, _ = self.gru1(x)             # [batch_size, seq_len, 256]\n",
    "        out2, _ = self.gru2(out1)          # [batch_size, seq_len, 128]\n",
    "\n",
    "        out2_last = out2[:, -1, :]         # Use the last timestep's features\n",
    "        x = self.relu(self.fc1(out2_last)) # [batch_size, 32]\n",
    "        output = self.fc2(x)               # [batch_size, 1]\n",
    "\n",
    "        return output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1e768f31-2477-4b5f-870d-7167f3c90f5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T16:21:21.462224Z",
     "iopub.status.busy": "2025-05-30T16:21:21.460947Z",
     "iopub.status.idle": "2025-05-30T16:21:21.479521Z",
     "shell.execute_reply": "2025-05-30T16:21:21.478286Z",
     "shell.execute_reply.started": "2025-05-30T16:21:21.462181Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_2 is on the model device: cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GRU(\n",
       "  (embedding): Embedding(108, 32, padding_idx=0)\n",
       "  (gru1): GRU(32, 128, batch_first=True, bidirectional=True)\n",
       "  (gru2): GRU(256, 64, batch_first=True, bidirectional=True)\n",
       "  (fc1): Linear(in_features=128, out_features=32, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2 = GRU(vocab_size=VOCAB_SIZE, embedding_dim=EMBEDDING_DIM).to(device)\n",
    "\n",
    "print(f\"Model_2 is on the model device: {next(model_2.parameters()).device}\")\n",
    "model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8a0fc82c-e48c-47dd-ad4a-193a7849de91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T16:21:32.895612Z",
     "iopub.status.busy": "2025-05-30T16:21:32.895153Z",
     "iopub.status.idle": "2025-05-30T16:21:32.902704Z",
     "shell.execute_reply": "2025-05-30T16:21:32.901522Z",
     "shell.execute_reply.started": "2025-05-30T16:21:32.895577Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Loss and Optimizer Functions ---\n",
    "loss_fn = AsymmetricFocalLoss(\n",
    "    alpha_pos=0.3,  # minority (tautology)\n",
    "    alpha_neg=0.7,  # majority\n",
    "    gamma_pos=3.0,\n",
    "    gamma_neg=1.5\n",
    ")\n",
    "optimizer = torch.optim.Adam(params=model_2.parameters(), \n",
    "                            lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7dc0a216-203c-40bf-93f2-0b8d6aaa55ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T16:21:35.462542Z",
     "iopub.status.busy": "2025-05-30T16:21:35.462037Z",
     "iopub.status.idle": "2025-05-30T16:21:35.506313Z",
     "shell.execute_reply": "2025-05-30T16:21:35.504976Z",
     "shell.execute_reply.started": "2025-05-30T16:21:35.462483Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "========================================================================================================================\n",
       "Layer (type (var_name))                  Input Shape          Output Shape         Param #              Trainable\n",
       "========================================================================================================================\n",
       "GRU (GRU)                                [16, 603]            [16, 1]              --                   True\n",
       "├─Embedding (embedding)                  [16, 603]            [16, 603, 32]        3,456                True\n",
       "├─GRU (gru1)                             [16, 603, 32]        [16, 603, 256]       124,416              True\n",
       "├─GRU (gru2)                             [16, 603, 256]       [16, 603, 128]       123,648              True\n",
       "├─Linear (fc1)                           [16, 128]            [16, 32]             4,128                True\n",
       "├─ReLU (relu)                            [16, 32]             [16, 32]             --                   --\n",
       "├─Linear (fc2)                           [16, 32]             [16, 1]              33                   True\n",
       "========================================================================================================================\n",
       "Total params: 255,681\n",
       "Trainable params: 255,681\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 2.39\n",
       "========================================================================================================================\n",
       "Input size (MB): 0.08\n",
       "Forward/backward pass size (MB): 32.11\n",
       "Params size (MB): 1.02\n",
       "Estimated Total Size (MB): 33.21\n",
       "========================================================================================================================"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a summary of Model_2 \n",
    "summary(model_2, \n",
    "         input_size=train_features_batch.shape,\n",
    "         dtypes=[torch.long],\n",
    "         verbose=0,\n",
    "         col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "         col_width=20,\n",
    "         row_settings=[\"var_names\"],\n",
    "         device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "08057266-caa1-47f4-a6ce-23ceeb08bcd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T16:21:40.570923Z",
     "iopub.status.busy": "2025-05-30T16:21:40.570397Z",
     "iopub.status.idle": "2025-05-30T16:22:24.507969Z",
     "shell.execute_reply": "2025-05-30T16:22:24.506813Z",
     "shell.execute_reply.started": "2025-05-30T16:21:40.570888Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "733c375755214e009c50cab5489d7d04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epochs:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 0.0429 | train_acc: 0.8403 | test_loss: 0.0213 | test_acc: 0.9463\n",
      "Epoch: 2 | train_loss: 0.0214 | train_acc: 0.9428 | test_loss: 0.0197 | test_acc: 0.9548\n",
      "Epoch: 3 | train_loss: 0.0188 | train_acc: 0.9512 | test_loss: 0.0157 | test_acc: 0.9594\n",
      "Epoch: 4 | train_loss: 0.0153 | train_acc: 0.9587 | test_loss: 0.0153 | test_acc: 0.9486\n",
      "Epoch: 5 | train_loss: 0.0133 | train_acc: 0.9608 | test_loss: 0.0129 | test_acc: 0.9640\n"
     ]
    }
   ],
   "source": [
    "# --- Train and Test Model_2 ---\n",
    "set_seeds()\n",
    "model_2_results = train(model=model_2,\n",
    "                        train_dataloader=train_dataloader,\n",
    "                        test_dataloader=test_dataloader,\n",
    "                        optimizer=optimizer,\n",
    "                        loss_fn=loss_fn,\n",
    "                        epochs=5,\n",
    "                        device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b0338dbd-6625-4801-a2fc-10b8be2febd4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T16:22:27.164063Z",
     "iopub.status.busy": "2025-05-30T16:22:27.163603Z",
     "iopub.status.idle": "2025-05-30T16:22:27.174929Z",
     "shell.execute_reply": "2025-05-30T16:22:27.173572Z",
     "shell.execute_reply.started": "2025-05-30T16:22:27.164028Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Results saved to: models_results/Model_2_stacked_bidirectional_gru_results.csv\n"
     ]
    }
   ],
   "source": [
    "save_results(model_2_results, target_dir=\"models_results\", filename=\"Model_2_stacked_bidirectional_gru_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a1adf2d5-94ec-47b6-86e9-0a85de4eeba1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T16:22:30.296608Z",
     "iopub.status.busy": "2025-05-30T16:22:30.296152Z",
     "iopub.status.idle": "2025-05-30T16:22:30.314014Z",
     "shell.execute_reply": "2025-05-30T16:22:30.312870Z",
     "shell.execute_reply.started": "2025-05-30T16:22:30.296576Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saving model to: models/Bidirectional_GRU_trained_on_synth_formulas.pth\n"
     ]
    }
   ],
   "source": [
    "save_model(model=model_2,\n",
    "           target_dir=\"models\",\n",
    "           model_name=\"Bidirectional_GRU_trained_on_synth_formulas.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69dcba83-e2db-4ed0-8c28-ffec1f3460b6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49645bf2-f156-4973-a2ed-a53d08177c02",
   "metadata": {},
   "source": [
    "### **5 LSTM Tree**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0635ddb6-187e-4f7c-aad7-9da18932c11d",
   "metadata": {},
   "source": [
    "Partiamo con il primo passo: la rappresentazione delle formule logiche come alberi. Questo ci servirà come struttura ricorsiva su cui il TreeLSTM opererà.\n",
    "\n",
    "#### Passo 1: Creazione della struttura ad albero FormulaTreeNode\n",
    "Ogni nodo dell’albero corrisponderà a un oggetto FormulaTreeNode, che rappresenta un nodo della formula logica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c39903df-79bb-4554-aba4-6320953d820c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T18:08:56.325183Z",
     "iopub.status.busy": "2025-05-30T18:08:56.324683Z",
     "iopub.status.idle": "2025-05-30T18:08:56.332694Z",
     "shell.execute_reply": "2025-05-30T18:08:56.331815Z",
     "shell.execute_reply.started": "2025-05-30T18:08:56.325147Z"
    }
   },
   "outputs": [],
   "source": [
    "class FormulaTreeNode:\n",
    "    \"\"\"\n",
    "    Rappresenta un nodo nell'albero sintattico di una formula logica.\n",
    "    \"\"\"\n",
    "    def __init__(self, formula):\n",
    "        self.formula = formula\n",
    "        self.children = []\n",
    "        self.embedding_index = None  # sarà assegnato più avanti dal tokenizer\n",
    "\n",
    "        # Costruzione ricorsiva dei figli\n",
    "        if isinstance(formula, UnaryConnectiveFormula):\n",
    "            self.children.append(FormulaTreeNode(formula.formula))\n",
    "\n",
    "        elif isinstance(formula, BinaryConnectiveFormula):\n",
    "            self.children.append(FormulaTreeNode(formula.left))\n",
    "            self.children.append(FormulaTreeNode(formula.right))\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Node({self.formula}, children={len(self.children)})\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b6556b-ba59-4f34-9baf-a3d6971231ab",
   "metadata": {},
   "source": [
    "Creazione di un FormulaTreeNode a partire da essa per verificare che la costruzione dell’albero funzioni correttamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a8122b64-e374-4532-b84b-6b806741c9d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T18:08:59.547597Z",
     "iopub.status.busy": "2025-05-30T18:08:59.547042Z",
     "iopub.status.idle": "2025-05-30T18:08:59.555105Z",
     "shell.execute_reply": "2025-05-30T18:08:59.554003Z",
     "shell.execute_reply.started": "2025-05-30T18:08:59.547554Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formula: ((A0 → A1) ∨ (A2 ∧ A3) ∨ A4 ∨ A5 → A6) ∨ ¬(A7 → A0)\n",
      "Radice: Node(((A0 → A1) ∨ (A2 ∧ A3) ∨ A4 ∨ A5 → A6) ∨ ¬(A7 → A0), children=2)\n",
      "Figli: [Node((A0 → A1) ∨ (A2 ∧ A3) ∨ A4 ∨ A5 → A6, children=2), Node(¬(A7 → A0), children=1)]\n"
     ]
    }
   ],
   "source": [
    "# Example\n",
    "example_formula = X_train[0]\n",
    "print(\"Formula:\", example_formula)\n",
    "\n",
    "root_node = FormulaTreeNode(example_formula)\n",
    "print(\"Radice:\", root_node)\n",
    "print(\"Figli:\", root_node.children)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9fc36d-8ea4-41e2-a387-19a2b3b6ad59",
   "metadata": {},
   "source": [
    "Fase 2: implementazione del TreeLSTM cell, che è il cuore del modello. Useremo una versione binaria del TreeLSTM, visto che le formule logiche usano solo connectivi unari e binari.\n",
    "\n",
    "#### Passo 2: Implementazione di BinaryTreeLSTMCell\n",
    "\n",
    "Questa classe sarà un modulo PyTorch che combina l'input x di un nodo con gli hidden state dei suoi figli per produrre un nuovo stato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9ebc4b2e-00c6-42c5-81b3-0490131e18f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T13:02:59.494300Z",
     "iopub.status.busy": "2025-05-30T13:02:59.493999Z",
     "iopub.status.idle": "2025-05-30T13:02:59.504345Z",
     "shell.execute_reply": "2025-05-30T13:02:59.503032Z",
     "shell.execute_reply.started": "2025-05-30T13:02:59.494267Z"
    }
   },
   "outputs": [],
   "source": [
    "class BinaryTreeLSTMCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # Linear transformations for i (input), o (output), and u (update) gates\n",
    "        self.W_iou = nn.Linear(input_size, 3 * hidden_size)\n",
    "        self.U_iou = nn.Linear(2 * hidden_size, 3 * hidden_size)\n",
    "\n",
    "        # Linear transformations for forget gates (left and right children) \n",
    "        self.W_f = nn.Linear(input_size, 2 * hidden_size)\n",
    "        self.U_f = nn.Linear(2 * hidden_size, 2 * hidden_size)\n",
    "\n",
    "    def forward(self, x, left_state :Tuple[Tensor, Tensor], right_state :Tuple[Tensor, Tensor]):\n",
    "        h_l, c_l = left_state  # left hidden states and cell states,  [1, hidd_size], [1, hidd_size]\n",
    "        h_r, c_r = right_state # right hidden states and cell states, [1, hidd_size], [1, hidd_size]\n",
    "\n",
    "        h_cat = torch.cat([h_l, h_r], dim=1)  # [1, 2xhidd_size]\n",
    "\n",
    "        # Input, Output, Update gates\n",
    "        iou = self.W_iou(x) + self.U_iou(h_cat)\n",
    "        i, o, u = torch.chunk(torch.sigmoid(iou), 3, dim=1)\n",
    "        u = torch.tanh(u)\n",
    "\n",
    "        # Forget gates\n",
    "        f = self.W_f(x) + self.U_f(h_cat)\n",
    "        f_l, f_r = torch.chunk(torch.sigmoid(f), 2, dim=1)\n",
    "\n",
    "        # Cell state\n",
    "        c = i * u + f_l * c_l + f_r * c_r\n",
    "        h = o * torch.tanh(c)\n",
    "\n",
    "        return h, c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa3e80f-5709-4288-abc5-a8859a77acf0",
   "metadata": {},
   "source": [
    "Ora passiamo al TreeLSTM encoder, che applicherà ricorsivamente la cella BinaryTreeLSTMCell a ogni nodo dell’albero logico.\n",
    "\n",
    "### Passo 3: Costruzione di TreeLSTMEncoder\n",
    "Questo modulo:\n",
    "\n",
    "- trasforma un FormulaTreeNode in una rappresentazione vettoriale,\n",
    "- ricorsivamente applica il TreeLSTM a tutti i figli,\n",
    "- restituisce lo stato nascosto (h) e lo stato di memoria (c) della radice, che potremo usare per la classificazione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8c978fda-7eee-4482-827c-53fdb1f46d78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T13:02:59.505602Z",
     "iopub.status.busy": "2025-05-30T13:02:59.505309Z",
     "iopub.status.idle": "2025-05-30T13:02:59.516126Z",
     "shell.execute_reply": "2025-05-30T13:02:59.514884Z",
     "shell.execute_reply.started": "2025-05-30T13:02:59.505572Z"
    }
   },
   "outputs": [],
   "source": [
    "class TreeLSTMEncoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size):\n",
    "        super().__init__()\n",
    "\n",
    "        # Nota: Questo encoder assume di ricevere un solo nodo (radice) per volta.\n",
    "        # L'embedding è calcolato su un singolo indice: [1] → [1, E]\n",
    "        # Non esiste gestione nativa del batch in questa architettura.\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.cell = BinaryTreeLSTMCell(input_size=embedding_dim, hidden_size=hidden_size)\n",
    "\n",
    "    def forward(self, node: FormulaTreeNode):\n",
    "        # Ottieni embedding del nodo corrente\n",
    "        x = self.embedding(torch.tensor([node.embedding_index], device=self.embedding.weight.device))\n",
    "\n",
    "        # Caso foglia: nessun figlio\n",
    "        if len(node.children) == 0:\n",
    "            zero_state = (\n",
    "                torch.zeros(1, self.cell.hidden_size, device=x.device), # zero_state = (h_zero, c_zero)\n",
    "                torch.zeros(1, self.cell.hidden_size, device=x.device)  # where h_zero: initial hidden state filled whit zeros\n",
    "                                                                        # c_zero: initial cell state filled with zeros\n",
    "            )\n",
    "            h, c = self.cell(x, zero_state, zero_state)\n",
    "            return h, c\n",
    "\n",
    "        # Caso unary: un figlio (es. Negazione)\n",
    "        elif len(node.children) == 1:\n",
    "            child_state = self.forward(node.children[0])\n",
    "            h, c = self.cell(x, child_state, child_state)  # The only child is duplicated, so that the binary cell can also be used for unary nodes.\n",
    "            return h, c\n",
    "\n",
    "        # Caso binary: due figli\n",
    "        elif len(node.children) == 2:\n",
    "            left_state = self.forward(node.children[0])\n",
    "            right_state = self.forward(node.children[1])\n",
    "            h, c = self.cell(x, left_state, right_state)\n",
    "            return h, c\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected number of children: {len(node.children)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c9ebb2-99fd-4b04-962c-ab1bc823a605",
   "metadata": {},
   "source": [
    "Riepilogo:\n",
    "- Ogni nodo dell’albero riceve il suo embedding.\n",
    "- I figli vengono elaborati prima, poi i loro stati sono usati per calcolare lo stato del genitore.\n",
    "- I nodi con 0, 1 o 2 figli sono trattati separatamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4235a776-ff07-4f38-a22d-adf79e2b2f1a",
   "metadata": {},
   "source": [
    "Ora ci occupiamo di associare a ogni nodo dell'albero il suo indice di embedding, usando il CustomTokenizer che hai già definito.\n",
    "\n",
    "#### Passo 4: Assegnazione degli indici di embedding ai nodi\n",
    "Il tokenizer già mappa ogni oggetto Formula in un intero. Ci serve un helper che:\n",
    "\n",
    "- Visita ricorsivamente l’albero FormulaTreeNode\n",
    "- Assegna a ogni nodo il corrispondente embedding_index usando tokenizer.formula_to_token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1b1456be-fbaa-4865-816c-950302055dde",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T18:09:07.398575Z",
     "iopub.status.busy": "2025-05-30T18:09:07.397325Z",
     "iopub.status.idle": "2025-05-30T18:09:07.406489Z",
     "shell.execute_reply": "2025-05-30T18:09:07.405519Z",
     "shell.execute_reply.started": "2025-05-30T18:09:07.398528Z"
    }
   },
   "outputs": [],
   "source": [
    "def assign_embedding_indices(node: FormulaTreeNode, tokenizer: CustomTokenizer):\n",
    "    \"\"\"\n",
    "    Ricorsivamente assegna a ciascun nodo dell'albero l'indice di embedding\n",
    "    usando il tokenizer già fittato.\n",
    "    \"\"\"\n",
    "    if node.formula in tokenizer.formula_to_token:\n",
    "        node.embedding_index = tokenizer.formula_to_token[node.formula]\n",
    "    else:\n",
    "        # fallback: prova ad assegnare sulla base del tipo (per connettivi)\n",
    "        if isinstance(node.formula, Falsity):\n",
    "            node.embedding_index = tokenizer.falsity_token\n",
    "        elif isinstance(node.formula, Letter):\n",
    "            # If it is a letter but it is not in the tokenizer, it raises an error\n",
    "            raise ValueError(f\"Using an unknown letter is not accepted: {node.formula}\")\n",
    "        elif isinstance(node.formula, UnaryConnectiveFormula):\n",
    "            node.embedding_index = tokenizer.connective_map[type(node.formula).__name__]\n",
    "        elif isinstance(node.formula, BinaryConnectiveFormula):\n",
    "            node.embedding_index = tokenizer.connective_map[type(node.formula).__name__]\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown formula: {node.formula}\")\n",
    "\n",
    "    for child in node.children:\n",
    "        assign_embedding_indices(child, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7c1df92d-fe9d-46e9-8741-1dc494421829",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T18:09:11.515577Z",
     "iopub.status.busy": "2025-05-30T18:09:11.515066Z",
     "iopub.status.idle": "2025-05-30T18:09:11.902573Z",
     "shell.execute_reply": "2025-05-30T18:09:11.901087Z",
     "shell.execute_reply.started": "2025-05-30T18:09:11.515541Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "└── [Disjunction] ((A0 → A1) ∨ (A2 ∧ A3) ∨ A4 ∨ A5 → A6) ∨ ¬(A7 → A0) (embedding_index=101)\n",
      "    ├── [Implication] (A0 → A1) ∨ (A2 ∧ A3) ∨ A4 ∨ A5 → A6 (embedding_index=103)\n",
      "    │   ├── [Disjunction] (A0 → A1) ∨ (A2 ∧ A3) ∨ A4 ∨ A5 (embedding_index=101)\n",
      "    │   │   ├── [Disjunction] (A0 → A1) ∨ (A2 ∧ A3) ∨ A4 (embedding_index=101)\n",
      "    │   │   │   ├── [Disjunction] (A0 → A1) ∨ (A2 ∧ A3) (embedding_index=101)\n",
      "    │   │   │   │   ├── [Implication] A0 → A1 (embedding_index=103)\n",
      "    │   │   │   │   │   ├── [Letter] A0 (embedding_index=1)\n",
      "    │   │   │   │   │   └── [Letter] A1 (embedding_index=2)\n",
      "    │   │   │   │   └── [Conjunction] A2 ∧ A3 (embedding_index=100)\n",
      "    │   │   │   │       ├── [Letter] A2 (embedding_index=3)\n",
      "    │   │   │   │       └── [Letter] A3 (embedding_index=4)\n",
      "    │   │   │   └── [Letter] A4 (embedding_index=5)\n",
      "    │   │   └── [Letter] A5 (embedding_index=6)\n",
      "    │   └── [Letter] A6 (embedding_index=7)\n",
      "    └── [Negation] ¬(A7 → A0) (embedding_index=102)\n",
      "        └── [Implication] A7 → A0 (embedding_index=103)\n",
      "            ├── [Letter] A7 (embedding_index=8)\n",
      "            └── [Letter] A0 (embedding_index=1)\n"
     ]
    }
   ],
   "source": [
    "# Example \n",
    "\n",
    "# Function: Print tree with embedding indexes\n",
    "def print_tree_with_embeddings(node: FormulaTreeNode, prefix: str = \"\", is_last: bool = True):\n",
    "    # Preparazione linea da stampare\n",
    "    connector = \"└── \" if is_last else \"├── \"\n",
    "    formula_str = str(node.formula)\n",
    "    formula_type = type(node.formula).__name__\n",
    "    print(f\"{prefix}{connector}[{formula_type}] {formula_str} (embedding_index={node.embedding_index})\")\n",
    "\n",
    "    # Preparazione del prefisso per i figli\n",
    "    new_prefix = prefix + (\"    \" if is_last else \"│   \")\n",
    "    child_count = len(node.children)\n",
    "    for i, child in enumerate(node.children):\n",
    "        is_child_last = i == (child_count - 1)\n",
    "        print_tree_with_embeddings(child, new_prefix, is_child_last)\n",
    "\n",
    "# Tokenizer fit\n",
    "tokenizer = CustomTokenizer()\n",
    "tokenizer.fit(X_train)\n",
    "\n",
    "# Tree construction for a formula\n",
    "example_formula = X_train[0]\n",
    "root_node = FormulaTreeNode(example_formula)\n",
    "\n",
    "# Embedding index assignment\n",
    "assign_embedding_indices(root_node, tokenizer)\n",
    "\n",
    "# Tree print with indexes\n",
    "print_tree_with_embeddings(root_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af83c0a8-9784-4a7a-b67f-ddcd6c3798aa",
   "metadata": {},
   "source": [
    " Passiamo ora al classificatore finale, che prende il vettore h (output del nodo radice del TreeLSTM) e predice se la formula è una tautologia (1) o non-tautologia (0).\n",
    "\n",
    "#### Passo 5: Classificatore TreeLSTM completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ebdc53e8-f500-400b-be89-c5cd99058ec6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T13:02:59.912449Z",
     "iopub.status.busy": "2025-05-30T13:02:59.912136Z",
     "iopub.status.idle": "2025-05-30T13:02:59.919665Z",
     "shell.execute_reply": "2025-05-30T13:02:59.918526Z",
     "shell.execute_reply.started": "2025-05-30T13:02:59.912416Z"
    }
   },
   "outputs": [],
   "source": [
    "class TreeLSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size, fc_size):\n",
    "        super().__init__()\n",
    "\n",
    "        # Nota importante: questo modello lavora su UN singolo albero per volta.\n",
    "        # Non supporta input batchificati come nei modelli sequenziali (es. GRU).\n",
    "        # La dimensione batch non viene mai usata nei tensori in input/output: ogni forward\n",
    "        # riceve una root `FormulaTreeNode`, non un tensore [B, ...].\n",
    "        #\n",
    "        # I tensori all’interno del modello (es. hidden state, embeddings) sono sempre di forma [1, H]\n",
    "        # e vengono creati dinamicamente nel forward ricorsivo. Questo è compatibile con DataLoader,\n",
    "        # ma impedisce il parallelismo tipico del batch training.\n",
    "\n",
    "        self.encoder = TreeLSTMEncoder(vocab_size, embedding_dim, hidden_size)\n",
    "        self.fc1 = nn.Linear(hidden_size, fc_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(fc_size, 1)  # Output binario (logit)\n",
    "\n",
    "    def forward(self, root_node: FormulaTreeNode):\n",
    "        h, _ = self.encoder(root_node)  # root's hidden state (ignore the cell state)\n",
    "        x = self.relu(self.fc1(h))\n",
    "        output = self.fc2(x)\n",
    "        output = output.squeeze(1)  # shape: [batch_size] (senza dimensione extra)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9e94ecb3-44e2-4240-9e50-0ded3e77e710",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T13:02:59.921394Z",
     "iopub.status.busy": "2025-05-30T13:02:59.921105Z",
     "iopub.status.idle": "2025-05-30T13:02:59.949488Z",
     "shell.execute_reply": "2025-05-30T13:02:59.948084Z",
     "shell.execute_reply.started": "2025-05-30T13:02:59.921364Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formula: ((A0 → A1) ∨ (A2 ∧ A3) ∨ A4 ∨ A5 → A6) ∨ ¬(A7 → A0), Tautology status: False\n",
      "Model's tautology probabiity: 0.4796 -> Prediction: 0\n"
     ]
    }
   ],
   "source": [
    "# Esempio d’uso su una formula\n",
    "model = TreeLSTMClassifier(vocab_size=VOCAB_SIZE, embedding_dim=32, hidden_size=64, fc_size=32).to(device)\n",
    "\n",
    "# Prepara l'albero\n",
    "example_formula = X_train[0]\n",
    "root = FormulaTreeNode(example_formula)\n",
    "assign_embedding_indices(root, tokenizer)\n",
    "\n",
    "# Inference\n",
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    logits = model(root)\n",
    "    prob = torch.sigmoid(logits).item()\n",
    "    prediction = round(prob)\n",
    "    print(f\"Formula: {example_formula}, Tautology status: {y_train[0]}\")\n",
    "    print(f\"Model's tautology probabiity: {prob:.4f} -> Prediction: {prediction}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a1baea-1aec-4aae-b280-90063b7969c6",
   "metadata": {},
   "source": [
    "Ora adattiamo il sistema per addestrare un modello TreeLSTM su interi alberi, invece che su sequenze di token.\n",
    "\n",
    "#### Passo 6: Dataset e collate_fn per strutture ad albero\n",
    "Obiettivo - Costruire:\n",
    "\n",
    "- Un Dataset che restituisce (FormulaTreeNode, label)\n",
    "- Un collate_fn che crea un batch (in realtà una lista) di alberi\n",
    "- Un DataLoader che usa collate_fn\n",
    "- Un adattamento di train_step() e test_step() per TreeLSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1be48a-2352-42ca-a320-2340bbdda437",
   "metadata": {},
   "source": [
    "6.1. Dataset basato su alberi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c116cc86-ef59-4135-a9c8-323a6f1922f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T13:02:59.951284Z",
     "iopub.status.busy": "2025-05-30T13:02:59.950982Z",
     "iopub.status.idle": "2025-05-30T13:02:59.958593Z",
     "shell.execute_reply": "2025-05-30T13:02:59.957371Z",
     "shell.execute_reply.started": "2025-05-30T13:02:59.951250Z"
    }
   },
   "outputs": [],
   "source": [
    "class TreeFormulaDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, formulas: List[Formula], labels: List[float], tokenizer: CustomTokenizer):\n",
    "        self.formulas = formulas\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.formulas)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        formula = self.formulas[idx]\n",
    "        root = FormulaTreeNode(formula)\n",
    "        assign_embedding_indices(root, self.tokenizer)\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "        return root, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b429c19e-1f52-4038-9ae4-2b6e98ad010f",
   "metadata": {},
   "source": [
    "6.2. Collate function\n",
    "Non dobbiamo fare padding: basta restituire le liste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720accc4-8868-4a3e-aaf9-b8eb8fec6198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_collate_fn(batch: List[Tuple[FormulaTreeNode, torch.Tensor]]) -> Tuple[List[FormulaTreeNode], torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Collate function personalizzata per TreeLSTM:\n",
    "    - Riceve il batch del DataLoader: una lista di tuple (root, label)\n",
    "    - Restituisce:\n",
    "        * una lista di root (non tensorizzabile)\n",
    "        * un tensore impilato delle label\n",
    "\n",
    "    Args:\n",
    "        batch: Lista di tuple (FormulaTreeNode, label)\n",
    "\n",
    "    Returns:\n",
    "        roots: lista di FormulaTreeNode\n",
    "        labels: tensori scalari (float), impilati in un batch tensoriale di shape [batch_size]\n",
    "    \"\"\"\n",
    "    # Estraiamo separatamente le radici degli alberi e le etichette:\n",
    "    roots, labels = zip(*batch)\n",
    "    \n",
    "    return list(roots), torch.stack(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d534e569-0152-4d82-a9b7-acb662a3f20f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f592880c-f7d5-48f5-909b-cab604949fd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "576a1c03-3c4c-46dd-bb55-acce71305467",
   "metadata": {},
   "source": [
    "6.3. Creazione dei dataloader - Rappresentative Subset for experiments\n",
    "\n",
    "Funzione chiamata create_balanced_subset() che:\n",
    "\n",
    "- Prende in input: tutte le formule e le etichette (0 = non tautologia, 1 = tautologia)\n",
    "- Seleziona un sottoinsieme bilanciato con la stessa proporzione (~74% / 26%)\n",
    "- Ritorna i DataLoader già pronti per l’addestramento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8afb07b3-c4a3-4de5-8641-cad736df37aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T13:02:59.967200Z",
     "iopub.status.busy": "2025-05-30T13:02:59.966923Z",
     "iopub.status.idle": "2025-05-30T13:02:59.980320Z",
     "shell.execute_reply": "2025-05-30T13:02:59.979201Z",
     "shell.execute_reply.started": "2025-05-30T13:02:59.967170Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_balanced_subset_from_dataset(dataset: pd.DataFrame,\n",
    "                                        tokenizer: CustomTokenizer,\n",
    "                                        train_size: int = 1000,\n",
    "                                        test_size: int = 200,\n",
    "                                        positive_ratio: float = 0.26,\n",
    "                                        batch_size: int = 2,\n",
    "                                        seed: int = 42):\n",
    "    assert 0.0 < positive_ratio < 1.0 \n",
    "    assert \"formula\" in dataset.columns and \"is_tautology\" in dataset.columns \n",
    "\n",
    "    # Suddividi in base alla classe\n",
    "    taut = dataset[dataset[\"is_tautology\"] == 1]\n",
    "    nontaut = dataset[dataset[\"is_tautology\"] == 0]\n",
    "\n",
    "    # Campiona quantità bilanciate\n",
    "    train_taut = int(train_size * positive_ratio)\n",
    "    train_nontaut = train_size - train_taut\n",
    "    test_taut = int(test_size * positive_ratio)\n",
    "    test_nontaut = test_size - test_taut\n",
    "\n",
    "    train_taut_subset = taut.sample(train_taut, random_state=seed)\n",
    "    test_taut_subset = taut.drop(train_taut_subset.index).sample(test_taut, random_state=seed)\n",
    "    train_nontaut_subset = nontaut.sample(train_nontaut, random_state=seed)\n",
    "    test_nontaut_subset = nontaut.drop(train_nontaut_subset.index).sample(test_nontaut, random_state=seed)\n",
    "\n",
    "    # Costruzione set finali\n",
    "    train_subset = pd.concat([train_taut_subset, train_nontaut_subset]).sample(frac=1, random_state=seed)\n",
    "    test_subset = pd.concat([test_taut_subset, test_nontaut_subset]).sample(frac=1, random_state=seed)\n",
    "\n",
    "    # Log distribuzione classi\n",
    "    train_counts = Counter(train_subset[\"is_tautology\"])\n",
    "    test_counts = Counter(test_subset[\"is_tautology\"])\n",
    "    train_ratio = train_counts[1] / len(train_subset) * 100\n",
    "    test_ratio = test_counts[1] / len(test_subset) * 100\n",
    "\n",
    "    print(f\"Train set: {train_counts} (tautologies: {train_ratio:.1f}%)\")\n",
    "    print(f\"Test set:  {test_counts} (tautologies: {test_ratio:.1f}%)\")\n",
    "\n",
    "    # Dataset PyTorch\n",
    "    train_dataset = TreeFormulaDataset(train_subset[\"formula\"].tolist(), train_subset[\"is_tautology\"].tolist(), tokenizer)\n",
    "    test_dataset = TreeFormulaDataset(test_subset[\"formula\"].tolist(), test_subset[\"is_tautology\"].tolist(), tokenizer)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, collate_fn=tree_collate_fn\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset, batch_size=batch_size, shuffle=False, collate_fn=tree_collate_fn\n",
    "    )\n",
    "\n",
    "    # Nota: anche se viene specificato un batch_size > 1,\n",
    "    # il TreeLSTM non elabora veri batch paralleli. \n",
    "    # Il DataLoader restituisce una lista di alberi (`roots`) e un batch di etichette,\n",
    "    # ma ogni albero viene processato individualmente nel training loop, \n",
    "    # perché le strutture ad albero non sono compatibili con operazioni vettoriali batched.\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "153a9e03-3b36-4f43-b64d-885f7caebbfe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T13:02:59.981919Z",
     "iopub.status.busy": "2025-05-30T13:02:59.981622Z",
     "iopub.status.idle": "2025-05-30T13:03:00.002120Z",
     "shell.execute_reply": "2025-05-30T13:03:00.000432Z",
     "shell.execute_reply.started": "2025-05-30T13:02:59.981884Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Counter({False: 740, True: 260}) (tautologies: 26.0%)\n",
      "Test set:  Counter({False: 148, True: 52}) (tautologies: 26.0%)\n"
     ]
    }
   ],
   "source": [
    "tree_train_loader, tree_test_loader = create_balanced_subset_from_dataset(dataset,       \n",
    "                                                                          tokenizer,\n",
    "                                                                          train_size=1000,\n",
    "                                                                          test_size=200,\n",
    "                                                                          positive_ratio=0.26,\n",
    "                                                                          batch_size=2\n",
    "                                                                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8730cd-27a1-4ee6-afce-0c1fc4a2cf70",
   "metadata": {},
   "source": [
    "6.4. Adattamento di train_step e test_step per TreeLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b0e2c023-78ec-416e-8b23-04f382f46011",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T13:13:26.682691Z",
     "iopub.status.busy": "2025-05-30T13:13:26.682130Z",
     "iopub.status.idle": "2025-05-30T13:13:26.696094Z",
     "shell.execute_reply": "2025-05-30T13:13:26.695011Z",
     "shell.execute_reply.started": "2025-05-30T13:13:26.682655Z"
    }
   },
   "outputs": [],
   "source": [
    "def tree_train_step(model, dataloader, loss_fn, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_examples = 0\n",
    "\n",
    "    # Nota_1 Batch: anche se batch_size > 1, ogni albero viene processato individualmente.\n",
    "    # Questo approccio non è \"batchificato\" nel senso stretto (non sfrutta il parallelismo GPU).\n",
    "    # PyTorch DataLoader restituisce un batch di radici, ma il modello è invocato una volta per albero.   \n",
    "    # Questo perché gli alberi hanno struttura variabile e non possono essere impilati in un singolo tensore.\n",
    "\n",
    "    # Nota_2 Device: non mandiamo le radici (root) su device, perché non sono tensori PyTorch ma oggetti FormulaTreeNode.\n",
    "    # Il passaggio su device avviene all'interno del modello (es. embedding), quando servono veri tensori.\n",
    "    # root.to(device) darebbe errore, mentre x = embedding(torch.tensor(..., device=...)) è sicuro.\n",
    "    for roots, labels in dataloader:\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        batch_logits = []\n",
    "        for root in roots:\n",
    "            root_logits = model(root)                    # shape [1]\n",
    "            batch_logits.append(root_logits)\n",
    "\n",
    "        logits = torch.stack(batch_logits).squeeze(1)    # (after stach:) [batch_size, 1] -> (after squezze(1):) [batch_size]\n",
    "        preds = torch.round(torch.sigmoid(logits))\n",
    "\n",
    "        loss = loss_fn(logits, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_correct += (preds == labels).sum().item()\n",
    "        total_examples += len(labels)\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    accuracy = total_correct / total_examples\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "def tree_test_step(model, dataloader, loss_fn, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_examples = 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        # Nota_1 Batch: anche se batch_size > 1, ogni albero viene processato individualmente.\n",
    "        # Questo approccio non è \"batchificato\" nel senso stretto (non sfrutta il parallelismo GPU).\n",
    "        # PyTorch DataLoader restituisce un batch di radici, ma il modello è invocato una volta per albero.\n",
    "        # Questo perché gli alberi hanno struttura variabile e non possono essere impilati in un singolo tensore.\n",
    "\n",
    "        # Nota_2 Device: non mandiamo le radici (root) su device, perché non sono tensori PyTorch ma oggetti FormulaTreeNode.\n",
    "        # Il passaggio su device avviene all'interno del modello (es. embedding), quando servono veri tensori.\n",
    "        # root.to(device) darebbe errore, mentre x = embedding(torch.tensor(..., device=...)) è sicuro.\n",
    "        for roots, labels in dataloader:\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            batch_logits = []\n",
    "            for root in roots:\n",
    "                root_logits = model(root)                 # shape [1]\n",
    "                batch_logits.append(root_logits)\n",
    "\n",
    "            logits = torch.stack(batch_logits).squeeze(1) # (after stach:) [batch_size, 1] -> (after squezze(1):) [batch_size]\n",
    "            preds = torch.round(torch.sigmoid(logits))\n",
    "\n",
    "            loss = loss_fn(logits, labels)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total_correct += (preds == labels).sum().item()\n",
    "            total_examples += len(labels)\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    accuracy = total_correct / total_examples\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb35da9a-f9a0-4378-9914-0446a6b7cc1e",
   "metadata": {},
   "source": [
    "6.5. Ciclo di training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6f77dee0-c33e-4651-941c-50529af98a53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T13:13:29.897826Z",
     "iopub.status.busy": "2025-05-30T13:13:29.896916Z",
     "iopub.status.idle": "2025-05-30T13:13:29.906491Z",
     "shell.execute_reply": "2025-05-30T13:13:29.905190Z",
     "shell.execute_reply.started": "2025-05-30T13:13:29.897787Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_tree_lstm(model, train_loader, test_loader, loss_fn, optimizer, epochs, device):\n",
    "    results = {\"train_loss\": [], \"train_acc\": [], \"test_loss\": [], \"test_acc\": []}\n",
    "\n",
    "    for epoch in tqdm(range(epochs), desc=\"Training Epochs\"):\n",
    "        train_loss, train_acc = tree_train_step(model, train_loader, loss_fn, optimizer, device)\n",
    "        test_loss, test_acc = tree_test_step(model, test_loader, loss_fn, device)\n",
    "\n",
    "        print(f\"Epoch {epoch+1} |\"\n",
    "              f\"train_loss: {train_loss:.4f} |\"\n",
    "              f\"train_acc={train_acc:.4f} |\"\n",
    "              f\"test_loss={test_loss:.4f} |\"\n",
    "              f\"test_acc={test_acc:.4f}\"\n",
    "        )\n",
    "\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        results[\"test_loss\"].append(test_loss)\n",
    "        results[\"test_acc\"].append(test_acc)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11b1ba6-1796-4f90-bcee-0e437b6ee583",
   "metadata": {},
   "source": [
    "---\n",
    "### **6 WandB Sweep**\n",
    "\n",
    "Strategia modulare consigliata (3 step)\n",
    "\n",
    "STEP 1 — Ottimizzazione mirata del core (modello)\n",
    "Testa la combinazione:\n",
    "\n",
    "hidden_size ∈ [32, 64, 128]\n",
    "fc_size ∈ [16, 32, 64]\n",
    "embedding_dim = 32 (fisso, per ora)\n",
    "loss e lr = fissi (usa quelli del tuo modello base)\n",
    "Obiettivo: vedere se c’è un “collo di bottiglia” nella rete.\n",
    "\n",
    "STEP 2 — Ottimizzazione focal loss\n",
    "Fissa il modello (usa i migliori parametri del passaggio 1) e varia:\n",
    "\n",
    "alpha_pos ∈ [0.2, 0.4, 0.5]\n",
    "alpha_neg ∈ [0.6, 0.7, 0.8]\n",
    "gamma_pos ∈ [2.0, 3.0, 4.0]\n",
    "gamma_neg ∈ [1.0, 1.5, 2.0]\n",
    "Obiettivo: trovare il giusto equilibrio per classi sbilanciate.\n",
    "\n",
    "STEP 3 — Learning rate finetuning\n",
    "Blocca modello e loss ottimizzati, e varia:\n",
    "\n",
    "learning_rate ∈ [1e-4, 3e-4, 5e-4, 1e-3]\n",
    "Obiettivo: capire la sensibilità alla velocità di apprendimento.\n",
    "\n",
    "\n",
    "Dopo i 3 step\n",
    "\n",
    "Quando avrai:\n",
    "\n",
    "best_model_config\n",
    "best_loss_config\n",
    "best_lr\n",
    "puoi fare un mini-sweep combinato solo su queste 2–3 migliori combinazioni per confermare stabilità."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b53010-d631-4d1b-9f78-debb67b61414",
   "metadata": {},
   "source": [
    " **Sweep config — Step 1: modello (hidden e fc)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9ae11b3-0e85-4917-a0ad-855d4d10bfb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T10:21:28.036312Z",
     "iopub.status.busy": "2025-05-31T10:21:28.035826Z",
     "iopub.status.idle": "2025-05-31T10:21:28.065755Z",
     "shell.execute_reply": "2025-05-31T10:21:28.064469Z",
     "shell.execute_reply.started": "2025-05-31T10:21:28.036277Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>num_epochs</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>embedding_dim</th>\n",
       "      <th>hidden_size</th>\n",
       "      <th>fc_size</th>\n",
       "      <th>alpha_pos</th>\n",
       "      <th>alpha_neg</th>\n",
       "      <th>gamma_pos</th>\n",
       "      <th>gamma_neg</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TreeLSTM_h128_fc32</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.022615</td>\n",
       "      <td>0.921</td>\n",
       "      <td>0.024835</td>\n",
       "      <td>0.920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TreeLSTM_h128_fc64</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>64</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.023098</td>\n",
       "      <td>0.929</td>\n",
       "      <td>0.025563</td>\n",
       "      <td>0.920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TreeLSTM_h128_fc16</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.023888</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.026621</td>\n",
       "      <td>0.920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TreeLSTM_h64_fc64</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.025826</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.024889</td>\n",
       "      <td>0.915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TreeLSTM_h32_fc64</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.037759</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0.033304</td>\n",
       "      <td>0.895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TreeLSTM_h64_fc16</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>16</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.037697</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.033604</td>\n",
       "      <td>0.840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TreeLSTM_h64_fc32</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.036740</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.032706</td>\n",
       "      <td>0.760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TreeLSTM_h32_fc16</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.048183</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.044698</td>\n",
       "      <td>0.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TreeLSTM_h32_fc32</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.048044</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.045320</td>\n",
       "      <td>0.740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Name  num_epochs  learning_rate  embedding_dim  hidden_size  \\\n",
       "0  TreeLSTM_h128_fc32           5         0.0005             32          128   \n",
       "1  TreeLSTM_h128_fc64           5         0.0005             32          128   \n",
       "2  TreeLSTM_h128_fc16           5         0.0005             32          128   \n",
       "3   TreeLSTM_h64_fc64           5         0.0005             32           64   \n",
       "4   TreeLSTM_h32_fc64           5         0.0005             32           32   \n",
       "5   TreeLSTM_h64_fc16           5         0.0005             32           64   \n",
       "6   TreeLSTM_h64_fc32           5         0.0005             32           64   \n",
       "7   TreeLSTM_h32_fc16           5         0.0005             32           32   \n",
       "8   TreeLSTM_h32_fc32           5         0.0005             32           32   \n",
       "\n",
       "   fc_size  alpha_pos  alpha_neg  gamma_pos  gamma_neg  train_loss  train_acc  \\\n",
       "0       32        0.3        0.7          3        1.5    0.022615      0.921   \n",
       "1       64        0.3        0.7          3        1.5    0.023098      0.929   \n",
       "2       16        0.3        0.7          3        1.5    0.023888      0.928   \n",
       "3       64        0.3        0.7          3        1.5    0.025826      0.915   \n",
       "4       64        0.3        0.7          3        1.5    0.037759      0.789   \n",
       "5       16        0.3        0.7          3        1.5    0.037697      0.744   \n",
       "6       32        0.3        0.7          3        1.5    0.036740      0.740   \n",
       "7       16        0.3        0.7          3        1.5    0.048183      0.740   \n",
       "8       32        0.3        0.7          3        1.5    0.048044      0.740   \n",
       "\n",
       "   test_loss  test_acc  \n",
       "0   0.024835     0.920  \n",
       "1   0.025563     0.920  \n",
       "2   0.026621     0.920  \n",
       "3   0.024889     0.915  \n",
       "4   0.033304     0.895  \n",
       "5   0.033604     0.840  \n",
       "6   0.032706     0.760  \n",
       "7   0.044698     0.740  \n",
       "8   0.045320     0.740  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First Sweep results\n",
    "sweep_1_dataset = pd.read_csv(\"datasets/wandb_Sweep_1_TreeLSTM_hidden_states_fc_size.csv\")\n",
    "\n",
    "sweep_1_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01b54d00-288c-42e6-9f31-0ca154835e12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T10:12:10.189875Z",
     "iopub.status.busy": "2025-05-31T10:12:10.189357Z",
     "iopub.status.idle": "2025-05-31T10:12:10.207389Z",
     "shell.execute_reply": "2025-05-31T10:12:10.205940Z",
     "shell.execute_reply.started": "2025-05-31T10:12:10.189838Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hidden_size</th>\n",
       "      <th>fc_size</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>test_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.921</td>\n",
       "      <td>0.022615</td>\n",
       "      <td>0.024835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hidden_size  fc_size  test_acc  train_acc  train_loss  test_loss\n",
       "0          128       32      0.92      0.921    0.022615   0.024835"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best Configurations\n",
    "best_sweep_1_dataset = sweep_1_dataset.sort_values(\"test_acc\", ascending=False)\n",
    "best_sweep_1_dataset[[\"hidden_size\", \"fc_size\", \"test_acc\", \"train_acc\", \"train_loss\", \"test_loss\"]].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b3d876a-bf21-4b7c-875d-607015a15ce3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T10:12:11.151236Z",
     "iopub.status.busy": "2025-05-31T10:12:11.150738Z",
     "iopub.status.idle": "2025-05-31T10:12:11.159031Z",
     "shell.execute_reply": "2025-05-31T10:12:11.157539Z",
     "shell.execute_reply.started": "2025-05-31T10:12:11.151199Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best conf. hidden states: 128\n",
      "Best conf. fully conn. layers: 32\n"
     ]
    }
   ],
   "source": [
    "best_config_sweep_1 = best_sweep_1_dataset.iloc[0]  # first row, best run\n",
    "best_hidden_sweep_1 = best_config_sweep_1[\"hidden_size\"]\n",
    "best_fc_sweep_1 = best_config_sweep_1[\"fc_size\"]\n",
    "\n",
    "print(f\"Best conf. hidden states: {best_hidden_sweep_1}\"\n",
    "      f\"\\nBest conf. fully conn. layers: {best_fc_sweep_1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb3577f-b67e-414e-a931-e202e0e9002d",
   "metadata": {},
   "source": [
    "**Sweep config — Step 2: alpha_pos, alpha_neg, gamma_pos, gamma_neg**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "311ee464-7541-4d12-86ab-90a1b0e2ee02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T22:09:47.014745Z",
     "iopub.status.busy": "2025-06-02T22:09:47.012818Z",
     "iopub.status.idle": "2025-06-02T22:09:47.306808Z",
     "shell.execute_reply": "2025-06-02T22:09:47.304905Z",
     "shell.execute_reply.started": "2025-06-02T22:09:47.014654Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Second Sweep results\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m sweep_2_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatasets/wandb_Sweep_2_TreeLSTM_alpha_gamma.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m sweep_2_dataset\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Second Sweep results\n",
    "sweep_2_dataset = pd.read_csv(\"datasets/wandb_Sweep_2_TreeLSTM_alpha_gamma.csv\")\n",
    "\n",
    "sweep_2_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87e66e4b-9721-4248-ba04-6a2523bd5597",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T10:32:54.818773Z",
     "iopub.status.busy": "2025-05-31T10:32:54.818290Z",
     "iopub.status.idle": "2025-05-31T10:32:54.836520Z",
     "shell.execute_reply": "2025-05-31T10:32:54.835663Z",
     "shell.execute_reply.started": "2025-05-31T10:32:54.818740Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha_pos</th>\n",
       "      <th>alpha_neg</th>\n",
       "      <th>gamma_pos</th>\n",
       "      <th>gamma_neg</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.70</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.011988</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.015430</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.65</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.014446</td>\n",
       "      <td>0.938</td>\n",
       "      <td>0.016611</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.65</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.019334</td>\n",
       "      <td>0.929</td>\n",
       "      <td>0.023019</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alpha_pos  alpha_neg  gamma_pos  gamma_neg  train_loss  train_acc  \\\n",
       "4       0.25       0.70        3.0        2.5    0.011988      0.930   \n",
       "5       0.35       0.65        3.0        2.5    0.014446      0.938   \n",
       "0       0.30       0.65        3.5        1.5    0.019334      0.929   \n",
       "\n",
       "   test_loss  test_acc  \n",
       "4   0.015430      0.93  \n",
       "5   0.016611      0.93  \n",
       "0   0.023019      0.93  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ordering by test_acc in decreasing order and, if test_acc is the same, for test_loss in increasing order\n",
    "best_sweep_2_dataset = sweep_2_dataset.sort_values(by=[\"test_acc\", \"test_loss\"], ascending=[False, True])\n",
    "best_sweep_2_dataset[[\"alpha_pos\", \"alpha_neg\", \"gamma_pos\", \"gamma_neg\", \"train_loss\", \"train_acc\", \"test_loss\", \"test_acc\"]].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "377819c8-2031-4498-bbc7-4d26fbe24f3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T10:38:35.119280Z",
     "iopub.status.busy": "2025-05-31T10:38:35.118803Z",
     "iopub.status.idle": "2025-05-31T10:38:35.127841Z",
     "shell.execute_reply": "2025-05-31T10:38:35.126361Z",
     "shell.execute_reply.started": "2025-05-31T10:38:35.119237Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best conf. alpha pos: 0.25\n",
      "Best conf. alpha neg: 0.7\n",
      "\n",
      "Best conf. gamma pos: 3.0\n",
      "Best conf. gamma neg: 2.5\n"
     ]
    }
   ],
   "source": [
    "best_config_sweep_2 = best_sweep_2_dataset.iloc[0]  # first row, best run\n",
    "\n",
    "best_alpha_pos_sweep_2 = best_config_sweep_2[\"alpha_pos\"]\n",
    "best_alpha_neg_sweep_2 = best_config_sweep_2[\"alpha_neg\"]\n",
    "\n",
    "best_gamma_pos_sweep_2 = best_config_sweep_2[\"gamma_pos\"]\n",
    "best_gamma_neg_sweep_2 = best_config_sweep_2[\"gamma_neg\"]\n",
    "\n",
    "\n",
    "print(f\"Best conf. alpha pos: {best_alpha_pos_sweep_2}\"\n",
    "      f\"\\nBest conf. alpha neg: {best_alpha_neg_sweep_2}\"\n",
    "      f\"\\n\\nBest conf. gamma pos: {best_gamma_pos_sweep_2}\"\n",
    "      f\"\\nBest conf. gamma neg: {best_gamma_neg_sweep_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d2714a-5d3e-4484-88a3-6cb469309d87",
   "metadata": {},
   "source": [
    "**Sweep config — Step 3: learning_rate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d0da0dc-126e-41f2-9a5b-3beb008a6444",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T12:46:29.459592Z",
     "iopub.status.busy": "2025-05-31T12:46:29.458396Z",
     "iopub.status.idle": "2025-05-31T12:46:29.493471Z",
     "shell.execute_reply": "2025-05-31T12:46:29.492225Z",
     "shell.execute_reply.started": "2025-05-31T12:46:29.459543Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>num_epochs</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>embedding_dim</th>\n",
       "      <th>hidden_size</th>\n",
       "      <th>fc_size</th>\n",
       "      <th>alpha_pos</th>\n",
       "      <th>alpha_neg</th>\n",
       "      <th>gamma_pos</th>\n",
       "      <th>gamma_neg</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TreeLSTM_h128_fc32</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.009835</td>\n",
       "      <td>0.943</td>\n",
       "      <td>0.011230</td>\n",
       "      <td>0.930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TreeLSTM_h128_fc32</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.010163</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.012574</td>\n",
       "      <td>0.930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TreeLSTM_h128_fc32</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.011897</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.014662</td>\n",
       "      <td>0.925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TreeLSTM_h128_fc32</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.010608</td>\n",
       "      <td>0.937</td>\n",
       "      <td>0.012560</td>\n",
       "      <td>0.925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TreeLSTM_h128_fc32</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.013062</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.015351</td>\n",
       "      <td>0.920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TreeLSTM_h128_fc32</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.011169</td>\n",
       "      <td>0.934</td>\n",
       "      <td>0.012204</td>\n",
       "      <td>0.920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TreeLSTM_h128_fc32</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.017525</td>\n",
       "      <td>0.908</td>\n",
       "      <td>0.016790</td>\n",
       "      <td>0.915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TreeLSTM_h128_fc32</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.022405</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.020852</td>\n",
       "      <td>0.785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TreeLSTM_h128_fc32</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.028553</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.027474</td>\n",
       "      <td>0.740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Name  num_epochs  learning_rate  embedding_dim  hidden_size  \\\n",
       "0  TreeLSTM_h128_fc32           5         0.0009             32          128   \n",
       "1  TreeLSTM_h128_fc32           5         0.0007             32          128   \n",
       "2  TreeLSTM_h128_fc32           5         0.0004             32          128   \n",
       "3  TreeLSTM_h128_fc32           5         0.0006             32          128   \n",
       "4  TreeLSTM_h128_fc32           5         0.0005             32          128   \n",
       "5  TreeLSTM_h128_fc32           5         0.0008             32          128   \n",
       "6  TreeLSTM_h128_fc32           5         0.0003             32          128   \n",
       "7  TreeLSTM_h128_fc32           5         0.0002             32          128   \n",
       "8  TreeLSTM_h128_fc32           5         0.0001             32          128   \n",
       "\n",
       "   fc_size  alpha_pos  alpha_neg  gamma_pos  gamma_neg  train_loss  train_acc  \\\n",
       "0       32       0.25        0.7          3        2.5    0.009835      0.943   \n",
       "1       32       0.25        0.7          3        2.5    0.010163      0.941   \n",
       "2       32       0.25        0.7          3        2.5    0.011897      0.933   \n",
       "3       32       0.25        0.7          3        2.5    0.010608      0.937   \n",
       "4       32       0.25        0.7          3        2.5    0.013062      0.930   \n",
       "5       32       0.25        0.7          3        2.5    0.011169      0.934   \n",
       "6       32       0.25        0.7          3        2.5    0.017525      0.908   \n",
       "7       32       0.25        0.7          3        2.5    0.022405      0.740   \n",
       "8       32       0.25        0.7          3        2.5    0.028553      0.740   \n",
       "\n",
       "   test_loss  test_acc  \n",
       "0   0.011230     0.930  \n",
       "1   0.012574     0.930  \n",
       "2   0.014662     0.925  \n",
       "3   0.012560     0.925  \n",
       "4   0.015351     0.920  \n",
       "5   0.012204     0.920  \n",
       "6   0.016790     0.915  \n",
       "7   0.020852     0.785  \n",
       "8   0.027474     0.740  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Third Sweep results\n",
    "sweep_3_dataset = pd.read_csv(\"datasets/wandb_Sweep_3_TreeLSTM_lr.csv\")\n",
    "\n",
    "sweep_3_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4961798a-6de5-498e-be2d-6fda252272d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T12:48:09.136688Z",
     "iopub.status.busy": "2025-05-31T12:48:09.136196Z",
     "iopub.status.idle": "2025-05-31T12:48:09.162051Z",
     "shell.execute_reply": "2025-05-31T12:48:09.160547Z",
     "shell.execute_reply.started": "2025-05-31T12:48:09.136653Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>alpha_pos</th>\n",
       "      <th>alpha_neg</th>\n",
       "      <th>gamma_pos</th>\n",
       "      <th>gamma_neg</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.009835</td>\n",
       "      <td>0.943</td>\n",
       "      <td>0.011230</td>\n",
       "      <td>0.930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.010163</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.012574</td>\n",
       "      <td>0.930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.010608</td>\n",
       "      <td>0.937</td>\n",
       "      <td>0.012560</td>\n",
       "      <td>0.925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   learning_rate  alpha_pos  alpha_neg  gamma_pos  gamma_neg  train_loss  \\\n",
       "0         0.0009       0.25        0.7          3        2.5    0.009835   \n",
       "1         0.0007       0.25        0.7          3        2.5    0.010163   \n",
       "3         0.0006       0.25        0.7          3        2.5    0.010608   \n",
       "\n",
       "   train_acc  test_loss  test_acc  \n",
       "0      0.943   0.011230     0.930  \n",
       "1      0.941   0.012574     0.930  \n",
       "3      0.937   0.012560     0.925  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ordering by test_acc in decreasing order and, if test_acc is the same, for test_loss in increasing order\n",
    "best_sweep_3_dataset = sweep_3_dataset.sort_values(by=[\"test_acc\", \"test_loss\"], ascending=[False, True])\n",
    "best_sweep_3_dataset[[\"learning_rate\", \"alpha_pos\", \"alpha_neg\", \"gamma_pos\", \"gamma_neg\", \"train_loss\", \"train_acc\", \"test_loss\", \"test_acc\"]].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69571f8b-847b-483a-9086-a71fcbb33206",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T12:51:41.458779Z",
     "iopub.status.busy": "2025-05-31T12:51:41.458219Z",
     "iopub.status.idle": "2025-05-31T12:51:41.467417Z",
     "shell.execute_reply": "2025-05-31T12:51:41.466221Z",
     "shell.execute_reply.started": "2025-05-31T12:51:41.458743Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final best hyperparameters congigration: \n",
      "\n",
      "- Best conf. learning rate: 0.0009\n",
      "\n",
      "- Best conf. alpha pos: 0.25\n",
      "- Best conf. alpha neg: 0.7\n",
      "\n",
      "- Best conf. gamma pos: 3\n",
      "- Best conf. gamma neg: 2.5\n"
     ]
    }
   ],
   "source": [
    "best_config_sweep_3 = best_sweep_3_dataset.iloc[0]  # first row, best run\n",
    "\n",
    "best_lr_sweep_3 = best_config_sweep_3[\"learning_rate\"]\n",
    "\n",
    "best_alpha_pos_sweep_3 = best_config_sweep_3[\"alpha_pos\"]\n",
    "best_alpha_neg_sweep_3 = best_config_sweep_3[\"alpha_neg\"]\n",
    "\n",
    "best_gamma_pos_sweep_3 = best_config_sweep_3[\"gamma_pos\"]\n",
    "best_gamma_neg_sweep_3 = best_config_sweep_3[\"gamma_neg\"]\n",
    "\n",
    "print(\"Final best hyperparameters congigration: \\n\")\n",
    "print(f\"- Best conf. learning rate: {best_lr_sweep_3}\"\n",
    "      f\"\\n\\n- Best conf. alpha pos: {best_alpha_pos_sweep_3}\"\n",
    "      f\"\\n- Best conf. alpha neg: {best_alpha_neg_sweep_3}\"\n",
    "      f\"\\n\\n- Best conf. gamma pos: {best_gamma_pos_sweep_3}\"\n",
    "      f\"\\n- Best conf. gamma neg: {best_gamma_neg_sweep_3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba3d1f2-94c7-4920-a095-c91ca5bb44d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eea8557d-b544-47da-98c3-39d3bd685908",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadc95c8-db1e-49c0-a84c-dc222f423eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allenamento e Test su tutto il datset con best Hyperparameters \n",
    "def prepare_tree_dataset(dataset: pd.DataFrame,\n",
    "                         test_size: float,\n",
    "                         batch_size: int,\n",
    "                         tokenizer: CustomTokenizer,\n",
    "                         seed: int = 42):\n",
    "    \"\"\"\n",
    "    Prepara dataloader per TreeLSTM usando tutto il dataset, con eventuale split train/test.\n",
    "\n",
    "    Args:\n",
    "        dataset (pd.DataFrame): contiene colonne 'formula' e 'is_tautology'\n",
    "        test_size (float): proporzione di dati da usare per il test\n",
    "        batch_size (int): dimensione dei batch\n",
    "        tokenizer (CustomTokenizer): tokenizer già fittato\n",
    "        seed (int): seme per riproducibilità\n",
    "\n",
    "    Returns:\n",
    "        train_loader, test_loader: DataLoader PyTorch\n",
    "    \"\"\"\n",
    "    assert \"formula\" in dataset.columns and \"is_tautology\" in dataset.columns\n",
    "\n",
    "    # Parsing delle formule\n",
    "    formulas = [parse_formula_string(f) for f in dataset[\"formula\"]]\n",
    "    labels = dataset[\"is_tautology\"].tolist()\n",
    "\n",
    "    # Split train/test\n",
    "    train_formulas, test_formulas, train_labels, test_labels = train_test_split(\n",
    "        formulas, labels, test_size=test_size, random_state=seed\n",
    "    )\n",
    "\n",
    "    # Dataset PyTorch\n",
    "    train_dataset = TreeFormulaDataset(train_formulas, train_labels, tokenizer)\n",
    "    test_dataset = TreeFormulaDataset(test_formulas, test_labels, tokenizer)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, collate_fn=tree_collate_fn\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset, batch_size=batch_size, shuffle=False, collate_fn=tree_collate_fn\n",
    "    )\n",
    "\n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- Tokenizer ---\n",
    "tokenizer = CustomTokenizer()\n",
    "tokenizer.fit([parse_formula_string(f) for f in dataset[\"formula\"]])\n",
    "\n",
    "# --- Tree train and Tree test sets ---\n",
    "tree_train_loader, tree_test_loader = prepare_tree_dataset(\n",
    "    dataset=dataset,\n",
    "    test_size=0.2,\n",
    "    batch_size=2,\n",
    "    tokenizer=tokenizer,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919c07fb-ac0e-4518-8e89-6c11f8abe17d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ce1811c-6452-4b69-97ca-76196d19327a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40cf0f0-2cc4-4646-83c1-91a3d3bf849f",
   "metadata": {},
   "source": [
    "Definizione del modello TreeLSTMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b3b8f96e-10e2-4955-923a-c7e94cddbf0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T20:28:48.106863Z",
     "iopub.status.busy": "2025-05-29T20:28:48.106492Z",
     "iopub.status.idle": "2025-05-29T20:28:48.118086Z",
     "shell.execute_reply": "2025-05-29T20:28:48.116876Z",
     "shell.execute_reply.started": "2025-05-29T20:28:48.106830Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TreeLSTMClassifier(\n",
       "  (encoder): TreeLSTMEncoder(\n",
       "    (embedding): Embedding(108, 32, padding_idx=0)\n",
       "    (cell): BinaryTreeLSTMCell(\n",
       "      (W_iou): Linear(in_features=32, out_features=192, bias=True)\n",
       "      (U_iou): Linear(in_features=128, out_features=192, bias=True)\n",
       "      (W_f): Linear(in_features=32, out_features=128, bias=True)\n",
       "      (U_f): Linear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (fc1): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EMBEDDING_DIM = 32\n",
    "HIDDEN_SIZE = 64\n",
    "\n",
    "tree_model = TreeLSTMClassifier(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    hidden_size=HIDDEN_SIZE\n",
    ").to(device)\n",
    "\n",
    "tree_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0901e957-57aa-48a1-ac35-377983b918ca",
   "metadata": {},
   "source": [
    "Loss e Ottimizzatore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d5cfc31b-5856-4a09-a96f-91c0839d31eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T20:28:48.120211Z",
     "iopub.status.busy": "2025-05-29T20:28:48.119861Z",
     "iopub.status.idle": "2025-05-29T20:28:48.126266Z",
     "shell.execute_reply": "2025-05-29T20:28:48.124885Z",
     "shell.execute_reply.started": "2025-05-29T20:28:48.120180Z"
    }
   },
   "outputs": [],
   "source": [
    "loss_fn = AsymmetricFocalLoss(\n",
    "    alpha_pos=0.3,  # minority class (tautology)\n",
    "    alpha_neg=0.7,  # majority class\n",
    "    gamma_pos=3.0,\n",
    "    gamma_neg=1.5\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(tree_model.parameters(), lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2e0889c1-0c9d-4dda-b30f-2c0df6fe5efa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T20:28:48.128925Z",
     "iopub.status.busy": "2025-05-29T20:28:48.128115Z",
     "iopub.status.idle": "2025-05-29T21:15:46.829503Z",
     "shell.execute_reply": "2025-05-29T21:15:46.827863Z",
     "shell.execute_reply.started": "2025-05-29T20:28:48.128877Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33e85ab990ff43508b54cdf065079f80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=0.0195, train_acc=0.9271, test_loss=0.0141, test_acc=0.9423\n",
      "Epoch 2: train_loss=0.0106, train_acc=0.9613, test_loss=0.0122, test_acc=0.9708\n",
      "Epoch 3: train_loss=0.0087, train_acc=0.9673, test_loss=0.0085, test_acc=0.9742\n",
      "Epoch 4: train_loss=0.0066, train_acc=0.9727, test_loss=0.0092, test_acc=0.9608\n",
      "Epoch 5: train_loss=0.0047, train_acc=0.9807, test_loss=0.0057, test_acc=0.9804\n"
     ]
    }
   ],
   "source": [
    "set_seeds()\n",
    "tree_lstm_results = train_tree_lstm(\n",
    "    model=tree_model,\n",
    "    train_loader=tree_train_loader,\n",
    "    test_loader=tree_test_loader,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    epochs=5,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b2cb2b20-e383-4ce3-b16a-3f204be0862d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T21:16:55.426253Z",
     "iopub.status.busy": "2025-05-29T21:16:55.424536Z",
     "iopub.status.idle": "2025-05-29T21:16:55.435965Z",
     "shell.execute_reply": "2025-05-29T21:16:55.434634Z",
     "shell.execute_reply.started": "2025-05-29T21:16:55.426209Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Results saved to: models_results/Tree_lstm_results.csv\n"
     ]
    }
   ],
   "source": [
    "save_results(tree_lstm_results, target_dir=\"models_results\", filename=\"Tree_lstm_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "32ec748b-c01b-413b-8cd1-18a55cc8a0ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T21:18:50.497720Z",
     "iopub.status.busy": "2025-05-29T21:18:50.496649Z",
     "iopub.status.idle": "2025-05-29T21:18:50.510230Z",
     "shell.execute_reply": "2025-05-29T21:18:50.508924Z",
     "shell.execute_reply.started": "2025-05-29T21:18:50.497681Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saving model to: models/Tree_lstm.pth\n"
     ]
    }
   ],
   "source": [
    "save_model(model=tree_model,\n",
    "           target_dir=\"models\",\n",
    "           model_name=\"Tree_lstm.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de24769-90a3-4d31-a580-e65512f0717b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "805dfc1b-8844-4c02-abb4-5ae3fa39dc0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T21:26:59.593889Z",
     "iopub.status.busy": "2025-05-29T21:26:59.593371Z",
     "iopub.status.idle": "2025-05-29T21:26:59.604813Z",
     "shell.execute_reply": "2025-05-29T21:26:59.603875Z",
     "shell.execute_reply.started": "2025-05-29T21:26:59.593853Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "22a6a352-377e-4492-8ac9-4d820a436612",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T21:27:22.657991Z",
     "iopub.status.busy": "2025-05-29T21:27:22.657571Z",
     "iopub.status.idle": "2025-05-29T21:27:22.664431Z",
     "shell.execute_reply": "2025-05-29T21:27:22.663336Z",
     "shell.execute_reply.started": "2025-05-29T21:27:22.657959Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17f612b2-5826-4682-95dc-06afe7e7fd09",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3bd9522c-6855-482d-83b5-1c66e98d3269",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T09:05:47.747037Z",
     "iopub.status.busy": "2025-05-30T09:05:47.746484Z",
     "iopub.status.idle": "2025-05-30T09:05:47.754170Z",
     "shell.execute_reply": "2025-05-30T09:05:47.753023Z",
     "shell.execute_reply.started": "2025-05-30T09:05:47.747000Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b4ef8f-d4f5-4add-a056-fb21fec93623",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
