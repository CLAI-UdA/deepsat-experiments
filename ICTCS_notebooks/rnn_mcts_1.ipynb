{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a93d507",
   "metadata": {},
   "source": [
    "### **Part 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa3497b",
   "metadata": {},
   "source": [
    "---\n",
    "#### **1.1 Import Formula Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce4ce81f-d592-4eb6-a4a4-61bce0a79a47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T18:23:56.080403Z",
     "iopub.status.busy": "2025-05-29T18:23:56.079959Z",
     "iopub.status.idle": "2025-05-29T18:24:01.188219Z",
     "shell.execute_reply": "2025-05-29T18:24:01.186958Z",
     "shell.execute_reply.started": "2025-05-29T18:23:56.080367Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import torch\n",
    "except:\n",
    "    print(\"[INFO] Couldn't find torch... installing it.\")\n",
    "    !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "    import torch\n",
    "\n",
    "try:\n",
    "    import torchmetrics\n",
    "except:\n",
    "    print(\"[INFO] Couldn't find torchmetrics... installing it.\")\n",
    "    !pip install torchmetrics\n",
    "    import torchmetrics\n",
    "\n",
    "try:\n",
    "    import torchinfo\n",
    "except:\n",
    "    print(\"[INFO] Couldn't find torchinfo... installing it.\")\n",
    "    !pip install torchinfo\n",
    "    import torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b707017",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T18:24:01.192765Z",
     "iopub.status.busy": "2025-05-29T18:24:01.191513Z",
     "iopub.status.idle": "2025-05-29T18:24:01.829418Z",
     "shell.execute_reply": "2025-05-29T18:24:01.828134Z",
     "shell.execute_reply.started": "2025-05-29T18:24:01.192726Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "from typing import Dict, Tuple, List, Set, Union, Type, Literal\n",
    "from itertools import product\n",
    "from dataclasses import dataclass\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchmetrics import Accuracy\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchinfo import summary\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "209bc5fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T18:24:01.831723Z",
     "iopub.status.busy": "2025-05-29T18:24:01.831203Z",
     "iopub.status.idle": "2025-05-29T18:24:01.843602Z",
     "shell.execute_reply": "2025-05-29T18:24:01.842072Z",
     "shell.execute_reply.started": "2025-05-29T18:24:01.831679Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Importing Formula Class ---\n",
    "# Go two levels up: from ICTCS_notebooks → theorem_prover_core → project root\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"..\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from theorem_prover_core.formula import (Formula, Letter, Falsity, Conjunction, Disjunction, Implication,\n",
    "                                         Negation, BinaryConnectiveFormula, UnaryConnectiveFormula, bottom)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e8bd1a",
   "metadata": {},
   "source": [
    "---\n",
    "#### **1.2 Truth Assignment function and Normalization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aed176b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T18:24:01.846757Z",
     "iopub.status.busy": "2025-05-29T18:24:01.846394Z",
     "iopub.status.idle": "2025-05-29T18:24:01.855383Z",
     "shell.execute_reply": "2025-05-29T18:24:01.854104Z",
     "shell.execute_reply.started": "2025-05-29T18:24:01.846727Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random truth values assigned to P1 and P2: {0: True, 1: True}\n"
     ]
    }
   ],
   "source": [
    "# --- Truth Assignment Function ---\n",
    "# Generate random truth values for letters\n",
    "def truth_assignment(letters: int, seed: int) -> Dict[int, bool]:\n",
    "    \"\"\"\n",
    "    Randomly assigns True or False to each propositional letter in a formula.\n",
    "\n",
    "    Args:\n",
    "        letters (int): An integer that represents the number of propositional letters \n",
    "    \n",
    "    Returns: \n",
    "        Dict[int, bool]: A dictonary where keys are integers representing the propositional \n",
    "        letters, and values are booleans (True or False), representing the truth value \n",
    "        assigned to each variable.\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        random.seed(seed)\n",
    "    return {i: random.choice([True, False]) for i in range(letters)}\n",
    "\n",
    "\n",
    "# Example: \n",
    "n_letters = 2 \n",
    "values = truth_assignment(n_letters, seed=42)\n",
    "print(f\"Random truth values assigned to P1 and P2: {values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64020ab0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T18:24:01.857358Z",
     "iopub.status.busy": "2025-05-29T18:24:01.857051Z",
     "iopub.status.idle": "2025-05-29T18:24:01.868842Z",
     "shell.execute_reply": "2025-05-29T18:24:01.867480Z",
     "shell.execute_reply.started": "2025-05-29T18:24:01.857330Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truth value of the composed formula: A1 ∧ A2 → A3, where A1=True, A2=False, and A3=True: \n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# --- Evaluate the truth value of a formula ---\n",
    "def evaluate_formula(formula: Formula, truth_assignment: Dict[int, bool]) -> bool:\n",
    "    \"\"\"\n",
    "    Evaluates the truth value of a formula using the given truth assignment \n",
    "    for propositional letters.\n",
    "\n",
    "    Args: \n",
    "        formula: The propositional formula to evaluate.\n",
    "        truth_assignment: A dictionary with the propositional letters values.\n",
    "    \n",
    "    Returns: \n",
    "        bool: A truth value.\n",
    "    \"\"\"\n",
    "    if isinstance(formula, Letter):\n",
    "        return truth_assignment[formula.n]\n",
    "    elif isinstance(formula, Falsity):\n",
    "        return False\n",
    "    elif isinstance(formula, Negation):\n",
    "        return not evaluate_formula(formula.formula, truth_assignment)\n",
    "    elif isinstance(formula, Conjunction):\n",
    "        return evaluate_formula(formula.left, truth_assignment) and evaluate_formula(formula.right, truth_assignment)\n",
    "    elif isinstance(formula, Disjunction):\n",
    "        return evaluate_formula(formula.left, truth_assignment) or evaluate_formula(formula.right, truth_assignment)\n",
    "    #elif isinstance(formula, ExclusiveDisjunction):\n",
    "    #    return evaluate_formula(formula.left, truth_assignment) != evaluate_formula(formula.right, truth_assignment)\n",
    "    elif isinstance(formula, Implication):\n",
    "        return not evaluate_formula(formula.left, truth_assignment) or evaluate_formula(formula.right, truth_assignment)\n",
    "    else:\n",
    "        raise Exception(\"Unknown formula type\")\n",
    "\n",
    "# Example: \n",
    "A1 = Letter(1)\n",
    "A2 = Letter(2)\n",
    "A3 = Letter(3)\n",
    "conjunction = Conjunction(A1, A2)\n",
    "implication = Implication(conjunction, A3)\n",
    "truth_assignment = {1: True, 2: False, 3: True}\n",
    "\n",
    "# Evaluate the formula\n",
    "result = evaluate_formula(implication, truth_assignment)\n",
    "\n",
    "values_list = list(truth_assignment.values())\n",
    "print(f\"Truth value of the composed formula: {implication}, where A1={values_list[0]},\"\n",
    "      f\" A2={values_list[1]}, and A3={values_list[2]}: \\n{result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04d9ddf3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T18:24:01.870667Z",
     "iopub.status.busy": "2025-05-29T18:24:01.870342Z",
     "iopub.status.idle": "2025-05-29T18:24:01.879518Z",
     "shell.execute_reply": "2025-05-29T18:24:01.878214Z",
     "shell.execute_reply.started": "2025-05-29T18:24:01.870637Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices of propositional variables in the formula: A1 ∧ A2 → A3: {1, 2, 3}\n"
     ]
    }
   ],
   "source": [
    "# --- Derive letters from a given formula ---\n",
    "def derive_letters(formula: Formula) -> Set[int]:\n",
    "    \"\"\"\n",
    "    Recursively derives the set of propositional letters (by their index) in the given formula.\n",
    "       \n",
    "    Args: \n",
    "        formula: A propositional formula.\n",
    "       \n",
    "    Returns: \n",
    "        A set of letters indices. \n",
    "    \"\"\"\n",
    "    if isinstance(formula, Letter):\n",
    "        return {formula.n}\n",
    "    elif isinstance(formula, Falsity):\n",
    "        return set()\n",
    "    elif isinstance(formula, UnaryConnectiveFormula):\n",
    "        return derive_letters(formula.formula)\n",
    "    elif isinstance(formula, BinaryConnectiveFormula):\n",
    "        left_letters = derive_letters(formula.left)\n",
    "        right_letters = derive_letters(formula.right)\n",
    "        return left_letters.union(right_letters)\n",
    "    else:\n",
    "        raise Exception(\"Unknown formula type\")\n",
    "\n",
    "print(f\"Indices of propositional variables in the formula: {implication}:\"\n",
    "      f\" {derive_letters(implication)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d4ea11a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T18:24:01.881424Z",
     "iopub.status.busy": "2025-05-29T18:24:01.881134Z",
     "iopub.status.idle": "2025-05-29T18:24:01.889412Z",
     "shell.execute_reply": "2025-05-29T18:24:01.888174Z",
     "shell.execute_reply.started": "2025-05-29T18:24:01.881396Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the formula A1 ∧ A2 → A3 a tautology? False\n",
      "Is the formula A1 ∨ ¬A1 a tautology? True\n"
     ]
    }
   ],
   "source": [
    "# --- Check tautology status of a given formula ---\n",
    "def is_tautology(formula: Formula) -> bool:\n",
    "    \"\"\"\n",
    "    Checks if a given formula is a tautology.\n",
    "\n",
    "    Args: \n",
    "        formula: A propositional formula.\n",
    "       \n",
    "    Returns: \n",
    "        bool: The tautology status (True or False).\n",
    "    \"\"\"\n",
    "    letters = derive_letters(formula)\n",
    "    num_letters = len(letters)\n",
    "\n",
    "    for values in product([False, True], repeat=num_letters):\n",
    "        assignment = dict(zip(sorted(letters), values))\n",
    "        if not evaluate_formula(formula, assignment):\n",
    "            return False\n",
    "\n",
    "    return True\n",
    "\n",
    "# Example\n",
    "print(f\"Is the formula {implication} a tautology? {is_tautology(implication)}\")\n",
    "taut = Disjunction(A1, Negation(A1))\n",
    "print(f\"Is the formula {taut} a tautology? {is_tautology(taut)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "979ec5b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T18:24:01.891531Z",
     "iopub.status.busy": "2025-05-29T18:24:01.891050Z",
     "iopub.status.idle": "2025-05-29T18:24:01.898232Z",
     "shell.execute_reply": "2025-05-29T18:24:01.897130Z",
     "shell.execute_reply.started": "2025-05-29T18:24:01.891500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A0\n",
      "A1\n",
      "A2\n",
      "A3\n",
      "A4\n",
      "A5\n",
      "A6\n",
      "A0\n",
      "A1\n",
      "A2\n"
     ]
    }
   ],
   "source": [
    "# --- Generator of letter sequence ---\n",
    "def generate_letter_sequence(num_letters: int) -> None:\n",
    "    \"\"\"\"\n",
    "    Generate sequence of letter wrapping around when reaching \n",
    "    the max number of letters.\n",
    "\n",
    "    Args:\n",
    "        num_letters (int): Number of total propositional letters to generate.\n",
    "    \"\"\"\n",
    "    current_letter = 0\n",
    "    while True:\n",
    "        yield Letter(current_letter)\n",
    "        current_letter += 1\n",
    "        if current_letter > num_letters:\n",
    "            current_letter = 0  \n",
    "\n",
    "# Example \n",
    "letter_generator = generate_letter_sequence(num_letters=6)\n",
    "for _ in range(10):\n",
    "    print(next(letter_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "262a23d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T18:24:01.900143Z",
     "iopub.status.busy": "2025-05-29T18:24:01.899815Z",
     "iopub.status.idle": "2025-05-29T18:24:01.913006Z",
     "shell.execute_reply": "2025-05-29T18:24:01.911726Z",
     "shell.execute_reply.started": "2025-05-29T18:24:01.900108Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not normalized formula: A3 ∧ A2 → A5 ∨ A3\n",
      "Normalized formula: A0 ∧ A1 → A2 ∨ A0\n"
     ]
    }
   ],
   "source": [
    "class Normalizer:\n",
    "    \"\"\"\n",
    "    This class is used to normalize formulas before use them as input.\n",
    "    Normalization maintains letter consistency, ensuring that the same propositional \n",
    "    letter could appears with the same index throughout the formula.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.__dict_letters = {}\n",
    "        self.__last_letter = 0\n",
    "\n",
    "    def normalize(self, data: Formula) -> Formula:\n",
    "        if isinstance(data, Letter):\n",
    "            # If the letter has already been encountered, use the same normalized index\n",
    "            n = data.n\n",
    "            if n not in self.__dict_letters:\n",
    "                # Assign a new letter if it hasn't been seen before\n",
    "                self.__dict_letters[n] = self.__last_letter\n",
    "                self.__last_letter += 1\n",
    "            # Return the letter with its normalized index\n",
    "            return Letter(self.__dict_letters[n])\n",
    "\n",
    "        elif isinstance(data, Falsity):\n",
    "            return Falsity()\n",
    "\n",
    "        elif isinstance(data, UnaryConnectiveFormula):\n",
    "            formula = self.normalize(data.formula)\n",
    "            return data.__class__(formula)\n",
    "\n",
    "        elif isinstance(data, BinaryConnectiveFormula):\n",
    "            left = self.normalize(data.left)\n",
    "            right = self.normalize(data.right)\n",
    "            return data.__class__(left, right)\n",
    "\n",
    "        else:\n",
    "            raise Exception(\"Unknown formula type\")\n",
    "\n",
    "# Example\n",
    "formula = Implication(Conjunction(Letter(3), Letter(2)), Disjunction(Letter(5), Letter(3)))\n",
    "print(f\"Not normalized formula: {formula}\")\n",
    "\n",
    "normalizer = Normalizer()\n",
    "normalized_formula = normalizer.normalize(formula)\n",
    "print(f\"Normalized formula: {normalized_formula}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14cd56e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T18:24:01.918044Z",
     "iopub.status.busy": "2025-05-29T18:24:01.917655Z",
     "iopub.status.idle": "2025-05-29T18:24:01.929817Z",
     "shell.execute_reply": "2025-05-29T18:24:01.928419Z",
     "shell.execute_reply.started": "2025-05-29T18:24:01.918012Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(A0 ∧ A1) ∨ A2 ∨ A0\n"
     ]
    }
   ],
   "source": [
    "# --- Random Formula Generator ---\n",
    "def generate_random_formula(max_depth: int = None, \n",
    "                            letter_generator = None, \n",
    "                            seed :int = None ) -> Formula:\n",
    "    \"\"\"\n",
    "    Generates a random formula of a certain depth.\n",
    "    \n",
    "    Args: \n",
    "        max_depth (int): Controls the maximum depth of the generated formula's syntax tree.\n",
    "        letter_generator: A generator of letter sequence. \n",
    "        seed (int): Integer for reproducibility.\n",
    "       \n",
    "    Returns: \n",
    "        A random propositional formula.\n",
    "\n",
    "    \"\"\"\n",
    "      \n",
    "    if seed is not None:\n",
    "        random.seed(seed)\n",
    "\n",
    "\n",
    "    if max_depth == 0 or random.random() > 0.5:\n",
    "        # If max depth is 0 or by random chance, return either a letter or falsity\n",
    "        return random.choices([next(letter_generator), Falsity()], weights=[0.95, 0.05])[0]  # Priority given to random letter\n",
    "\n",
    "    formula_type = random.choice([Conjunction, Disjunction, Implication, Negation])\n",
    "\n",
    "    if formula_type == Negation:\n",
    "        subformula = generate_random_formula(max_depth - 1, letter_generator)\n",
    "        return Negation(subformula)\n",
    "    else:\n",
    "        left_subformula = generate_random_formula(max_depth - 1, letter_generator)\n",
    "        right_subformula = generate_random_formula(max_depth - 1, letter_generator)\n",
    "        return formula_type(left_subformula, right_subformula)\n",
    "    \n",
    "# --- Generate normalized random formulas ---\n",
    "def generate_normalized_random_formula(max_depth: int = None, \n",
    "                                       num_letters: int = None, \n",
    "                                       seed :int = None) -> Formula:\n",
    "    \"\"\"\n",
    "    Generates a normalized random formula where letters are renumbered in ascending order.\n",
    "\n",
    "    Args: \n",
    "        max_depth (int): Controls the maximum depth of the generated formula's syntax tree.\n",
    "        num_letters (int): Number of propositional letter that can be used.\n",
    "        seed (int): integer for reproducibility.\n",
    "      \n",
    "    Returns: \n",
    "        A random normalized formula.\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    if seed is not None:\n",
    "        random.seed(seed)\n",
    "\n",
    "    # Initialize a generator for propositional letters in ascending order\n",
    "    letter_generator = generate_letter_sequence(num_letters)\n",
    "\n",
    "    # Generate a random formula\n",
    "    random_formula = generate_random_formula(max_depth, letter_generator, seed=seed)\n",
    "\n",
    "    # Normalize the formula using the Normalizer class\n",
    "    normalizer = Normalizer()\n",
    "    normalized_formula = normalizer.normalize(random_formula)\n",
    "\n",
    "    return normalized_formula\n",
    "\n",
    "# Example: \n",
    "new_formula = generate_normalized_random_formula(max_depth=3, \n",
    "                                                 num_letters=2,\n",
    "                                                 seed=32)\n",
    "print(new_formula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ba5b5ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T18:24:01.931838Z",
     "iopub.status.busy": "2025-05-29T18:24:01.931517Z",
     "iopub.status.idle": "2025-05-29T18:24:01.944881Z",
     "shell.execute_reply": "2025-05-29T18:24:01.943826Z",
     "shell.execute_reply.started": "2025-05-29T18:24:01.931807Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized status of (A0 ∨ A1) should be True and is: True\n",
      "Normalized status of (A1 ∨ A0) should be False and is: False\n",
      "Normalized status of (A0 ∨ ¬A0) should be True and is: True\n",
      "Normalized status of ((A0 ∨ A1) ∧ A2 → A0 ∧ A3) should be True and is: True\n"
     ]
    }
   ],
   "source": [
    "# --- Checking if a formula is normalized --- \n",
    "def is_normalized(formula: Formula) -> bool:\n",
    "    \"\"\"\n",
    "    Checks if a given formula is normalized.\n",
    "    \n",
    "    \"\"\"\n",
    "    encountered_letters = set()\n",
    "    last_index = -1  # Initialize to an invalid index to check ascending order\n",
    "                     # when the first letter is checked, its index will always be greater than -1\n",
    "\n",
    "    def check_formula(f: Formula):\n",
    "        nonlocal last_index\n",
    "        if isinstance(f, Letter):\n",
    "            # Check if the letter index is in ascending order\n",
    "            if f.n in encountered_letters:\n",
    "                return True  # Already seen, valid\n",
    "            if f.n <= last_index:\n",
    "                return False  # Not in ascending order\n",
    "            encountered_letters.add(f.n)\n",
    "            last_index = f.n  # Update last_index to current letter's index\n",
    "            return True\n",
    "\n",
    "        elif isinstance(f, Falsity):\n",
    "            return True\n",
    "\n",
    "        elif isinstance(f, UnaryConnectiveFormula):\n",
    "            return check_formula(f.formula)\n",
    "\n",
    "        elif isinstance(f, BinaryConnectiveFormula):\n",
    "            return check_formula(f.left) and check_formula(f.right)\n",
    "\n",
    "        else:\n",
    "            raise Exception(\"Unknown formula type\")\n",
    "\n",
    "    return check_formula(formula)\n",
    "\n",
    "# Example:\n",
    "A0 = Letter(0)\n",
    "A1 = Letter(1)\n",
    "A2 = Letter(2)\n",
    "A3 = Letter(3)\n",
    "A4 = Letter(4)\n",
    "falsity = Falsity()\n",
    "\n",
    "formula1 = Disjunction(Letter(0), Letter(1))  # Normalized: A0 ∨ A1\n",
    "formula2 = Disjunction(Letter(1), Letter(0))  # Not normalized: A1 ∨ A0\n",
    "formula3 = Disjunction(Letter(0), Negation(Letter(0)))  # Normalized: A0 ∨ ¬A0\n",
    "\n",
    "disjunction_A0_A1 = A0 | A1  # A0 ∨ A1\n",
    "and_with_A3 = Conjunction(disjunction_A0_A1, A2)  # ((A0 ∨ A1) ∧ A2)\n",
    "and_with_A0_A4 = Conjunction(A0, A3)  # A0 ∧ A3\n",
    "formula4 = Implication(and_with_A3, and_with_A0_A4)  # ((A0 ∨ A1) ∧ A2) → (A0 ∧ A3)\n",
    "\n",
    "# Print the final formula\n",
    "print(f\"Normalized status of ({formula1}) should be True and is: {is_normalized(formula1)}\")  # True\n",
    "print(f\"Normalized status of ({formula2}) should be False and is: {is_normalized(formula2)}\") # False\n",
    "print(f\"Normalized status of ({formula3}) should be True and is: {is_normalized(formula3)}\")  # True\n",
    "print(f\"Normalized status of ({formula4}) should be True and is: {is_normalized(formula4)}\")  # True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8f26a0",
   "metadata": {},
   "source": [
    "---\n",
    "### **1.3 Generate Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2407a931",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T18:24:01.946926Z",
     "iopub.status.busy": "2025-05-29T18:24:01.946514Z",
     "iopub.status.idle": "2025-05-29T18:24:01.954371Z",
     "shell.execute_reply": "2025-05-29T18:24:01.953024Z",
     "shell.execute_reply.started": "2025-05-29T18:24:01.946797Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Normalized Dataset --- \n",
    "def generate_normalized_dataset(num_formulas: int, \n",
    "                                max_depth: int, \n",
    "                                num_letters: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generates a DataFrame containing random normalized formulas and their tautology status.\n",
    "\n",
    "    Args: \n",
    "        num_formulas (int): Number of formulas to generate.\n",
    "        max_depth (int): maximum depth of the generated formula's syntax tree.\n",
    "        num_letters (int): Number of propositional letter that can be used.\n",
    "    \n",
    "    Returns: \n",
    "        A pandas DataFrame) that contains:\n",
    "        - Random normalized logical formulas,\n",
    "        - A Boolean label indicating whether each formula is a tautology.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    seen_formulas = set()\n",
    "\n",
    "    while len(data) < num_formulas:\n",
    "        formula = generate_normalized_random_formula(max_depth=max_depth, num_letters=num_letters)\n",
    "\n",
    "        formula_str = str(formula)\n",
    "\n",
    "        if formula_str in seen_formulas:\n",
    "            continue\n",
    "\n",
    "        seen_formulas.add(formula_str)\n",
    "\n",
    "        tautology_status = is_tautology(formula)\n",
    "\n",
    "        data.append({\"formula\": formula_str, \"is_tautology\": tautology_status})\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae3f619f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T18:24:01.956128Z",
     "iopub.status.busy": "2025-05-29T18:24:01.955846Z",
     "iopub.status.idle": "2025-05-29T18:24:01.962950Z",
     "shell.execute_reply": "2025-05-29T18:24:01.961865Z",
     "shell.execute_reply.started": "2025-05-29T18:24:01.956100Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_normalized_dataset_to_csv(filename: str, \n",
    "                                   size: int, \n",
    "                                   max_depth: int = None, \n",
    "                                   num_letters: int = None, \n",
    "                                   seed: int = None):\n",
    "    \"\"\"\n",
    "    Save the normalized dataset in a CSV file. \n",
    "\n",
    "    Args: \n",
    "        filename (str):\n",
    "        size (str):\n",
    "        max_depth (int):\n",
    "        num_letters (int):\n",
    "        seed (int):\n",
    "        \n",
    "    Returns: \n",
    "        A Dataset of random, normalized propositional logic formulas (with their tautology status),\n",
    "        and saves it as a CSV file on disk under a specific filename.\n",
    "    \"\"\"\n",
    "\n",
    "    if seed is not None:\n",
    "        random.seed(seed)\n",
    "    dataset = generate_normalized_dataset(num_formulas=size, \n",
    "                                          max_depth=max_depth, \n",
    "                                          num_letters=num_letters)\n",
    "    dataset.to_csv(filename, index=False) # DataFrame’s index is not saved as a column\n",
    "    print(f\"[INFO] Saving Dataset to {os.path.abspath(filename)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e03fffd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T18:24:01.964665Z",
     "iopub.status.busy": "2025-05-29T18:24:01.964389Z",
     "iopub.status.idle": "2025-05-29T18:24:04.753324Z",
     "shell.execute_reply": "2025-05-29T18:24:04.752113Z",
     "shell.execute_reply.started": "2025-05-29T18:24:01.964638Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saving Dataset to /home/labeconomia/nbalestra/theorem_prover/theorem_prover_core/ICTCS_notebooks/datasets/first_normalized_formulas_dataset.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>formula</th>\n",
       "      <th>is_tautology</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(A0 ∧ ¬(A1 ∧ A2 ∧ A3)) ∨ (A4 → A5)</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(¬(A0 → A1) → A2) ∨ A3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>⊥ ∨ A0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>¬A0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              formula  is_tautology\n",
       "0                                  A0         False\n",
       "1  (A0 ∧ ¬(A1 ∧ A2 ∧ A3)) ∨ (A4 → A5)         False\n",
       "2              (¬(A0 → A1) → A2) ∨ A3         False\n",
       "3                              ⊥ ∨ A0         False\n",
       "4                                 ¬A0         False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SIZE = 10000\n",
    "MAX_DEPTH = 5\n",
    "NUM_LETTERS = 7\n",
    "\n",
    "save_normalized_dataset_to_csv(filename='datasets/first_normalized_formulas_dataset.csv', \n",
    "                               size=SIZE, \n",
    "                               max_depth=MAX_DEPTH, \n",
    "                               num_letters=NUM_LETTERS, \n",
    "                               seed=42)\n",
    "\n",
    "datapath = \"datasets/first_normalized_formulas_dataset.csv\"\n",
    "data_set = pd.read_csv(datapath)\n",
    "\n",
    "data_set.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f3f197f-9922-4305-984a-839acb5e3a4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T18:24:04.755146Z",
     "iopub.status.busy": "2025-05-29T18:24:04.754833Z",
     "iopub.status.idle": "2025-05-29T18:24:04.767220Z",
     "shell.execute_reply": "2025-05-29T18:24:04.765991Z",
     "shell.execute_reply.started": "2025-05-29T18:24:04.755117Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "formula         10000\n",
      "is_tautology    10000\n",
      "dtype: int64\n",
      "\n",
      "Number of True and False formulas: \n",
      "is_tautology\n",
      "False    9576\n",
      "True      424\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Percentage of tautologies in the dataset: 4.24%\n"
     ]
    }
   ],
   "source": [
    "print(data_set.count())\n",
    "count = data_set.is_tautology.value_counts()\n",
    "print(f\"\\nNumber of True and False formulas: \\n{count}\\n\")\n",
    "\n",
    "total = len(data_set)\n",
    "tautologies = data_set[\"is_tautology\"].sum()\n",
    "percentage = (tautologies / total) * 100\n",
    "print(f\"Percentage of tautologies in the dataset: {percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd72783b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T18:24:04.769063Z",
     "iopub.status.busy": "2025-05-29T18:24:04.768765Z",
     "iopub.status.idle": "2025-05-29T18:24:04.782983Z",
     "shell.execute_reply": "2025-05-29T18:24:04.781487Z",
     "shell.execute_reply.started": "2025-05-29T18:24:04.769034Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The formula 'A0 ∨ ¬A0' is not in the dataset.\n",
      "The formula '¬(A0 ∧ ¬A0)' is not in the dataset.\n",
      "The formula '(¬(A0 ∧ A1) → ¬A0 ∨ ¬A1) ∧ (¬A0 ∨ ¬A1 → ¬(A0 ∧ A1))' is not in the dataset.\n",
      "The formula '(A0 ∧ (A1 ∨ A2) → (A0 ∧ A1) ∨ (A0 ∧ A2)) ∧ ((A0 ∧ A1) ∨ (A0 ∧ A2) → A0 ∧ (A1 ∨ A2))' is not in the dataset.\n"
     ]
    }
   ],
   "source": [
    "# Checking if common tautologies are in the dataset\n",
    "\n",
    "A0 = Letter(0)\n",
    "A1 = Letter(1)\n",
    "A2 = Letter(2)\n",
    "\n",
    "excluded_middle = Disjunction(A0, Negation(A0))  # A0 ∨ ¬A0\n",
    "not_contradiction = Negation(Conjunction(A0, Negation(A0)))  # ¬(A0 ∧ ¬A0)\n",
    "de_morgan = Conjunction(\n",
    "            Implication(Negation(Conjunction(A0, A1)), Disjunction(Negation(A0), Negation(A1))),\n",
    "            Implication(Disjunction(Negation(A0), Negation(A1)), Negation(Conjunction(A0, A1)))    # ¬(A0 ∧ A1) ↔ (¬A0 ∨ ¬A1)\n",
    "        )\n",
    "distributivity = Conjunction(\n",
    "                Implication(Conjunction(A0, Disjunction(A1, A2)), Disjunction(Conjunction(A0, A1), Conjunction(A0, A2))),\n",
    "                Implication(Disjunction(Conjunction(A0, A1), Conjunction(A0, A2)), Conjunction(A0, Disjunction(A1, A2)))   # A0 ∨ (A1 ∧ A2) ↔ (A0 ∨ A1) ∧ (A0 ∨ A2)\n",
    "        )\n",
    "\n",
    "\n",
    "excluded_middle_str = str(excluded_middle)\n",
    "not_contradiction_str = str(not_contradiction)\n",
    "de_morgan_str = str(de_morgan)\n",
    "distributivity_str = str(distributivity)\n",
    "\n",
    "\n",
    "formulas_to_check = [excluded_middle_str, not_contradiction_str, de_morgan_str, distributivity_str]\n",
    "\n",
    "for formula_str in formulas_to_check:\n",
    "    exists_in_dataset = formula_str in data_set['formula'].values\n",
    "    print(f\"The formula '{formula_str}' is {'in' if exists_in_dataset else 'not in'} the dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a978ad0",
   "metadata": {},
   "source": [
    "---\n",
    "#### **1.4 Data Augmentation With Common Tautologies Instantiation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8821d17a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T18:24:04.785638Z",
     "iopub.status.busy": "2025-05-29T18:24:04.784735Z",
     "iopub.status.idle": "2025-05-29T18:24:04.802672Z",
     "shell.execute_reply": "2025-05-29T18:24:04.801394Z",
     "shell.execute_reply.started": "2025-05-29T18:24:04.785606Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original formula with metavariables: A ∧ B\n",
      "\n",
      "Metavariable A will be instantiated with: A0 ∨ A1 and\n",
      "Metavariable B will be instantiated with: (A0 ∨ A1 ∨ (A2 → A3)) ∧ ((A4 → A5) → A6 ∧ A0)\n",
      "\n",
      "Instantiated formula: (A0 ∨ A1) ∧ (A0 ∨ A1 ∨ (A2 → A3)) ∧ ((A4 → A5) → A6 ∧ A0)\n"
     ]
    }
   ],
   "source": [
    "# Metavariable and Instantiation classes\n",
    "\n",
    "Position = Literal[\"left\", \"right\"]  \n",
    "Associativity = Literal[\"left\", \"right\"]  \n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Metavariable(Formula):\n",
    "    \"\"\"\n",
    "    A class representing a metavariable in a formula.\n",
    "    Metavariables will be replaced with actual formulas during instantiation.\n",
    "    \"\"\"\n",
    "    __slots__ = ('name',)\n",
    "    name: str\n",
    "\n",
    "    def _make_str(self, outer_class: Union[Type[Formula], None], position: Union[Position, None]) -> str:\n",
    "        return f'{self.name}'\n",
    "\n",
    "\n",
    "class Instantiator:\n",
    "    \"\"\"\n",
    "    This class handles the instantiation of metavariables within formulas.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, num_letters: int):\n",
    "        self.num_letters = num_letters\n",
    "        self.letter_generator = generate_letter_sequence(num_letters)\n",
    "        self.normalizer = Normalizer()\n",
    "\n",
    "    def instantiate(self, formula: Formula, metavariable_map: Dict[str, Formula]) -> Formula:\n",
    "        \"\"\"\n",
    "        Recursively replaces metavariables in a formula with actual formulas from the map.\n",
    "\n",
    "        \"\"\"\n",
    "        if isinstance(formula, Metavariable):\n",
    "            if formula.name not in metavariable_map:\n",
    "                raise Exception(f\"Metavariable '{formula.name}' not found in the map.\")\n",
    "            return self.normalizer.normalize(metavariable_map[formula.name])\n",
    "\n",
    "        elif isinstance(formula, Letter):\n",
    "            return formula\n",
    "\n",
    "        elif isinstance(formula, Falsity):\n",
    "            return formula\n",
    "\n",
    "        elif isinstance(formula, UnaryConnectiveFormula):\n",
    "            instantiated_formula = self.instantiate(formula.formula, metavariable_map)\n",
    "            return formula.__class__(instantiated_formula)\n",
    "\n",
    "        elif isinstance(formula, BinaryConnectiveFormula):\n",
    "            left_instantiated = self.instantiate(formula.left, metavariable_map)\n",
    "            right_instantiated = self.instantiate(formula.right, metavariable_map)\n",
    "            return formula.__class__(left_instantiated, right_instantiated)\n",
    "\n",
    "        else:\n",
    "            raise Exception(\"Unknown formula type\")\n",
    "\n",
    "\n",
    "# Example:\n",
    "meta_A = Metavariable(\"A\")\n",
    "meta_B = Metavariable(\"B\")\n",
    "formula_with_metavariables = Conjunction(meta_A, meta_B)\n",
    "\n",
    "num_letters = 6\n",
    "max_depth = 3\n",
    "instantiator = Instantiator(num_letters=num_letters)\n",
    "\n",
    "form_1 = generate_normalized_random_formula(max_depth=max_depth, num_letters=num_letters, seed=43)\n",
    "form_2 = generate_normalized_random_formula(max_depth=max_depth, num_letters=num_letters, seed=44)\n",
    "\n",
    "metavariable_map = {\n",
    "        \"A\": form_1,\n",
    "        \"B\": form_2\n",
    "        }\n",
    "\n",
    "instantiated_formula = instantiator.instantiate(formula_with_metavariables, metavariable_map)\n",
    "\n",
    "\n",
    "print(f\"Original formula with metavariables: {formula_with_metavariables}\\n\")\n",
    "print(f\"Metavariable A will be instantiated with: {form_1} and\"\n",
    "      f\"\\nMetavariable B will be instantiated with: {form_2}\\n\")\n",
    "print(f\"Instantiated formula: {instantiated_formula}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b0fae2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T18:24:04.805302Z",
     "iopub.status.busy": "2025-05-29T18:24:04.804274Z",
     "iopub.status.idle": "2025-05-29T18:24:04.816204Z",
     "shell.execute_reply": "2025-05-29T18:24:04.814740Z",
     "shell.execute_reply.started": "2025-05-29T18:24:04.805270Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A ∨ ¬A\n",
      "¬(A ∧ ¬A)\n",
      "(¬(A ∧ B) → ¬A ∨ ¬B) ∧ (¬A ∨ ¬B → ¬(A ∧ B))\n",
      "(¬(A ∨ B) → ¬A ∧ ¬B) ∧ (¬A ∧ ¬B → ¬(A ∨ B))\n",
      "(A ∧ (B ∨ C) → (A ∧ B) ∨ (A ∧ C)) ∧ ((A ∧ B) ∨ (A ∧ C) → A ∧ (B ∨ C))\n",
      "(A ∨ (B ∧ C) → (A ∨ B) ∧ (A ∨ C)) ∧ ((A ∨ B) ∧ (A ∨ C) → A ∨ (B ∧ C))\n"
     ]
    }
   ],
   "source": [
    "# --- Creating Common Tautologies --- \n",
    "A = Metavariable(\"A\")\n",
    "B = Metavariable(\"B\")\n",
    "C = Metavariable(\"C\")\n",
    "\n",
    "# List of common tautologies\n",
    "tautologies = [\n",
    "\n",
    "    Disjunction(A, Negation(A)),\n",
    "\n",
    "    Negation(Conjunction(A, Negation(A))),\n",
    "\n",
    "    Conjunction(\n",
    "        Implication(Negation(Conjunction(A, B)), Disjunction(Negation(A), Negation(B))),\n",
    "        Implication(Disjunction(Negation(A), Negation(B)), Negation(Conjunction(A, B)))\n",
    "    ),\n",
    "\n",
    "    Conjunction(\n",
    "        Implication(Negation(Disjunction(A, B)), Conjunction(Negation(A), Negation(B))),\n",
    "        Implication(Conjunction(Negation(A), Negation(B)), Negation(Disjunction(A, B)))\n",
    "    ),\n",
    "\n",
    "    Conjunction(\n",
    "        Implication(Conjunction(A, Disjunction(B, C)), Disjunction(Conjunction(A, B), Conjunction(A, C))),\n",
    "        Implication(Disjunction(Conjunction(A, B), Conjunction(A, C)), Conjunction(A, Disjunction(B, C)))\n",
    "    ),\n",
    "\n",
    "    Conjunction(\n",
    "        Implication(Disjunction(A, Conjunction(B, C)), Conjunction(Disjunction(A, B), Disjunction(A, C))),\n",
    "        Implication(Conjunction(Disjunction(A, B), Disjunction(A, C)), Disjunction(A, Conjunction(B, C)))\n",
    "    )\n",
    "]\n",
    "\n",
    "for tautology in tautologies:\n",
    "    print(tautology)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f457cec0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T18:24:04.819155Z",
     "iopub.status.busy": "2025-05-29T18:24:04.817793Z",
     "iopub.status.idle": "2025-05-29T18:24:04.829202Z",
     "shell.execute_reply": "2025-05-29T18:24:04.828220Z",
     "shell.execute_reply.started": "2025-05-29T18:24:04.819120Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Intantiating Common Tautologies --- \n",
    "def instantiate_random_formulas(num_samples: int, \n",
    "                                tautologies: List[Formula], \n",
    "                                seed: int = None) -> List[Formula]:\n",
    "    \"\"\"\n",
    "    Samples and instantiates tautologies,\n",
    "    re-sampling if necessary to reach the number of unique samples.\n",
    "\n",
    "    Args: \n",
    "        num_samples (int): Number of tautologies to instantiate.\n",
    "        tautologies: List of tautologies. \n",
    "        seed (int): Integer for reproducibility.\n",
    "    \n",
    "    Returns:\n",
    "        A list of istantiated tautologies. \n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        random.seed(seed)\n",
    "\n",
    "    instantiated_tautologies = []\n",
    "    seen_formulas = set()\n",
    "    instantiator = Instantiator(num_letters=num_samples)\n",
    "\n",
    "    attempts = 0  # Track the number of sampling attempts\n",
    "    max_attempts = num_samples * 2  # Limit to avoid infinite loops\n",
    "\n",
    "    # Continue generating until we have the required number of unique instantiations\n",
    "    while len(instantiated_tautologies) < num_samples and attempts < max_attempts:\n",
    "        random_formulas = [\n",
    "            generate_normalized_random_formula(max_depth=MAX_DEPTH, \n",
    "                                               num_letters=NUM_LETTERS, \n",
    "                                               seed=(seed + attempts + i))\n",
    "            for i in range(3)\n",
    "        ]\n",
    "\n",
    "        metavariable_map = {\n",
    "            \"A\": random_formulas[0],\n",
    "            \"B\": random_formulas[1],\n",
    "            \"C\": random_formulas[2]\n",
    "        }\n",
    "\n",
    "        tautology = tautologies[attempts % len(tautologies)]  # Wrap around the tautologies list\n",
    "\n",
    "        if isinstance(tautology, Formula):\n",
    "            try:\n",
    "                instantiated = instantiator.instantiate(tautology, metavariable_map)\n",
    "                instantiated_str = str(instantiated)\n",
    "\n",
    "                if instantiated_str not in seen_formulas:\n",
    "                    instantiated_tautologies.append(instantiated)\n",
    "                    seen_formulas.add(instantiated_str)\n",
    "\n",
    "            except Exception as e:\n",
    "                pass\n",
    "\n",
    "        attempts += 1\n",
    "\n",
    "    # Warning if the number of unique instantiations is less than required\n",
    "    if len(instantiated_tautologies) < num_samples:\n",
    "        print(f\"Warning: Only {len(instantiated_tautologies)} unique formulas generated out of {num_samples} requested.\")\n",
    "\n",
    "    return instantiated_tautologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "949d699f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T18:24:04.832193Z",
     "iopub.status.busy": "2025-05-29T18:24:04.830700Z",
     "iopub.status.idle": "2025-05-29T18:24:06.875393Z",
     "shell.execute_reply": "2025-05-29T18:24:06.874302Z",
     "shell.execute_reply.started": "2025-05-29T18:24:04.832160Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total instantiated tautologies: 3000\n",
      "Instantiated Tautology 0: A0 ∨ ¬A0\n",
      "Instantiated Tautology 200: (¬A0 ∨ (((A0 → ¬A1) ∨ ¬¬A2) ∧ (A0 → ¬¬A1)) → (¬A0 ∨ (A0 → ¬A1) ∨ ¬¬A2) ∧ (¬A0 ∨ (A0 → ¬¬A1))) ∧ ((¬A0 ∨ (A0 → ¬A1) ∨ ¬¬A2) ∧ (¬A0 ∨ (A0 → ¬¬A1)) → ¬A0 ∨ (((A0 → ¬A1) ∨ ¬¬A2) ∧ (A0 → ¬¬A1)))\n",
      "Instantiated Tautology 400: (A0 ∧ (⊥ ∨ A0) → (A0 ∧ ⊥) ∨ (A0 ∧ A0)) ∧ ((A0 ∧ ⊥) ∨ (A0 ∧ A0) → A0 ∧ (⊥ ∨ A0))\n",
      "Instantiated Tautology 600: ¬((¬(¬A0 ∨ A1 ∨ ¬A2) ∨ ¬(¬A3 ∧ ¬¬A4)) ∧ ¬(¬(¬A0 ∨ A1 ∨ ¬A2) ∨ ¬(¬A3 ∧ ¬¬A4)))\n",
      "Instantiated Tautology 800: (¬(A0 ∧ A1) ∧ (A0 ∨ A0) → (¬(A0 ∧ A1) ∧ A0) ∨ (¬(A0 ∧ A1) ∧ A0)) ∧ ((¬(A0 ∧ A1) ∧ A0) ∨ (¬(A0 ∧ A1) ∧ A0) → ¬(A0 ∧ A1) ∧ (A0 ∨ A0))\n",
      "Instantiated Tautology 1000: ¬((A0 ∨ A1) ∧ A2 ∧ ¬((A0 ∨ A1) ∧ A2))\n",
      "Instantiated Tautology 1200: ¬((⊥ → A0 ∧ A1) ∧ ¬(⊥ → A0 ∧ A1))\n",
      "Instantiated Tautology 1400: (¬((¬A0 → A1) ∨ A0) → ¬(¬A0 → A1) ∧ ¬A0) ∧ (¬(¬A0 → A1) ∧ ¬A0 → ¬((¬A0 → A1) ∨ A0))\n",
      "Instantiated Tautology 1600: (¬((A0 → ⊥) ∨ ¬A0) → ¬(A0 → ⊥) ∧ ¬¬A0) ∧ (¬(A0 → ⊥) ∧ ¬¬A0 → ¬((A0 → ⊥) ∨ ¬A0))\n",
      "Instantiated Tautology 1800: (¬(¬(A0 ∧ A1) → ⊥) ∧ ¬¬A2 ∧ A3) ∨ ¬(¬(¬(A0 ∧ A1) → ⊥) ∧ ¬¬A2 ∧ A3)\n",
      "Instantiated Tautology 2000: (¬(A0 ∨ ((A0 ∨ A1) ∧ A2 ∧ A3 ∧ ¬((A4 ∨ A5) ∧ ⊥))) → ¬A0 ∧ ¬((A0 ∨ A1) ∧ A2 ∧ A3 ∧ ¬((A4 ∨ A5) ∧ ⊥))) ∧ (¬A0 ∧ ¬((A0 ∨ A1) ∧ A2 ∧ A3 ∧ ¬((A4 ∨ A5) ∧ ⊥)) → ¬(A0 ∨ ((A0 ∨ A1) ∧ A2 ∧ A3 ∧ ¬((A4 ∨ A5) ∧ ⊥))))\n",
      "Instantiated Tautology 2200: ¬(¬(A0 → A1) ∨ A2 ∨ ¬A3) ∨ ¬¬(¬(A0 → A1) ∨ A2 ∨ ¬A3)\n",
      "Instantiated Tautology 2400: (¬(A0 ∧ ¬(¬A1 ∧ A2)) ∧ ((A0 ∨ ⊥ → ¬A1) ∨ A0) → (¬(A0 ∧ ¬(¬A1 ∧ A2)) ∧ (A0 ∨ ⊥ → ¬A1)) ∨ (¬(A0 ∧ ¬(¬A1 ∧ A2)) ∧ A0)) ∧ ((¬(A0 ∧ ¬(¬A1 ∧ A2)) ∧ (A0 ∨ ⊥ → ¬A1)) ∨ (¬(A0 ∧ ¬(¬A1 ∧ A2)) ∧ A0) → ¬(A0 ∧ ¬(¬A1 ∧ A2)) ∧ ((A0 ∨ ⊥ → ¬A1) ∨ A0))\n",
      "Instantiated Tautology 2600: (A0 ∧ ((A0 → A1) ∨ A0 ∨ (A1 → ⊥ ∨ A2)) → (A0 ∧ (A0 → A1)) ∨ (A0 ∧ (A0 ∨ (A1 → ⊥ ∨ A2)))) ∧ ((A0 ∧ (A0 → A1)) ∨ (A0 ∧ (A0 ∨ (A1 → ⊥ ∨ A2))) → A0 ∧ ((A0 → A1) ∨ A0 ∨ (A1 → ⊥ ∨ A2)))\n",
      "Instantiated Tautology 2800: ((A0 → A1) ∨ ¬A2 ∨ (A3 ∧ A4 ∧ A5) ∨ (A6 ∧ A7) ∨ (A0 ∧ ⊥) → ((A0 → A1) ∨ ¬A2 ∨ (A3 ∧ A4 ∧ A5) ∨ (A6 ∧ A7) ∨ A0) ∧ ((A0 → A1) ∨ ¬A2 ∨ (A3 ∧ A4 ∧ A5) ∨ (A6 ∧ A7) ∨ ⊥)) ∧ (((A0 → A1) ∨ ¬A2 ∨ (A3 ∧ A4 ∧ A5) ∨ (A6 ∧ A7) ∨ A0) ∧ ((A0 → A1) ∨ ¬A2 ∨ (A3 ∧ A4 ∧ A5) ∨ (A6 ∧ A7) ∨ ⊥) → (A0 → A1) ∨ ¬A2 ∨ (A3 ∧ A4 ∧ A5) ∨ (A6 ∧ A7) ∨ (A0 ∧ ⊥))\n"
     ]
    }
   ],
   "source": [
    "seed_value = 42\n",
    "num_samples = 3000 # (30% of the dataset formulas)\n",
    "\n",
    "instantiated_tautologies = instantiate_random_formulas(num_samples, tautologies, seed_value)\n",
    "\n",
    "print(f\"Number of total instantiated tautologies: {len(instantiated_tautologies)}\")\n",
    "\n",
    "for i, instantiated in enumerate(instantiated_tautologies):\n",
    "    if i % 200 == 0:\n",
    "        print(f\"Instantiated Tautology {i}: {instantiated}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1194410d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T18:24:06.877575Z",
     "iopub.status.busy": "2025-05-29T18:24:06.877047Z",
     "iopub.status.idle": "2025-05-29T18:24:06.993826Z",
     "shell.execute_reply": "2025-05-29T18:24:06.992719Z",
     "shell.execute_reply.started": "2025-05-29T18:24:06.877526Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate instantiated tautologies: {}\n",
      "Number of distinct instantiated tautologies: 3000\n"
     ]
    }
   ],
   "source": [
    "# --- Check if istantated tautologies are unique ---\n",
    "# Occurrences of each instantiated tautology\n",
    "tautology_counter = Counter(instantiated_tautologies)\n",
    "\n",
    "duplicates = {tautology: count for tautology, count in tautology_counter.items() if count > 1}\n",
    "print(f\"Duplicate instantiated tautologies: {duplicates}\")\n",
    "\n",
    "# Number of distinct tautologies\n",
    "distinct_tautologies = set(instantiated_tautologies)\n",
    "num_distinct_tautologies = len(distinct_tautologies)\n",
    "print(f\"Number of distinct instantiated tautologies: {num_distinct_tautologies}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b1deecae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T18:24:06.995521Z",
     "iopub.status.busy": "2025-05-29T18:24:06.995188Z",
     "iopub.status.idle": "2025-05-29T18:24:45.328090Z",
     "shell.execute_reply": "2025-05-29T18:24:45.326818Z",
     "shell.execute_reply.started": "2025-05-29T18:24:06.995490Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saving Dataset to /home/labeconomia/nbalestra/theorem_prover/theorem_prover_core/ICTCS_notebooks/datasets/first_extended_dataset.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>formula</th>\n",
       "      <th>is_tautology</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>¬⊥ ∨ ¬A0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(A0 → A1) ∨ ⊥ → ¬A2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0 ∨ A1 ∨ ¬(⊥ → A2) ∨ A3 ∨ A4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>((A0 ∨ A1 → A2) ∧ ((⊥ → A3) ∨ (A4 → A5))) ∨ (A...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0 ∧ A1 ∧ (A2 ∨ A3 ∨ A4 ∨ A5) ∧ ¬¬A6 ∧ (¬A7 ∨ ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             formula  is_tautology\n",
       "0                                           ¬⊥ ∨ ¬A0          True\n",
       "1                                (A0 → A1) ∨ ⊥ → ¬A2         False\n",
       "2                      A0 ∨ A1 ∨ ¬(⊥ → A2) ∨ A3 ∨ A4         False\n",
       "3  ((A0 ∨ A1 → A2) ∧ ((⊥ → A3) ∨ (A4 → A5))) ∨ (A...          True\n",
       "4  A0 ∧ A1 ∧ (A2 ∨ A3 ∨ A4 ∨ A5) ∧ ¬¬A6 ∧ (¬A7 ∨ ...         False"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Adding 3,000 (30% of dataaset) new tatologies to the dataset ---\n",
    "\n",
    "def add_new_tautologies_to_dataset(dataset: pd.DataFrame, \n",
    "                                   tautologies: List[Formula],\n",
    "                                   num_samples: int,\n",
    "                                   seed: int = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Add a fixed number of unique tautologies to the dataset.\n",
    "\n",
    "    Args: \n",
    "        dataset (pd.DataFrame): Existing dataset.\n",
    "        tautologies (List[Formula]): Template tautologies.\n",
    "        num_samples (int): Number of new tautologies to add.\n",
    "        seed (int): Random seed for reproducibility.\n",
    "\n",
    "    Returns: \n",
    "        Updated DataFrame with added tautologies.\n",
    "    \"\"\"\n",
    "    existing_formulas = set(dataset['formula'].tolist())\n",
    "    new_data = []\n",
    "    attempts = 0\n",
    "    batch_size = 500  # generate in chunks\n",
    "    seed_base = seed if seed is not None else random.randint(0, 10000)\n",
    "\n",
    "    while len(new_data) < num_samples and attempts < num_samples * 5:\n",
    "        # Instantiate new formulas in batches\n",
    "        fresh = instantiate_random_formulas(batch_size, tautologies, seed_base + attempts)\n",
    "\n",
    "        for formula in fresh:\n",
    "            formula_str = str(formula)\n",
    "            if formula_str not in existing_formulas:\n",
    "                new_data.append({\n",
    "                    'formula': formula_str,\n",
    "                    'is_tautology': True\n",
    "                })\n",
    "                existing_formulas.add(formula_str)\n",
    "                if len(new_data) >= num_samples:\n",
    "                    break\n",
    "        attempts += 1\n",
    "\n",
    "    if len(new_data) < num_samples:\n",
    "        print(f\"[Warning] Only {len(new_data)} unique tautologies added out of {num_samples} requested.\")\n",
    "\n",
    "    \n",
    "    # Concatenating and shuffling dataset\n",
    "    new_df = pd.DataFrame(new_data)\n",
    "    updated_dataset = pd.concat([dataset, new_df], ignore_index=True)\n",
    "    return updated_dataset.sample(frac=1, random_state=seed).reset_index(drop=True) # frac=1 means shuffle all rows\n",
    "                                                                                    # reset_index(drop=True) removes the old index\n",
    "\n",
    "\n",
    "num_samples = 3000\n",
    "seed_value = 42\n",
    "\n",
    "dataset = add_new_tautologies_to_dataset(dataset=data_set,\n",
    "                                         tautologies=tautologies,\n",
    "                                         num_samples=num_samples,\n",
    "                                         seed=seed_value)\n",
    "dataset.to_csv('datasets/first_extended_dataset.cvs', index=False)\n",
    "print(f\"[INFO] Saving Dataset to {os.path.abspath('datasets/first_extended_dataset.csv')}\")\n",
    "dataset[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "69e21cc7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T18:24:45.329745Z",
     "iopub.status.busy": "2025-05-29T18:24:45.329424Z",
     "iopub.status.idle": "2025-05-29T18:24:45.343354Z",
     "shell.execute_reply": "2025-05-29T18:24:45.341838Z",
     "shell.execute_reply.started": "2025-05-29T18:24:45.329715Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "formula         13000\n",
      "is_tautology    13000\n",
      "dtype: int64\n",
      "\n",
      "Number of True and False formulas: \n",
      "is_tautology\n",
      "False    9576\n",
      "True     3424\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Percentage of tautologies in the dataset: 26.34%\n"
     ]
    }
   ],
   "source": [
    "# --- Get Dataset Info ---\n",
    "print(dataset.count())\n",
    "count = dataset.is_tautology.value_counts()\n",
    "print(f\"\\nNumber of True and False formulas: \\n{count}\\n\")\n",
    "\n",
    "total = len(dataset)\n",
    "tautologies = dataset[\"is_tautology\"].sum()\n",
    "percentage = (tautologies / total) * 100\n",
    "print(f\"Percentage of tautologies in the dataset: {percentage:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043224ed",
   "metadata": {},
   "source": [
    "--- \n",
    "#### **1.5 Preparing the Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c8f7d618",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T18:24:45.345371Z",
     "iopub.status.busy": "2025-05-29T18:24:45.345070Z",
     "iopub.status.idle": "2025-05-29T18:24:45.365860Z",
     "shell.execute_reply": "2025-05-29T18:24:45.364553Z",
     "shell.execute_reply.started": "2025-05-29T18:24:45.345340Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¬A0 ∨ A1\n",
      "¬(A0 ∨ A1)\n",
      "¬A0 ∨ A1 == ¬(A0 ∨ A1) shoud be false and is: False\n",
      "\n",
      "¬(A0 ∧ A1) → ¬A0 ∨ ¬A1\n",
      "¬(A0 ∨ A1) → ¬A0 ∧ ¬A1\n",
      "A0 ∧ (A1 ∨ A2) → (A0 ∧ A1) ∨ (A0 ∧ A2)\n"
     ]
    }
   ],
   "source": [
    "# --- Parser Module ---\n",
    "# Parses a string representation of a formula\n",
    "\n",
    "# Operator symbol to class map\n",
    "OPERATOR_CLASSES = {\n",
    "    '¬': Negation,\n",
    "    '∧': Conjunction,\n",
    "    '∨': Disjunction,\n",
    "    #'⊻': ExclusiveDisjunction,\n",
    "    '→': Implication\n",
    "}\n",
    "\n",
    "def tokenize(formula: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Splits a logical formula string into a list of tokens.\n",
    "\n",
    "    Supported tokens:\n",
    "        - Propositional letters: A0, A1, ...\n",
    "        - Connectives: ¬, ∧, ∨, ⊻, →\n",
    "        - Falsity: ⊥\n",
    "        - Parentheses: (,)\n",
    "\n",
    "    Args:\n",
    "        formula (str): A logical formula in string format.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: A list of string tokens (e.g. ['¬', '(', 'A0', '∧', 'A1', ')'])\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the formula contains an unrecognized character.  \n",
    "    \"\"\"\n",
    "    tokens = []\n",
    "    i = 0\n",
    "    # Iterate over each character\n",
    "    while i < len(formula):\n",
    "        c = formula[i]\n",
    "        # Skip whitespace\n",
    "        if c.isspace():\n",
    "            i += 1\n",
    "        elif c in '()¬∧∨⊻':\n",
    "            tokens.append(c)\n",
    "            i += 1\n",
    "        elif formula[i:i+1] == '→':  \n",
    "            tokens.append('→')\n",
    "            i += 1\n",
    "        elif c == 'A':\n",
    "            j = i + 1\n",
    "            while j < len(formula) and formula[j].isdigit():\n",
    "                j += 1\n",
    "            tokens.append(formula[i:j])\n",
    "            i = j\n",
    "        elif c == '⊥':\n",
    "            tokens.append('⊥')\n",
    "            i += 1\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected character: {c}\")\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def parse_formula_string(formula_string: str) -> Formula:\n",
    "    \"\"\"\n",
    "    Parses a string representation of a propositional logic formula into a\n",
    "    structured Formula object, respecting operator precedence and associativity.\n",
    "\n",
    "    Precedence and associativity are extracted directly from the formula classes.\n",
    "\n",
    "    Args:\n",
    "        formula_string (str): The input logical formula in string form.\n",
    "\n",
    "    Returns:\n",
    "        Formula: The parsed Formula object (e.g., Conjunction, Implication, etc.).\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the formula contains invalid or unexpected tokens.\n",
    "    \"\"\"\n",
    "    tokens = tokenize(formula_string)\n",
    "\n",
    "    def parse_expr(tokens: List[str], min_prec: int = 0) -> Formula:\n",
    "        \"\"\"\n",
    "        Recursively parses an expression using a precedence climbing strategy.\n",
    "\n",
    "        Args:\n",
    "            tokens (List[str]): List of tokens.\n",
    "            min_prec (int): Minimum precedence required to continue parsing.\n",
    "\n",
    "        Returns:\n",
    "            Formula: A Formula object representing the parsed structure.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: For invalid token sequences or unexpected syntax.\n",
    "        \"\"\"\n",
    "        if not tokens:\n",
    "            raise ValueError(\"Empty expression\")\n",
    "        \n",
    "        # Pick the first element of the list\n",
    "        token = tokens.pop(0)\n",
    "\n",
    "        # Base cases: atomic formulas\n",
    "        if token == '(':\n",
    "            # Handle parentheses by recursing on the subexpression\n",
    "            sub_tokens = []\n",
    "            depth = 1\n",
    "            while tokens:\n",
    "                t = tokens.pop(0)\n",
    "                if t == '(':\n",
    "                    depth += 1\n",
    "                elif t == ')':\n",
    "                    depth -= 1\n",
    "                    if depth == 0:\n",
    "                        break\n",
    "                sub_tokens.append(t)\n",
    "            node = parse_expr(sub_tokens)\n",
    "\n",
    "        elif token == '⊥':\n",
    "            node = Falsity()\n",
    "\n",
    "        elif token.startswith('A') and token[1:].isdigit():\n",
    "            node = Letter(int(token[1:]))\n",
    "\n",
    "        elif token == '¬':\n",
    "            # Unary operator\n",
    "            cls = Negation\n",
    "            right = parse_expr(tokens, cls.priority)\n",
    "            node = cls(right)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected token: {token}\")\n",
    "\n",
    "        # After parsing an atomic or unary expression, handle binary connectives\n",
    "        while tokens and tokens[0] in OPERATOR_CLASSES:\n",
    "            op = tokens[0]\n",
    "            cls = OPERATOR_CLASSES[op]\n",
    "            prec = cls.priority\n",
    "            assoc = cls.associativity\n",
    "\n",
    "            if prec < min_prec:\n",
    "                break\n",
    "\n",
    "            tokens.pop(0)  # consume the operator\n",
    "            \n",
    "            # Recursively parse the right-hand expression, and combine it with the \n",
    "            # left node into a full binary Formula\n",
    "            # Adjust min_prec depending on associativity\n",
    "            next_min_prec = prec + 1 if assoc == 'left' else prec\n",
    "\n",
    "            right = parse_expr(tokens, next_min_prec)\n",
    "            node = cls(node, right)\n",
    "\n",
    "        return node\n",
    "\n",
    "    return parse_expr(tokens)\n",
    "\n",
    "\n",
    "# Example 1: \n",
    "f1 = parse_formula_string(\"¬A0 ∨ A1\")\n",
    "f2 = parse_formula_string(\"¬(A0 ∨ A1)\")\n",
    "\n",
    "print(f1)  # (¬A0 ∨ A1)\n",
    "print(f2)  # ¬(A0 ∨ A1)\n",
    "print(f\"{f1} == {f2} shoud be false and is: {f1 == f2}\\n\")  # False — correct\n",
    "\n",
    "# Example 2:\n",
    "list_of_str = [\n",
    "    \"¬(A0 ∧ A1) → (¬A0 ∨ ¬A1)\",\n",
    "    \"¬(A0 ∨ A1) → (¬A0 ∧ ¬A1)\",\n",
    "    \"(A0 ∧ (A1 ∨ A2)) → ((A0 ∧ A1) ∨ (A0 ∧ A2))\"\n",
    "]\n",
    "\n",
    "for formula_str in list_of_str:\n",
    "    parsed_formulas = parse_formula_string(formula_str)\n",
    "    print(parsed_formulas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d7da40e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T18:24:45.367558Z",
     "iopub.status.busy": "2025-05-29T18:24:45.367252Z",
     "iopub.status.idle": "2025-05-29T18:24:45.377230Z",
     "shell.execute_reply": "2025-05-29T18:24:45.375824Z",
     "shell.execute_reply.started": "2025-05-29T18:24:45.367529Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13000, 13000)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Formulas and Truth Values lists ---\n",
    "Formulas = dataset['formula'].tolist()\n",
    "Truth_values = dataset['is_tautology'].tolist()\n",
    "\n",
    "len(Formulas), len(Truth_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c470fd0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T18:24:45.378817Z",
     "iopub.status.busy": "2025-05-29T18:24:45.378517Z",
     "iopub.status.idle": "2025-05-29T18:24:45.387863Z",
     "shell.execute_reply": "2025-05-29T18:24:45.386432Z",
     "shell.execute_reply.started": "2025-05-29T18:24:45.378789Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formula_set = set(Formulas)\n",
    "len(formula_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "695cdf96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T18:24:45.389423Z",
     "iopub.status.busy": "2025-05-29T18:24:45.389139Z",
     "iopub.status.idle": "2025-05-29T18:24:46.949674Z",
     "shell.execute_reply": "2025-05-29T18:24:46.948286Z",
     "shell.execute_reply.started": "2025-05-29T18:24:45.389394Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed second formula: (A0 → A1) ∨ ⊥ → ¬A2\n",
      "Total parsed formulas: 13000\n",
      "Number of distinct parsed formulas: 13000\n"
     ]
    }
   ],
   "source": [
    "# --- Parse Dataset's formulas ---\n",
    "parsed_formulas = [parse_formula_string(f) for f in Formulas]\n",
    "\n",
    "print(f\"Parsed second formula: {parsed_formulas[1]}\")\n",
    "print(f\"Total parsed formulas: {len(parsed_formulas)}\")\n",
    "\n",
    "distinct_formulas = set(parsed_formulas)\n",
    "print(f\"Number of distinct parsed formulas: {len(distinct_formulas)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a33bb508",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T18:24:46.955654Z",
     "iopub.status.busy": "2025-05-29T18:24:46.955334Z",
     "iopub.status.idle": "2025-05-29T18:24:46.970102Z",
     "shell.execute_reply": "2025-05-29T18:24:46.968986Z",
     "shell.execute_reply.started": "2025-05-29T18:24:46.955624Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 10400 samples\n",
      "Test set: 2600 samples\n"
     ]
    }
   ],
   "source": [
    "# Data splitting: 80% of the data is reserved for training the model. \n",
    "# Test Sets: 20% of the data is used for testing the model.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(parsed_formulas, \n",
    "                                                    Truth_values, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)\n",
    "\n",
    "print(f\"Training set: {len(X_train)} samples\")\n",
    "print(f\"Test set: {len(X_test)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "751c3eba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T18:24:46.971883Z",
     "iopub.status.busy": "2025-05-29T18:24:46.971560Z",
     "iopub.status.idle": "2025-05-29T18:24:47.001989Z",
     "shell.execute_reply": "2025-05-29T18:24:47.000281Z",
     "shell.execute_reply.started": "2025-05-29T18:24:46.971854Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Convert symbols in numbers ---\n",
    "class CustomTokenizer:\n",
    "    \"\"\"\n",
    "    Custom tokenizer class for logical formulas.\n",
    "    This class converts formulas into tokenized integer representations,\n",
    "    and supports detokenizing back into Formula objects.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.token_to_formula: Dict[int, Formula] = {}\n",
    "        self.formula_to_token: Dict[Formula, int] = {}\n",
    "\n",
    "        self.connective_map = {\n",
    "            'Conjunction': 100,\n",
    "            'Disjunction': 101,\n",
    "            'Negation': 102,\n",
    "            'Implication': 103,\n",
    "            #'Exclusive Disjunction': 104\n",
    "        }\n",
    "\n",
    "        self.special_map = {\n",
    "            '(': 106,\n",
    "            ')': 107\n",
    "        }\n",
    "\n",
    "        self.falsity_token = 105\n",
    "\n",
    "    def fit(self, formulas: List[Formula]):\n",
    "        \"\"\"\n",
    "        Fit the tokenizer on a list of formulas, deriving tokens for each formula.\n",
    "        \"\"\"\n",
    "        for formula in formulas:\n",
    "            self._derive_tokens(formula)\n",
    "\n",
    "    def _derive_tokens(self, formula: Formula):\n",
    "        \"\"\"\n",
    "        Recursively derive tokens for all subcomponents of a formula.\n",
    "        \"\"\"\n",
    "        if isinstance(formula, Falsity):\n",
    "            if formula not in self.formula_to_token:\n",
    "                self.formula_to_token[formula] = self.falsity_token\n",
    "                self.token_to_formula[self.falsity_token] = formula\n",
    "\n",
    "        elif isinstance(formula, Letter):\n",
    "            letter_index = formula.n\n",
    "            if formula not in self.formula_to_token:\n",
    "                token = letter_index + 1  # Start letters from 1\n",
    "                self.formula_to_token[formula] = token\n",
    "                self.token_to_formula[token] = formula\n",
    "\n",
    "        elif isinstance(formula, UnaryConnectiveFormula):\n",
    "            self._derive_tokens(formula.formula)\n",
    "\n",
    "        elif isinstance(formula, BinaryConnectiveFormula):\n",
    "            self._derive_tokens(formula.left)\n",
    "            self._derive_tokens(formula.right)\n",
    "\n",
    "    def tokenize(self, formula: Formula) -> List[int]:\n",
    "        \"\"\"\n",
    "        Convert a formula into a list of integer tokens.\n",
    "        \"\"\"\n",
    "        tokens = []\n",
    "        self._tokenize_helper(formula, tokens)\n",
    "        return tokens\n",
    "\n",
    "    def _tokenize_helper(self, formula: Formula, tokens: List[int]):\n",
    "        \"\"\"\n",
    "        Helper method for recursive token generation.\n",
    "        \"\"\"\n",
    "        if formula in self.formula_to_token:\n",
    "            tokens.append(self.formula_to_token[formula])\n",
    "            return\n",
    "\n",
    "        if isinstance(formula, BinaryConnectiveFormula):\n",
    "            tokens.append(self.special_map['('])\n",
    "            self._tokenize_helper(formula.left, tokens)\n",
    "            tokens.append(self.connective_map[type(formula).__name__])\n",
    "            self._tokenize_helper(formula.right, tokens)\n",
    "            tokens.append(self.special_map[')'])\n",
    "\n",
    "        elif isinstance(formula, UnaryConnectiveFormula):\n",
    "            tokens.append(self.special_map['('])\n",
    "            tokens.append(self.connective_map[type(formula).__name__])\n",
    "            tokens.append(self.special_map['('])\n",
    "            self._tokenize_helper(formula.formula, tokens)\n",
    "            tokens.append(self.special_map[')'])\n",
    "            tokens.append(self.special_map[')'])\n",
    "\n",
    "        elif isinstance(formula, Falsity):\n",
    "            tokens.append(self.falsity_token)\n",
    "\n",
    "        elif isinstance(formula, Letter):\n",
    "            tokens.append(self.formula_to_token[formula])\n",
    "\n",
    "    def detokenize(self, tokens: List[int]) -> Formula:\n",
    "        \"\"\"\n",
    "        Convert a list of tokens (possibly padded) back into a Formula object.\n",
    "        \"\"\"\n",
    "        # Remove trailing padding\n",
    "        tokens = [t for t in tokens if t != 0]\n",
    "\n",
    "        def parse_expr(pos: int) -> Tuple[Formula, int]:\n",
    "            token = tokens[pos]\n",
    "\n",
    "            if token == self.falsity_token:\n",
    "                return Falsity(), pos + 1\n",
    "\n",
    "            elif token in self.token_to_formula:\n",
    "                return self.token_to_formula[token], pos + 1\n",
    "\n",
    "            elif token == self.special_map['(']:\n",
    "                next_token = tokens[pos + 1]\n",
    "\n",
    "                # Handle unary connective\n",
    "                if next_token in self.connective_map.values() and tokens[pos + 2] == self.special_map['(']:\n",
    "                    op_token = next_token\n",
    "                    inner_formula, new_pos = parse_expr(pos + 3)\n",
    "                    assert tokens[new_pos] == self.special_map[')']\n",
    "                    assert tokens[new_pos + 1] == self.special_map[')']\n",
    "                    connective_class = self._connective_class(op_token)\n",
    "                    return connective_class(inner_formula), new_pos + 2\n",
    "\n",
    "                # Handle binary connective\n",
    "                else:\n",
    "                    left_formula, pos_left = parse_expr(pos + 1)\n",
    "                    op_token = tokens[pos_left]\n",
    "                    right_formula, pos_right = parse_expr(pos_left + 1)\n",
    "                    assert tokens[pos_right] == self.special_map[')']\n",
    "                    connective_class = self._connective_class(op_token)\n",
    "                    return connective_class(left_formula, right_formula), pos_right + 1\n",
    "\n",
    "            raise ValueError(f\"Unexpected token at position {pos}: {tokens[pos:]}\")\n",
    "\n",
    "        return parse_expr(0)[0]\n",
    "\n",
    "    def _connective_class(self, token: int):\n",
    "        \"\"\"\n",
    "        Resolve token ID back to the appropriate connective class.\n",
    "        \"\"\"\n",
    "        for name, code in self.connective_map.items():\n",
    "            if token == code:\n",
    "                return {\n",
    "                    'Conjunction': Conjunction,\n",
    "                    'Disjunction': Disjunction,\n",
    "                    'Negation': Negation,\n",
    "                    'Implication': Implication,\n",
    "                    #'Exclusive Disjunction': ExclusiveDisjunction\n",
    "                }[name]\n",
    "        raise ValueError(f\"Unknown connective token: {token}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "26c0880c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T18:24:47.003776Z",
     "iopub.status.busy": "2025-05-29T18:24:47.003451Z",
     "iopub.status.idle": "2025-05-29T18:24:47.472300Z",
     "shell.execute_reply": "2025-05-29T18:24:47.470927Z",
     "shell.execute_reply.started": "2025-05-29T18:24:47.003747Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: 105, Formula: ⊥\n",
      "Token: 1, Formula: A0\n",
      "Token: 2, Formula: A1\n",
      "Token: 3, Formula: A2\n",
      "Token: 4, Formula: A3\n",
      "Token: 5, Formula: A4\n",
      "Token: 6, Formula: A5\n",
      "Token: 7, Formula: A6\n",
      "Token: 8, Formula: A7\n",
      "\n",
      "Tokenized representation of (A0 ∧ ¬A1): [106, 1, 100, 106, 102, 106, 2, 107, 107, 107]\n"
     ]
    }
   ],
   "source": [
    "# Inspect unique formula's token \n",
    "tokenizer = CustomTokenizer()\n",
    "tokenizer.fit(parsed_formulas)\n",
    "\n",
    "def print_token_mappings(tokenizer):\n",
    "    for token, formula in tokenizer.token_to_formula.items():\n",
    "        print(f\"Token: {token}, Formula: {formula}\")\n",
    "\n",
    "print_token_mappings(tokenizer)\n",
    "\n",
    "# Example\n",
    "example_formula = Conjunction(Letter(0), Negation(Letter(1)))\n",
    "tokens = tokenizer.tokenize(example_formula)\n",
    "\n",
    "print(f\"\\nTokenized representation of ({example_formula}): {tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4c37a5ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T18:24:47.473895Z",
     "iopub.status.busy": "2025-05-29T18:24:47.473583Z",
     "iopub.status.idle": "2025-05-29T18:24:47.848655Z",
     "shell.execute_reply": "2025-05-29T18:24:47.847448Z",
     "shell.execute_reply.started": "2025-05-29T18:24:47.473866Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Tokenize Train Test ---\n",
    "tokenizer = CustomTokenizer()\n",
    "tokenizer.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a32a2559",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T18:24:47.850393Z",
     "iopub.status.busy": "2025-05-29T18:24:47.850087Z",
     "iopub.status.idle": "2025-05-29T18:24:47.858574Z",
     "shell.execute_reply": "2025-05-29T18:24:47.857086Z",
     "shell.execute_reply.started": "2025-05-29T18:24:47.850363Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Formula: (¬A0 ∨ A1) ∧ (A2 ∨ (¬A3 → A4))\n",
      "Tokenized Version: [106, 106, 106, 102, 106, 1, 107, 107, 101, 2, 107, 100, 106, 3, 101, 106, 106, 102, 106, 4, 107, 107, 103, 5, 107, 107, 107]\n",
      "\n",
      "Original Formula: (¬A0 → ¬(A1 ∧ A2 → A3 → A4)) → A5\n",
      "Tokenized Version: [106, 106, 106, 102, 106, 1, 107, 107, 103, 106, 102, 106, 106, 106, 2, 100, 3, 107, 103, 106, 4, 103, 5, 107, 107, 107, 107, 107, 103, 6, 107]\n",
      "\n",
      "Original Formula: ¬⊥ ∧ (A0 ∨ A1)\n",
      "Tokenized Version: [106, 106, 102, 106, 105, 107, 107, 100, 106, 1, 101, 2, 107, 107]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test function\n",
    "def test_tokenizer(tokenizer, example_formulas):\n",
    "    for formula in example_formulas:\n",
    "        tokens = tokenizer.tokenize(formula)\n",
    "        print(f\"Original Formula: {formula}\")\n",
    "        print(f\"Tokenized Version: {tokens}\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tokenizer = CustomTokenizer()\n",
    "    example_formulas = [X_train[2], X_train[3], X_train[4]]\n",
    "    tokenizer.fit(example_formulas)\n",
    "\n",
    "    test_tokenizer(tokenizer, example_formulas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "44cb5150",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T18:24:47.860007Z",
     "iopub.status.busy": "2025-05-29T18:24:47.859730Z",
     "iopub.status.idle": "2025-05-29T18:24:48.234211Z",
     "shell.execute_reply": "2025-05-29T18:24:48.232851Z",
     "shell.execute_reply.started": "2025-05-29T18:24:47.859979Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique letters: 8\n",
      "Number of unique connectives: 4\n",
      "Number of spacial tokens: 2\n"
     ]
    }
   ],
   "source": [
    "tokenizer = CustomTokenizer()\n",
    "tokenizer.fit(X_train)\n",
    "\n",
    "num_letters = sum(1 for formula in tokenizer.formula_to_token if isinstance(formula, Letter))\n",
    "num_connectives = len(tokenizer.connective_map)\n",
    "num_parenthesis = sum(1 for formula in tokenizer.special_map)\n",
    "\n",
    "print(f\"Number of unique letters: {num_letters}\")\n",
    "print(f\"Number of unique connectives: {num_connectives}\")\n",
    "print(f\"Number of spacial tokens: {num_parenthesis}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2e3e14f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T18:24:48.235920Z",
     "iopub.status.busy": "2025-05-29T18:24:48.235539Z",
     "iopub.status.idle": "2025-05-29T18:24:49.471382Z",
     "shell.execute_reply": "2025-05-29T18:24:49.470140Z",
     "shell.execute_reply.started": "2025-05-29T18:24:48.235880Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Tokenize Train and Test formulas ---\n",
    "tokenizer = CustomTokenizer()\n",
    "tokenizer.fit(X_train)\n",
    "\n",
    "X_train_seq = [tokenizer.tokenize(formula) for formula in X_train]\n",
    "X_test_seq = [tokenizer.tokenize(formula) for formula in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "840721b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T18:24:49.473539Z",
     "iopub.status.busy": "2025-05-29T18:24:49.473210Z",
     "iopub.status.idle": "2025-05-29T18:24:49.785188Z",
     "shell.execute_reply": "2025-05-29T18:24:49.783981Z",
     "shell.execute_reply.started": "2025-05-29T18:24:49.473509Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Convert lists of int into tensors ---\n",
    "X_train_tensors = [torch.tensor(seq, dtype=torch.long) for seq in X_train_seq]\n",
    "X_test_tensors = [torch.tensor(seq, dtype=torch.long) for seq in X_test_seq]\n",
    "\n",
    "# --- Pad sequences (fill with 0s) ---\n",
    "X_train_padded = pad_sequence(X_train_tensors, batch_first=True, padding_value=0) # With batch_first = True, Shape: (batch_size, seq_len, features)\n",
    "X_test_padded = pad_sequence(X_test_tensors, batch_first=True, padding_value=0)\n",
    "\n",
    "# --- Convert labels to tensors --- \n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c1b28f9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T18:24:49.786862Z",
     "iopub.status.busy": "2025-05-29T18:24:49.786555Z",
     "iopub.status.idle": "2025-05-29T18:24:49.793567Z",
     "shell.execute_reply": "2025-05-29T18:24:49.792379Z",
     "shell.execute_reply.started": "2025-05-29T18:24:49.786833Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_padded shape: torch.Size([10400, 603]) -> [num_of_tokenized_formulas, num_of_tokens_per_formula])\n",
      "y_train_tensor shape: torch.Size([10400]) -> [num_of_labels]\n",
      "\n",
      "X_test_padded shape: torch.Size([2600, 545]) -> [num_of_tokenized_formulas, num_of_tokens_per_formula])\n",
      "y_test_tensor shape: torch.Size([10400]) -> [num_of_labels]\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train_padded shape: {X_train_padded.shape} -> [num_of_tokenized_formulas, num_of_tokens_per_formula])\")\n",
    "print(f\"y_train_tensor shape: {y_train_tensor.shape} -> [num_of_labels]\")\n",
    "\n",
    "print(f\"\\nX_test_padded shape: {X_test_padded.shape} -> [num_of_tokenized_formulas, num_of_tokens_per_formula])\")\n",
    "print(f\"y_test_tensor shape: {y_train_tensor.shape} -> [num_of_labels]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5fc42e",
   "metadata": {},
   "source": [
    "---\n",
    "#### **1.6 Getting a PyTorch Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2f92b0cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T18:24:49.795102Z",
     "iopub.status.busy": "2025-05-29T18:24:49.794775Z",
     "iopub.status.idle": "2025-05-29T18:24:49.804883Z",
     "shell.execute_reply": "2025-05-29T18:24:49.803794Z",
     "shell.execute_reply.started": "2025-05-29T18:24:49.795073Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset FormulaDataset\n",
      "  Number of datapoints: 10400\n",
      "  Input shape: torch.Size([603])\n",
      "  Target type: torch.float32\n",
      " \n",
      "Dataset FormulaDataset\n",
      "  Number of datapoints: 2600\n",
      "  Input shape: torch.Size([545])\n",
      "  Target type: torch.float32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Create a PyTorch Dataset ---\n",
    "class FormulaDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "        # Define class label info\n",
    "        self.classes = ['non-tautology', 'tautology']\n",
    "        self.class_to_idx = {label: i for i, label in enumerate(self.classes)}\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (\n",
    "            f\"Dataset FormulaDataset\\n\"\n",
    "            f\"  Number of datapoints: {len(self)}\\n\"\n",
    "            f\"  Input shape: {self.X[0].shape if len(self.X) > 0 else 'N/A'}\\n\"\n",
    "            f\"  Target type: {self.y.dtype}\\n\"\n",
    "        )\n",
    "\n",
    "\n",
    "train_data = FormulaDataset(X_train_padded, y_train_tensor)\n",
    "test_data = FormulaDataset(X_test_padded, y_test_tensor)\n",
    "\n",
    "print(f\"{train_data} \\n{test_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "df48c638",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T18:24:49.806587Z",
     "iopub.status.busy": "2025-05-29T18:24:49.806231Z",
     "iopub.status.idle": "2025-05-29T18:24:49.814068Z",
     "shell.execute_reply": "2025-05-29T18:24:49.812987Z",
     "shell.execute_reply.started": "2025-05-29T18:24:49.806558Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train class counts: Counter({False: 7662, True: 2738})\n",
      "Test class counts: Counter({False: 1914, True: 686})\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "train_class_counts = collections.Counter(y_train)\n",
    "test_class_counts = collections.Counter(y_test)\n",
    "\n",
    "print(f\"Train class counts: {train_class_counts}\")\n",
    "print(f\"Test class counts: {test_class_counts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2b5e81f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T18:24:49.815646Z",
     "iopub.status.busy": "2025-05-29T18:24:49.815336Z",
     "iopub.status.idle": "2025-05-29T18:24:49.822493Z",
     "shell.execute_reply": "2025-05-29T18:24:49.821338Z",
     "shell.execute_reply.started": "2025-05-29T18:24:49.815617Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set (47998 samples): False = 76.50 % and True = 23.50 %\n",
      "Test set (240samples): False = 77.00% and True = 23.00%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train set (47998 samples): False = {(3671/4799)*100:.2f} % and True = {(1128/4799)* 100:.2f} %\")\n",
    "print(f\"Test set (240samples): False = {(924/1200)*100:.2f}% and True = {(276/1200)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b46bf173",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T18:24:49.824042Z",
     "iopub.status.busy": "2025-05-29T18:24:49.823739Z",
     "iopub.status.idle": "2025-05-29T18:24:50.563556Z",
     "shell.execute_reply": "2025-05-29T18:24:50.562310Z",
     "shell.execute_reply.started": "2025-05-29T18:24:49.824013Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Convert lists of int into tensors ---\n",
    "X_train_tensors = [torch.tensor(seq, dtype=torch.long) for seq in X_train_seq]\n",
    "X_test_tensors = [torch.tensor(seq, dtype=torch.long) for seq in X_test_seq]\n",
    "\n",
    "# --- Pad sequences (fill with 0s) ---\n",
    "X_train_padded = pad_sequence(X_train_tensors, batch_first=True, padding_value=0) # With batch_first = True, Shape: (batch_size, seq_len, features)\n",
    "X_test_padded = pad_sequence(X_test_tensors, batch_first=True, padding_value=0)\n",
    "\n",
    "# --- Convert labels to tensors --- \n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2c869278",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T18:24:50.565662Z",
     "iopub.status.busy": "2025-05-29T18:24:50.565345Z",
     "iopub.status.idle": "2025-05-29T18:24:50.571795Z",
     "shell.execute_reply": "2025-05-29T18:24:50.570594Z",
     "shell.execute_reply.started": "2025-05-29T18:24:50.565632Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['non-tautology', 'tautology']\n",
      "{'non-tautology': 0, 'tautology': 1}\n"
     ]
    }
   ],
   "source": [
    "# Classes Names and Labels Map\n",
    "class_names = train_data.classes\n",
    "class_to_idx = train_data.class_to_idx\n",
    "print(class_names)\n",
    "print(class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "904657b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T18:24:50.573315Z",
     "iopub.status.busy": "2025-05-29T18:24:50.573005Z",
     "iopub.status.idle": "2025-05-29T18:24:50.588567Z",
     "shell.execute_reply": "2025-05-29T18:24:50.587399Z",
     "shell.execute_reply.started": "2025-05-29T18:24:50.573283Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random formula: tensor([106, 106,   1, 100, 106, 106, 106,   2, 103,   3, 107, 101, 106, 102,\n",
      "        106,   4, 107, 107, 107, 103, 106,   5, 101, 106, 102, 106,   6, 107,\n",
      "        107, 107, 107, 107, 103,   7, 107,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0]), \n",
      "\n",
      "Label: 0.0\n",
      "Reconstructed formula: A0 ∧ ((A1 → A2) ∨ ¬A3 → A4 ∨ ¬A5) → A6\n",
      "\n",
      "Tautology status: non-tautology\n"
     ]
    }
   ],
   "source": [
    "# Visualizing a random sampled formula\n",
    "torch.manual_seed(42)\n",
    "random_idx = torch.randint(0, len(train_data), size=[1]).item()\n",
    "\n",
    "random_formula, label = train_data[random_idx]\n",
    "print(f\"Random formula: {random_formula}, \\n\\nLabel: {label}\")\n",
    "\n",
    "# Convert tensor to list of token IDs (needed by detokenize)\n",
    "token_list = random_formula.tolist()\n",
    "# Reconstruct the original Formula\n",
    "reconstructed_formula = tokenizer.detokenize(token_list)\n",
    "print(f\"Reconstructed formula: {reconstructed_formula}\")\n",
    "print(f\"\\nTautology status: {class_names[int(label.item())]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08a7c9a",
   "metadata": {},
   "source": [
    "----\n",
    "#### **1.7 DataLoader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e3b476-028f-4bcc-abf2-d4b3fc930c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the batch size hyperparameter\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# Turn datasets into iterables (batches)\n",
    "train_dataloader = DataLoader(train_data, # dataset to turn into iterable\n",
    "                              batch_size=BATCH_SIZE, # how many samples per batch? \n",
    "                              shuffle=True # shuffle data every epoch?\n",
    "                                           # This removes the data order, so the model does not learn it \n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(test_data,\n",
    "                             batch_size=BATCH_SIZE,\n",
    "                             shuffle=False # don't necessarily have to shuffle the testing data\n",
    ")\n",
    "\n",
    "# Let's check out what we've created\n",
    "print(f\"Dataloaders: {train_dataloader, test_dataloader}\") \n",
    "print(f\"Length of train dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}\")\n",
    "print(f\"Length of test dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dca774c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T02:46:55.887967Z",
     "iopub.status.busy": "2025-05-27T02:46:55.887655Z",
     "iopub.status.idle": "2025-05-27T02:46:55.896928Z",
     "shell.execute_reply": "2025-05-27T02:46:55.895776Z",
     "shell.execute_reply.started": "2025-05-27T02:46:55.887934Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(torch.Size([16, 603]), torch.Size([16])) -> [batch_size, num_of_tokens_per_formula], [bach_size]\n"
     ]
    }
   ],
   "source": [
    "# Check out what's inside the training dataloader\n",
    "train_features_batch, train_labels_batch = next(iter(train_dataloader)) # next() grabs the first batch from the iterator\n",
    "print(f\"{train_features_batch.shape, train_labels_batch.shape} -> [batch_size, num_of_tokens_per_formula], [bach_size]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc7077f",
   "metadata": {},
   "source": [
    "---\n",
    "#### **1.8 Set up device agnostic-code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f4272ed5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T02:46:55.898986Z",
     "iopub.status.busy": "2025-05-27T02:46:55.898692Z",
     "iopub.status.idle": "2025-05-27T02:46:56.048705Z",
     "shell.execute_reply": "2025-05-27T02:46:56.047402Z",
     "shell.execute_reply.started": "2025-05-27T02:46:55.898955Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa66ea7f",
   "metadata": {},
   "source": [
    "--- \n",
    "#### **1.9 Reproducibility**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8f0bf1b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T02:46:56.050065Z",
     "iopub.status.busy": "2025-05-27T02:46:56.049773Z",
     "iopub.status.idle": "2025-05-27T02:46:56.055988Z",
     "shell.execute_reply": "2025-05-27T02:46:56.054940Z",
     "shell.execute_reply.started": "2025-05-27T02:46:56.050030Z"
    }
   },
   "outputs": [],
   "source": [
    "def set_seeds(seed: int=42):\n",
    "    \"\"\"Sets random sets for torch operations.\n",
    "\n",
    "    Args:\n",
    "        seed (int, optional): Random seed to set. Defaults to 42.\n",
    "    \"\"\"\n",
    "    # Set the seed for general torch operations\n",
    "    torch.manual_seed(seed)\n",
    "    # Set the seed for CUDA torch operations (ones that happen on the GPU)\n",
    "    #torch.mps.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c07d245",
   "metadata": {},
   "source": [
    "--- \n",
    "#### **1.10 Create `train_step()` and `test_step()` functions, and `test()` function to combne them**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aec2d140",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T02:46:56.057535Z",
     "iopub.status.busy": "2025-05-27T02:46:56.057222Z",
     "iopub.status.idle": "2025-05-27T02:46:56.081246Z",
     "shell.execute_reply": "2025-05-27T02:46:56.080277Z",
     "shell.execute_reply.started": "2025-05-27T02:46:56.057504Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Functions for training and testing a PyTorch model ---\n",
    "\n",
    "def train_step(model: torch.nn.Module, \n",
    "               dataloader: torch.utils.data.DataLoader, \n",
    "               loss_fn: torch.nn.Module, \n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               device: torch.device) -> Tuple[float, float]:\n",
    "  \"\"\"Trains a PyTorch model for a single epoch.\n",
    "\n",
    "  Turns a target PyTorch model to training mode and then\n",
    "  runs through all of the required training steps (forward\n",
    "  pass, loss calculation, optimizer step).\n",
    "\n",
    "  Args:\n",
    "    model: A PyTorch model to be trained.\n",
    "    dataloader: A DataLoader instance for the model to be trained on.\n",
    "    loss_fn: A PyTorch loss function to minimize.\n",
    "    optimizer: A PyTorch optimizer to help minimize the loss function.\n",
    "    device: A target device to compute on.\n",
    "\n",
    "  Returns:\n",
    "    A tuple of training loss and training accuracy metrics.\n",
    "    In the form (train_loss, train_accuracy).\n",
    "    \n",
    "  \"\"\"\n",
    "  # Put model in train mode\n",
    "  model.train()\n",
    "  \n",
    "  # Setup train loss and train accuracy values\n",
    "  train_loss, train_acc = 0, 0\n",
    "  \n",
    "  # Loop through data loader data batches\n",
    "  for batch, (X, y) in enumerate(dataloader):\n",
    "      # Send data to target device\n",
    "      X, y = X.to(device), y.to(device)\n",
    "\n",
    "      # 1. Forward pass\n",
    "      y_logits = model(X).squeeze(dim=1)\n",
    "      y_preds = torch.round(torch.sigmoid(y_logits))\n",
    "\n",
    "      # 2. Calculate  and accumulate loss\n",
    "      loss = loss_fn(y_logits, y)\n",
    "      train_loss += loss.item() \n",
    "\n",
    "      # 3. Optimizer zero grad\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      # 4. Loss backward\n",
    "      loss.backward()\n",
    "\n",
    "      # 5. Optimizer step\n",
    "      optimizer.step()\n",
    "\n",
    "      # Calculate and accumulate accuracy metric across all batches\n",
    "      train_acc += (y_preds == y).sum().item()/len(y_preds)\n",
    "\n",
    "  # Adjust metrics to get average loss and accuracy per batch \n",
    "  train_loss = train_loss / len(dataloader)\n",
    "  train_acc = train_acc / len(dataloader)\n",
    "  return train_loss, train_acc\n",
    "\n",
    "def test_step(model: torch.nn.Module, \n",
    "              dataloader: torch.utils.data.DataLoader, \n",
    "              loss_fn: torch.nn.Module,\n",
    "              device: torch.device) -> Tuple[float, float]:\n",
    "  \"\"\"Tests a PyTorch model for a single epoch.\n",
    "\n",
    "  Turns a target PyTorch model to \"eval\" mode and then performs\n",
    "  a forward pass on a testing dataset.\n",
    "\n",
    "  Args:\n",
    "    model: A PyTorch model to be tested.\n",
    "    dataloader: A DataLoader instance for the model to be tested on.\n",
    "    loss_fn: A PyTorch loss function to calculate loss on the test data.\n",
    "    device: A target device to compute on.\n",
    "\n",
    "  Returns:\n",
    "    A tuple of testing loss and testing accuracy metrics.\n",
    "    In the form (test_loss, test_accuracy). \n",
    "    \n",
    "  \"\"\"\n",
    "  # Put model in eval mode\n",
    "  model.eval() \n",
    "  \n",
    "  # Setup test loss and test accuracy values\n",
    "  test_loss, test_acc = 0, 0\n",
    "  \n",
    "  # Turn on inference context manager\n",
    "  with torch.inference_mode():\n",
    "      # Loop through DataLoader batches\n",
    "      for batch, (X, y) in enumerate(dataloader):\n",
    "          # Send data to target device\n",
    "          X, y = X.to(device), y.to(device)\n",
    "  \n",
    "          # 1. Forward pass\n",
    "          test_pred_logits = model(X).squeeze(dim=1)\n",
    "          preds = torch.round(torch.sigmoid(test_pred_logits))\n",
    "\n",
    "          # 2. Calculate and accumulate loss\n",
    "          loss = loss_fn(test_pred_logits, y)\n",
    "          test_loss += loss.item()\n",
    "          \n",
    "          # Calculate and accumulate accuracy\n",
    "          test_pred_labels = preds\n",
    "          test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
    "          \n",
    "  # Adjust metrics to get average loss and accuracy per batch \n",
    "  test_loss = test_loss / len(dataloader)\n",
    "  test_acc = test_acc / len(dataloader)\n",
    "  return test_loss, test_acc\n",
    "\n",
    "def train(model: torch.nn.Module, \n",
    "          train_dataloader: torch.utils.data.DataLoader, \n",
    "          test_dataloader: torch.utils.data.DataLoader, \n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          loss_fn: torch.nn.Module,\n",
    "          epochs: int,\n",
    "          device: torch.device) -> Dict[str, List]:\n",
    "  \"\"\"Trains and tests a PyTorch model.\n",
    "\n",
    "  Passes a target PyTorch models through train_step() and test_step()\n",
    "  functions for a number of epochs, training and testing the model\n",
    "  in the same epoch loop.\n",
    "\n",
    "  Calculates, prints and stores evaluation metrics throughout.\n",
    "\n",
    "  Args:\n",
    "    model: A PyTorch model to be trained and tested.\n",
    "    train_dataloader: A DataLoader instance for the model to be trained on.\n",
    "    test_dataloader: A DataLoader instance for the model to be tested on.\n",
    "    optimizer: A PyTorch optimizer to help minimize the loss function.\n",
    "    loss_fn: A PyTorch loss function to calculate loss on both datasets.\n",
    "    epochs: An integer indicating how many epochs to train for.\n",
    "    device: A target device to compute on.\n",
    "\n",
    "  Returns:\n",
    "    A dictionary of training and testing loss as well as training and\n",
    "    testing accuracy metrics. Each metric has a value in a list for \n",
    "    each epoch.\n",
    "    In the form: {train_loss: [...],\n",
    "                  train_acc: [...],\n",
    "                  test_loss: [...],\n",
    "                  test_acc: [...]} \n",
    "\n",
    "  \"\"\"\n",
    "  # Create empty results dictionary\n",
    "  results = {\"train_loss\": [],\n",
    "             \"train_acc\": [],\n",
    "             \"test_loss\": [],\n",
    "             \"test_acc\": []\n",
    "  }\n",
    "  \n",
    "  # Loop through training and testing steps for a number of epochs\n",
    "  for epoch in tqdm(range(epochs)):\n",
    "      train_loss, train_acc = train_step(model=model,\n",
    "                                          dataloader=train_dataloader,\n",
    "                                          loss_fn=loss_fn,\n",
    "                                          optimizer=optimizer,\n",
    "                                          device=device)\n",
    "      test_loss, test_acc = test_step(model=model,\n",
    "          dataloader=test_dataloader,\n",
    "          loss_fn=loss_fn,\n",
    "          device=device)\n",
    "      \n",
    "      # Print out what's happening\n",
    "      print(\n",
    "          f\"Epoch: {epoch+1} | \"\n",
    "          f\"train_loss: {train_loss:.4f} | \"\n",
    "          f\"train_acc: {train_acc:.4f} | \"\n",
    "          f\"test_loss: {test_loss:.4f} | \"\n",
    "          f\"test_acc: {test_acc:.4f}\"\n",
    "      )\n",
    "\n",
    "      # Update results dictionary\n",
    "      results[\"train_loss\"].append(train_loss)\n",
    "      results[\"train_acc\"].append(train_acc)\n",
    "      results[\"test_loss\"].append(test_loss)\n",
    "      results[\"test_acc\"].append(test_acc)\n",
    "\n",
    "  # Return the filled results at the end of the epochs\n",
    "  return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417d8bde",
   "metadata": {},
   "source": [
    "---\n",
    "#### **1.11 Function to save a model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fd07e96a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T02:46:56.083164Z",
     "iopub.status.busy": "2025-05-27T02:46:56.082870Z",
     "iopub.status.idle": "2025-05-27T02:46:56.090466Z",
     "shell.execute_reply": "2025-05-27T02:46:56.089095Z",
     "shell.execute_reply.started": "2025-05-27T02:46:56.083133Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_model(model: torch.nn.Module,\n",
    "               target_dir: str,\n",
    "               model_name: str):\n",
    "  \"\"\"Saves a PyTorch model to a target directory.\n",
    "\n",
    "  Args:\n",
    "    model: A target PyTorch model to save.\n",
    "    target_dir: A directory for saving the model to.\n",
    "    model_name: A filename for the saved model. Should include\n",
    "      either \".pth\" or \".pt\" as the file extension.\n",
    "  \n",
    "  Example usage:\n",
    "    save_model(model=model_0,\n",
    "               target_dir=\"models\",\n",
    "               model_name=\"05_going_modular_tingvgg_model.pth\")\n",
    "  \"\"\"\n",
    "  # Create target directory\n",
    "  target_dir_path = Path(target_dir)\n",
    "  target_dir_path.mkdir(parents=True,\n",
    "                        exist_ok=True)\n",
    "  \n",
    "  # Create model save path\n",
    "  assert model_name.endswith(\".pth\") or model_name.endswith(\".pt\"), \"model_name should end with '.pt' or '.pth'\"\n",
    "  model_save_path = target_dir_path / model_name\n",
    "\n",
    "  # Save the model state_dict()\n",
    "  print(f\"[INFO] Saving model to: {model_save_path}\")\n",
    "  torch.save(obj=model.state_dict(),\n",
    "             f=model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddcec8b",
   "metadata": {},
   "source": [
    "---\n",
    "#### **1.12 Hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d6daeb70-62a3-4947-9ebf-d4ae061ef2ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T02:46:56.091562Z",
     "iopub.status.busy": "2025-05-27T02:46:56.091293Z",
     "iopub.status.idle": "2025-05-27T02:46:56.099666Z",
     "shell.execute_reply": "2025-05-27T02:46:56.098677Z",
     "shell.execute_reply.started": "2025-05-27T02:46:56.091532Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size (including padding token): 108\n",
      "Max index in batch: 107\n"
     ]
    }
   ],
   "source": [
    "# --- Hyperparameters --- \n",
    "# Determine the vocabulary size for the embedding layer and add 1 for padding index (0)\n",
    "all_token_indices = (\n",
    "    list(tokenizer.formula_to_token.values()) +\n",
    "    list(tokenizer.connective_map.values()) +\n",
    "    list(tokenizer.special_map.values()) +\n",
    "    [tokenizer.falsity_token]\n",
    ")\n",
    "\n",
    "VOCAB_SIZE = max(all_token_indices) + 1  \n",
    "print(f\"Vocabulary size (including padding token): {VOCAB_SIZE}\")\n",
    "print(\"Max index in batch:\", train_features_batch.max().item())\n",
    "assert train_features_batch.max().item() < VOCAB_SIZE, \"Some token indices exceed the embedding size!\"\n",
    "\n",
    "EMBEDDING_DIM = 32\n",
    "LR = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f110be8",
   "metadata": {},
   "source": [
    "---\n",
    "#### **Build Model 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0babb440",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T02:46:56.100989Z",
     "iopub.status.busy": "2025-05-27T02:46:56.100716Z",
     "iopub.status.idle": "2025-05-27T02:46:56.109505Z",
     "shell.execute_reply": "2025-05-27T02:46:56.108760Z",
     "shell.execute_reply.started": "2025-05-27T02:46:56.100959Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch of formula sequences shape: torch.Size([16, 603]) -> [batch_size, seq_len]\n",
      "Embedding Layer output shape: torch.Size([16, 603, 32]) -> [batch_size, seq_len, embed_dim]\n"
     ]
    }
   ],
   "source": [
    "# --- Embedding layer ---\n",
    "# This layer converts each token (represented as an integer ID) into a dense, trainable vector.\n",
    "# Using an embedding is essential because raw integer token IDs have no semantic meaning to the model.\n",
    "# The embedding allows the model to learn useful representations of logical symbols (e.g., A0, ∧, ¬, etc.)\n",
    "# based on how they are used in formulas — similar symbols can develop similar vector representations.\n",
    "# Without this layer, feeding raw integers into the model would mislead it into thinking larger token IDs are \"more\" important,\n",
    "# which is not true for symbolic data.\n",
    "\n",
    "embedding = nn.Embedding(num_embeddings=VOCAB_SIZE, embedding_dim=EMBEDDING_DIM)\n",
    "\n",
    "x = train_features_batch\n",
    "output_1 = embedding(x)\n",
    "print(f\"First batch of formula sequences shape: {train_features_batch.shape} -> [batch_size, seq_len]\")\n",
    "print(f\"Embedding Layer output shape: {output_1.shape} -> [batch_size, seq_len, embed_dim]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "49cfb5ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T02:46:56.111159Z",
     "iopub.status.busy": "2025-05-27T02:46:56.110294Z",
     "iopub.status.idle": "2025-05-27T02:46:56.120265Z",
     "shell.execute_reply": "2025-05-27T02:46:56.119037Z",
     "shell.execute_reply.started": "2025-05-27T02:46:56.111128Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size (including padding token): 108\n",
      "Max index in batch: 107\n"
     ]
    }
   ],
   "source": [
    "# --- Hyperparameters --- \n",
    "# Determine the vocabulary size for the embedding layer and add 1 for padding index (0)\n",
    "all_token_indices = (\n",
    "    list(tokenizer.formula_to_token.values()) +\n",
    "    list(tokenizer.connective_map.values()) +\n",
    "    list(tokenizer.special_map.values()) +\n",
    "    [tokenizer.falsity_token]\n",
    ")\n",
    "\n",
    "VOCAB_SIZE = max(all_token_indices) + 1  \n",
    "print(f\"Vocabulary size (including padding token): {VOCAB_SIZE}\")\n",
    "print(\"Max index in batch:\", train_features_batch.max().item())\n",
    "assert train_features_batch.max().item() < VOCAB_SIZE, \"Some token indices exceed the embedding size!\"\n",
    "\n",
    "EMBEDDING_DIM = 32\n",
    "HIDDEN_DIM = 10\n",
    "LR = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6abc6697",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T02:46:56.121845Z",
     "iopub.status.busy": "2025-05-27T02:46:56.121548Z",
     "iopub.status.idle": "2025-05-27T02:46:56.150127Z",
     "shell.execute_reply": "2025-05-27T02:46:56.148909Z",
     "shell.execute_reply.started": "2025-05-27T02:46:56.121815Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnn output shape: torch.Size([16, 603, 10]) -> [batch_size, seq_len, hidden_size]\n",
      "h_n shape: torch.Size([1, 16, 10]) -> [num_layers, batch_size, hidden_size]\n"
     ]
    }
   ],
   "source": [
    "# --- Simple RNN layer ---\n",
    "# - input_size=32: Each input vector (e.g., from an embedding) has 32 features\n",
    "# - hidden_size=10: The RNN will maintain a hidden state with 10 dimensions\n",
    "# - batch_first=True: Input and output tensors will have shape (batch, seq, feature)\n",
    "rnn = nn.RNN(input_size=32, hidden_size=10, batch_first=True)\n",
    "\n",
    "# Pass a sequence of embedded inputs to the RNN\n",
    "# output_1 should have shape (batch_size, sequence_length, input_size=32)\n",
    "# The RNN will process this input sequence and return:\n",
    "#   - hidden_states: The hidden state at each time step -> shape: (batch, seq_len, hidden_size)\n",
    "#   - h_n: The final hidden state for the last time step -> shape (num_layers, batch, hidden_size)\n",
    "output_2 = rnn(output_1)\n",
    "hidden_states, h_n = output_2\n",
    "print(f\"rnn output shape: {hidden_states.shape} -> [batch_size, seq_len, hidden_size]\")\n",
    "print(f\"h_n shape: {h_n.shape} -> [num_layers, batch_size, hidden_size]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "182bdadc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T02:46:56.151769Z",
     "iopub.status.busy": "2025-05-27T02:46:56.151477Z",
     "iopub.status.idle": "2025-05-27T02:46:56.159758Z",
     "shell.execute_reply": "2025-05-27T02:46:56.158569Z",
     "shell.execute_reply.started": "2025-05-27T02:46:56.151738Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear layer output shape: torch.Size([16, 1]) -> [batch_size, 1]\n"
     ]
    }
   ],
   "source": [
    "# --- Linear layer  ---\n",
    "# This layer maps from the hidden state (size 10) to a single output (e.g., binary classification).\n",
    "# in_features=10: the dimension of the RNN's final hidden state.\n",
    "# out_features=1: we want a single output (e.g., a logit for binary classification).\n",
    "linear = nn.Linear(in_features=10, out_features=1)\n",
    "\n",
    "# h_n has shape (num_layers, batch_size, hidden_size)\n",
    "# Since we’re using 1 RNN layer, h_n.shape == (1, batch_size, 10)\n",
    "# We remove the first dimension using squeeze(0) -> (batch_size, 10)\n",
    "# This gives us one 10-dimensional vector per sequence in the batch.\n",
    "output_3 = linear(h_n.squeeze(0))\n",
    "\n",
    "# The result is a tensor of shape (batch_size, 1)\n",
    "# Each value is a prediction logit for the corresponding sequence\n",
    "print(f\"Linear layer output shape: {output_3.shape} -> [batch_size, 1]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e0e33372",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T02:46:56.161286Z",
     "iopub.status.busy": "2025-05-27T02:46:56.160982Z",
     "iopub.status.idle": "2025-05-27T02:46:56.169134Z",
     "shell.execute_reply": "2025-05-27T02:46:56.167699Z",
     "shell.execute_reply.started": "2025-05-27T02:46:56.161255Z"
    }
   },
   "outputs": [],
   "source": [
    "class RNN_V1(nn.Module):\n",
    "    def __init__(self, vocab_size :int, embedding_dim :int, hidden_units: int, output_size :int):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim)\n",
    "        self.rnn = nn.RNN(input_size=embedding_dim, hidden_size=hidden_units, batch_first=True)\n",
    "        self.linear = nn.Linear(in_features=hidden_units, out_features=output_size)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.embedding(x)               # [batch_size, seq_len, embed_dim]\n",
    "        _, h_n = self.rnn(x)                # [num_layers, batch_size, hidden_dim]\n",
    "        last_hidden = h_n.squeeze(0)        # remove the first dimension, which is num_layers=1 \n",
    "        output = self.linear(last_hidden)   # [batch_size, output_size] == [32, 1]\n",
    "        output = output                     # Reshape output to match label shape [32]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1e127644",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T02:46:56.170772Z",
     "iopub.status.busy": "2025-05-27T02:46:56.170477Z",
     "iopub.status.idle": "2025-05-27T02:46:56.452436Z",
     "shell.execute_reply": "2025-05-27T02:46:56.451262Z",
     "shell.execute_reply.started": "2025-05-27T02:46:56.170742Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_1 is on the model device: cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RNN_V1(\n",
       "  (embedding): Embedding(108, 32)\n",
       "  (rnn): RNN(32, 10, batch_first=True)\n",
       "  (linear): Linear(in_features=10, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "model_1 = RNN_V1(vocab_size=VOCAB_SIZE, \n",
    "                 embedding_dim=EMBEDDING_DIM,\n",
    "                 hidden_units=HIDDEN_DIM,\n",
    "                 output_size=1\n",
    ").to(device) \n",
    "\n",
    "print(f\"Model_1 is on the model device: {next(model_1.parameters()).device}\")\n",
    "model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "accc2de9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T02:46:56.454084Z",
     "iopub.status.busy": "2025-05-27T02:46:56.453790Z",
     "iopub.status.idle": "2025-05-27T02:46:56.584851Z",
     "shell.execute_reply": "2025-05-27T02:46:56.583728Z",
     "shell.execute_reply.started": "2025-05-27T02:46:56.454052Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "========================================================================================================================\n",
       "Layer (type (var_name))                  Input Shape          Output Shape         Param #              Trainable\n",
       "========================================================================================================================\n",
       "RNN_V1 (RNN_V1)                          [16, 603]            [16, 1]              --                   True\n",
       "├─Embedding (embedding)                  [16, 603]            [16, 603, 32]        3,456                True\n",
       "├─RNN (rnn)                              [16, 603, 32]        [16, 603, 10]        440                  True\n",
       "├─Linear (linear)                        [16, 10]             [16, 1]              11                   True\n",
       "========================================================================================================================\n",
       "Total params: 3,907\n",
       "Trainable params: 3,907\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 4.30\n",
       "========================================================================================================================\n",
       "Input size (MB): 0.08\n",
       "Forward/backward pass size (MB): 3.24\n",
       "Params size (MB): 0.02\n",
       "Estimated Total Size (MB): 3.33\n",
       "========================================================================================================================"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a summary of Model_1 \n",
    "summary(model_1, \n",
    "         input_size=train_features_batch.shape,\n",
    "         dtypes=[torch.long],\n",
    "         verbose=0,\n",
    "         col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "         col_width=20,\n",
    "         row_settings=[\"var_names\"],\n",
    "         device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "32dfaa4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T02:46:56.586684Z",
     "iopub.status.busy": "2025-05-27T02:46:56.586353Z",
     "iopub.status.idle": "2025-05-27T02:46:56.592696Z",
     "shell.execute_reply": "2025-05-27T02:46:56.591397Z",
     "shell.execute_reply.started": "2025-05-27T02:46:56.586653Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Loss and Optimizer Functions ---\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(params=model_1.parameters(), \n",
    "                            lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "288ef7eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T02:46:56.594349Z",
     "iopub.status.busy": "2025-05-27T02:46:56.594039Z",
     "iopub.status.idle": "2025-05-27T02:47:10.604000Z",
     "shell.execute_reply": "2025-05-27T02:47:10.602776Z",
     "shell.execute_reply.started": "2025-05-27T02:46:56.594318Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63da3f016ec84618b56fe253939dac99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 0.5859 | train_acc: 0.7237 | test_loss: 0.5770 | test_acc: 0.7362\n",
      "Epoch: 2 | train_loss: 0.5772 | train_acc: 0.7367 | test_loss: 0.5773 | test_acc: 0.7362\n",
      "Epoch: 3 | train_loss: 0.5770 | train_acc: 0.7367 | test_loss: 0.5768 | test_acc: 0.7362\n",
      "Epoch: 4 | train_loss: 0.5770 | train_acc: 0.7367 | test_loss: 0.5768 | test_acc: 0.7362\n",
      "Epoch: 5 | train_loss: 0.5767 | train_acc: 0.7367 | test_loss: 0.5766 | test_acc: 0.7362\n"
     ]
    }
   ],
   "source": [
    "# --- Train and Test Model_1 ---\n",
    "set_seeds()\n",
    "results = train(model=model_1,\n",
    "                train_dataloader=train_dataloader,\n",
    "                test_dataloader=test_dataloader,\n",
    "                optimizer=optimizer,\n",
    "                loss_fn=loss_fn,\n",
    "                epochs=5,\n",
    "                device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bd16174d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T02:47:10.606109Z",
     "iopub.status.busy": "2025-05-27T02:47:10.605788Z",
     "iopub.status.idle": "2025-05-27T02:47:10.614956Z",
     "shell.execute_reply": "2025-05-27T02:47:10.613407Z",
     "shell.execute_reply.started": "2025-05-27T02:47:10.606076Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train class counts: Counter({False: 7662, True: 2738})\n",
      "Test class counts: Counter({False: 1914, True: 686})\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "train_class_counts = collections.Counter(y_train)\n",
    "test_class_counts = collections.Counter(y_test)\n",
    "\n",
    "print(f\"Train class counts: {train_class_counts}\")\n",
    "print(f\"Test class counts: {test_class_counts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a52c9bd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T02:47:10.617357Z",
     "iopub.status.busy": "2025-05-27T02:47:10.617009Z",
     "iopub.status.idle": "2025-05-27T02:47:10.623541Z",
     "shell.execute_reply": "2025-05-27T02:47:10.621966Z",
     "shell.execute_reply.started": "2025-05-27T02:47:10.617323Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Given this distribution and Model performances, model_1 that opredicts False every time — and that would still be right 77% of the time.\n"
     ]
    }
   ],
   "source": [
    "#print(f\"Train set (960 samples): False = {(3671/4799)*100:.2f} % and True = {(1128/4799)* 100:.2f} %\")\n",
    "#print(f\"Test set (240samples): False = {(924/1200)*100:.2f}% and True = {(276/1200)*100:.2f}%\")\n",
    "print(f\"\\nGiven this distribution and Model performances, model_1 that opredicts False every time — and that would still be right 77% of the time.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa218e0",
   "metadata": {},
   "source": [
    "---\n",
    "#### **Buils Model 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3be23c4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T02:47:10.625436Z",
     "iopub.status.busy": "2025-05-27T02:47:10.625120Z",
     "iopub.status.idle": "2025-05-27T02:47:10.635311Z",
     "shell.execute_reply": "2025-05-27T02:47:10.633880Z",
     "shell.execute_reply.started": "2025-05-27T02:47:10.625405Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Asymmetric Focal Loss for Binary Classification ---\n",
    "\n",
    "# Due to the class imbalance in our dataset (~26% tautologies), the model may bias toward \n",
    "# predicting the majority class (non-tautologies). This leads to high accuracy but poor recall \n",
    "# on the minority class, which is undesirable in many reasoning or safety-critical settings.\n",
    "\n",
    "# To address this, we use an Asymmetric Focal Loss, a refined version of the standard focal loss.\n",
    "# The core idea is to:\n",
    "# - Assign higher weight (α) to the minority class (tautologies) to penalize false negatives more.\n",
    "# - Apply a modulating factor (1 - p)^γ to focus learning on hard examples.\n",
    "# - Use separate α and γ values for each class for better control.\n",
    "\n",
    "# Loss formula:\n",
    "# L(y, ŷ) = \n",
    "#   - α_pos * y * (1 - ŷ)^γ_pos * log(ŷ)\n",
    "#   - α_neg * (1 - y)^γ_neg * log(1 - ŷ)\n",
    "# where:\n",
    "#   - y is the true label (0 or 1)\n",
    "#   - ŷ is the predicted probability (after sigmoid)\n",
    "#   - α_pos/neg control class weighting\n",
    "#   - γ_pos/neg control the focus on hard examples\n",
    "\n",
    "\n",
    "class AsymmetricFocalLoss(nn.Module):\n",
    "    def __init__(self, alpha_pos=1.0, alpha_neg=1.0, gamma_pos=2.0, gamma_neg=2.0, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.alpha_pos = alpha_pos\n",
    "        self.alpha_neg = alpha_neg\n",
    "        self.gamma_pos = gamma_pos\n",
    "        self.gamma_neg = gamma_neg\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        probs = torch.sigmoid(logits)\n",
    "        probs = torch.clamp(probs, 1e-6, 1 - 1e-6)  # Avoid log(0)\n",
    "\n",
    "        # Loss for positive (tautology)\n",
    "        pos_loss = self.alpha_pos * (1 - probs) ** self.gamma_pos * torch.log(probs)\n",
    "        # Loss for negative (non-tautology)\n",
    "        neg_loss = self.alpha_neg * (probs) ** self.gamma_neg * torch.log(1 - probs)\n",
    "\n",
    "        # Full loss\n",
    "        loss = -targets * pos_loss - (1 - targets) * neg_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return loss.sum()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d51cf48c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T02:47:10.637068Z",
     "iopub.status.busy": "2025-05-27T02:47:10.636780Z",
     "iopub.status.idle": "2025-05-27T02:47:10.644978Z",
     "shell.execute_reply": "2025-05-27T02:47:10.643606Z",
     "shell.execute_reply.started": "2025-05-27T02:47:10.637038Z"
    }
   },
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, vocab_size: int, embedding_dim: int, hidden_dim: int, output_size: int):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_dim, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_dim, output_size)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.embedding(x)                  # [batch_size, seq_len, embed_dim]\n",
    "        _, (h_n, _) = self.lstm(x)             # h_n: [num_layers, batch_size, hidden_dim]\n",
    "        last_hidden = h_n.squeeze(0)           # [batch_size, hidden_dim]\n",
    "        output = self.linear(last_hidden)      # [batch_size, output_size]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e878551d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T02:47:10.646883Z",
     "iopub.status.busy": "2025-05-27T02:47:10.646581Z",
     "iopub.status.idle": "2025-05-27T02:47:10.658163Z",
     "shell.execute_reply": "2025-05-27T02:47:10.657045Z",
     "shell.execute_reply.started": "2025-05-27T02:47:10.646854Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (embedding): Embedding(108, 32, padding_idx=0)\n",
       "  (lstm): LSTM(32, 64, batch_first=True)\n",
       "  (linear): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HIDDEN_DIM=64\n",
    "\n",
    "model_2 = LSTM(vocab_size=VOCAB_SIZE,\n",
    "               embedding_dim=EMBEDDING_DIM,\n",
    "               hidden_dim=HIDDEN_DIM,\n",
    "               output_size=1).to(device)\n",
    "model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "12694ce9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T02:47:10.660145Z",
     "iopub.status.busy": "2025-05-27T02:47:10.659841Z",
     "iopub.status.idle": "2025-05-27T02:47:10.666802Z",
     "shell.execute_reply": "2025-05-27T02:47:10.665409Z",
     "shell.execute_reply.started": "2025-05-27T02:47:10.660115Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Loss and Optimizer Functions ---\n",
    "loss_fn = AsymmetricFocalLoss(\n",
    "    alpha_pos=0.75,   # emphasize tautologies\n",
    "    alpha_neg=0.25,   # downweight non-tautologies\n",
    "    gamma_pos=2.0,    # focus more on hard positives\n",
    "    gamma_neg=1.0     # still soften easy negatives\n",
    ")\n",
    "optimizer = torch.optim.Adam(params=model_2.parameters(), \n",
    "                            lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2ba776df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T02:47:10.668772Z",
     "iopub.status.busy": "2025-05-27T02:47:10.668482Z",
     "iopub.status.idle": "2025-05-27T02:47:28.846530Z",
     "shell.execute_reply": "2025-05-27T02:47:28.844756Z",
     "shell.execute_reply.started": "2025-05-27T02:47:10.668742Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60a828d2c06b46878a0acda19e0df1ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 0.0969 | train_acc: 0.7369 | test_loss: 0.0968 | test_acc: 0.7370\n",
      "Epoch: 2 | train_loss: 0.0968 | train_acc: 0.7369 | test_loss: 0.0969 | test_acc: 0.7370\n",
      "Epoch: 3 | train_loss: 0.0969 | train_acc: 0.7369 | test_loss: 0.0968 | test_acc: 0.7370\n",
      "Epoch: 4 | train_loss: 0.0969 | train_acc: 0.7369 | test_loss: 0.0968 | test_acc: 0.7370\n",
      "Epoch: 5 | train_loss: 0.0970 | train_acc: 0.7358 | test_loss: 0.0968 | test_acc: 0.7370\n"
     ]
    }
   ],
   "source": [
    "# --- Train and Test Model_2 ---\n",
    "set_seeds()\n",
    "results = train(model=model_2,\n",
    "                train_dataloader=train_dataloader,\n",
    "                test_dataloader=test_dataloader,\n",
    "                optimizer=optimizer,\n",
    "                loss_fn=loss_fn,\n",
    "                epochs=5,\n",
    "                device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bda415",
   "metadata": {},
   "source": [
    "--- \n",
    "### **Build Model 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f69b0acd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T02:47:28.849537Z",
     "iopub.status.busy": "2025-05-27T02:47:28.849036Z",
     "iopub.status.idle": "2025-05-27T02:47:28.860664Z",
     "shell.execute_reply": "2025-05-27T02:47:28.859367Z",
     "shell.execute_reply.started": "2025-05-27T02:47:28.849412Z"
    }
   },
   "outputs": [],
   "source": [
    "class GRU(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim=32):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "\n",
    "        self.gru1 = nn.GRU(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=128,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "\n",
    "        self.gru2 = nn.GRU(\n",
    "            input_size=128 * 2,  # Because bidirectional doubles output size\n",
    "            hidden_size=64,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Linear(64 * 2, 32)  # 64*2 because second GRU is bidirectional\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.fc2 = nn.Linear(32, 1)  # Binary classification output (logit)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [batch_size, seq_len]\n",
    "        x = self.embedding(x)              # [batch_size, seq_len, embed_dim]\n",
    "\n",
    "        out1, _ = self.gru1(x)             # [batch_size, seq_len, 256]\n",
    "        out2, _ = self.gru2(out1)          # [batch_size, seq_len, 128]\n",
    "\n",
    "        out2_last = out2[:, -1, :]         # Use the last timestep's features\n",
    "        x = self.relu(self.fc1(out2_last)) # [batch_size, 32]\n",
    "        output = self.fc2(x)               # [batch_size, 1]\n",
    "\n",
    "        return output  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cfc79dfd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T02:47:28.862499Z",
     "iopub.status.busy": "2025-05-27T02:47:28.862127Z",
     "iopub.status.idle": "2025-05-27T02:47:28.879406Z",
     "shell.execute_reply": "2025-05-27T02:47:28.878003Z",
     "shell.execute_reply.started": "2025-05-27T02:47:28.862434Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GRU(\n",
       "  (embedding): Embedding(108, 32, padding_idx=0)\n",
       "  (gru1): GRU(32, 128, batch_first=True, bidirectional=True)\n",
       "  (gru2): GRU(256, 64, batch_first=True, bidirectional=True)\n",
       "  (fc1): Linear(in_features=128, out_features=32, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3 = GRU(vocab_size=VOCAB_SIZE, embedding_dim=EMBEDDING_DIM).to(device)\n",
    "model_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c660c2d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T02:47:28.882036Z",
     "iopub.status.busy": "2025-05-27T02:47:28.880954Z",
     "iopub.status.idle": "2025-05-27T02:47:28.888309Z",
     "shell.execute_reply": "2025-05-27T02:47:28.887070Z",
     "shell.execute_reply.started": "2025-05-27T02:47:28.881995Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Loss and Optimizer Functions ---\n",
    "loss_fn = AsymmetricFocalLoss(\n",
    "    alpha_pos=0.3,  # minority (tautology)\n",
    "    alpha_neg=0.7,  # majority\n",
    "    gamma_pos=3.0,\n",
    "    gamma_neg=1.5\n",
    ")\n",
    "optimizer = torch.optim.Adam(params=model_3.parameters(), \n",
    "                            lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c01ffbef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T02:47:28.890155Z",
     "iopub.status.busy": "2025-05-27T02:47:28.889839Z",
     "iopub.status.idle": "2025-05-27T02:47:28.917172Z",
     "shell.execute_reply": "2025-05-27T02:47:28.916021Z",
     "shell.execute_reply.started": "2025-05-27T02:47:28.890120Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "========================================================================================================================\n",
       "Layer (type (var_name))                  Input Shape          Output Shape         Param #              Trainable\n",
       "========================================================================================================================\n",
       "GRU (GRU)                                [16, 603]            [16, 1]              --                   True\n",
       "├─Embedding (embedding)                  [16, 603]            [16, 603, 32]        3,456                True\n",
       "├─GRU (gru1)                             [16, 603, 32]        [16, 603, 256]       124,416              True\n",
       "├─GRU (gru2)                             [16, 603, 256]       [16, 603, 128]       123,648              True\n",
       "├─Linear (fc1)                           [16, 128]            [16, 32]             4,128                True\n",
       "├─ReLU (relu)                            [16, 32]             [16, 32]             --                   --\n",
       "├─Linear (fc2)                           [16, 32]             [16, 1]              33                   True\n",
       "========================================================================================================================\n",
       "Total params: 255,681\n",
       "Trainable params: 255,681\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 2.39\n",
       "========================================================================================================================\n",
       "Input size (MB): 0.08\n",
       "Forward/backward pass size (MB): 32.11\n",
       "Params size (MB): 1.02\n",
       "Estimated Total Size (MB): 33.21\n",
       "========================================================================================================================"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a summary of Model_3 \n",
    "summary(model_3, \n",
    "         input_size=train_features_batch.shape,\n",
    "         dtypes=[torch.long],\n",
    "         verbose=0,\n",
    "         col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "         col_width=20,\n",
    "         row_settings=[\"var_names\"],\n",
    "         device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0d9e77bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T02:47:28.919195Z",
     "iopub.status.busy": "2025-05-27T02:47:28.918860Z",
     "iopub.status.idle": "2025-05-27T02:50:25.241051Z",
     "shell.execute_reply": "2025-05-27T02:50:25.239652Z",
     "shell.execute_reply.started": "2025-05-27T02:47:28.919161Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4265205bceb646dbbad4c7039491a6f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 0.0429 | train_acc: 0.8403 | test_loss: 0.0213 | test_acc: 0.9463\n",
      "Epoch: 2 | train_loss: 0.0214 | train_acc: 0.9428 | test_loss: 0.0197 | test_acc: 0.9548\n",
      "Epoch: 3 | train_loss: 0.0188 | train_acc: 0.9512 | test_loss: 0.0157 | test_acc: 0.9594\n",
      "Epoch: 4 | train_loss: 0.0153 | train_acc: 0.9587 | test_loss: 0.0153 | test_acc: 0.9486\n",
      "Epoch: 5 | train_loss: 0.0133 | train_acc: 0.9608 | test_loss: 0.0129 | test_acc: 0.9640\n",
      "Epoch: 6 | train_loss: 0.0121 | train_acc: 0.9624 | test_loss: 0.0130 | test_acc: 0.9666\n",
      "Epoch: 7 | train_loss: 0.0109 | train_acc: 0.9655 | test_loss: 0.0117 | test_acc: 0.9655\n",
      "Epoch: 8 | train_loss: 0.0096 | train_acc: 0.9674 | test_loss: 0.0102 | test_acc: 0.9689\n",
      "Epoch: 9 | train_loss: 0.0090 | train_acc: 0.9674 | test_loss: 0.0092 | test_acc: 0.9689\n",
      "Epoch: 10 | train_loss: 0.0083 | train_acc: 0.9705 | test_loss: 0.0091 | test_acc: 0.9670\n",
      "Epoch: 11 | train_loss: 0.0078 | train_acc: 0.9688 | test_loss: 0.0118 | test_acc: 0.9578\n",
      "Epoch: 12 | train_loss: 0.0070 | train_acc: 0.9714 | test_loss: 0.0080 | test_acc: 0.9666\n",
      "Epoch: 13 | train_loss: 0.0063 | train_acc: 0.9736 | test_loss: 0.0081 | test_acc: 0.9705\n",
      "Epoch: 14 | train_loss: 0.0059 | train_acc: 0.9754 | test_loss: 0.0079 | test_acc: 0.9728\n",
      "Epoch: 15 | train_loss: 0.0058 | train_acc: 0.9748 | test_loss: 0.0080 | test_acc: 0.9755\n",
      "Epoch: 16 | train_loss: 0.0052 | train_acc: 0.9768 | test_loss: 0.0078 | test_acc: 0.9751\n",
      "Epoch: 17 | train_loss: 0.0048 | train_acc: 0.9762 | test_loss: 0.0092 | test_acc: 0.9758\n",
      "Epoch: 18 | train_loss: 0.0048 | train_acc: 0.9778 | test_loss: 0.0075 | test_acc: 0.9720\n",
      "Epoch: 19 | train_loss: 0.0040 | train_acc: 0.9811 | test_loss: 0.0088 | test_acc: 0.9762\n",
      "Epoch: 20 | train_loss: 0.0040 | train_acc: 0.9807 | test_loss: 0.0092 | test_acc: 0.9755\n"
     ]
    }
   ],
   "source": [
    "# --- Train and Test Model_3 ---\n",
    "set_seeds()\n",
    "results = train(model=model_3,\n",
    "                train_dataloader=train_dataloader,\n",
    "                test_dataloader=test_dataloader,\n",
    "                optimizer=optimizer,\n",
    "                loss_fn=loss_fn,\n",
    "                epochs=20,\n",
    "                device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "becd4c05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T02:50:25.242965Z",
     "iopub.status.busy": "2025-05-27T02:50:25.242635Z",
     "iopub.status.idle": "2025-05-27T02:50:25.269633Z",
     "shell.execute_reply": "2025-05-27T02:50:25.268394Z",
     "shell.execute_reply.started": "2025-05-27T02:50:25.242928Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saving model to: models/Bidirectional_GRU_1.pth\n"
     ]
    }
   ],
   "source": [
    "save_model(model=model_3,\n",
    "           target_dir=\"models\",\n",
    "           model_name=\"Bidirectional_GRU_1.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea0e6d2",
   "metadata": {},
   "source": [
    "---\n",
    "### **Part 2**\n",
    "> **Note:** Needs to execute all cells before Preparing the Data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac7cab4",
   "metadata": {},
   "source": [
    "#### **2.1 Extending Dataset** with [SATLIB - Benchmark Problems](https://www.cs.ubc.ca/~hoos/SATLIB/benchm.html), using propositional formulas in Dimacs format.\n",
    "\n",
    "Formulas Downloaded from SATLIB: \n",
    "- uf20-91: 20 variables, 91 clauses - 1000 instances, all satisfiable\n",
    "- uf50-218 / uuf50-218: 50 variables, 218 clauses - 1000 instances, all sat/unsat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c2f2fc10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T13:40:28.585732Z",
     "iopub.status.busy": "2025-05-28T13:40:28.585259Z",
     "iopub.status.idle": "2025-05-28T13:40:36.943551Z",
     "shell.execute_reply": "2025-05-28T13:40:36.942199Z",
     "shell.execute_reply.started": "2025-05-28T13:40:28.585694Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_dimacs_files(base_dir: str):\n",
    "    \"\"\"\n",
    "    Parses DIMACS CNF files from a directory and returns a labeled dataset of formulas.\n",
    "\n",
    "    This function scans subdirectories under the specified base directory to identify \n",
    "    and process CNF files representing propositional logic formulas in DIMACS format. \n",
    "    It labels the formulas as tautology or not tautology based on directory naming \n",
    "    conventions (`uf*` = satisfiable, `uuf*` = unsatisfiable).\n",
    "\n",
    "    Args:\n",
    "        base_dir (str): The path to the top-level directory containing `uf*` and `uuf*` folders\n",
    "                        with .cnf files inside.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing two columns:\n",
    "                      - 'formula': the parsed `Formula` object\n",
    "                      - 'is_tautology': a boolean indicating whether the formula is satisfiable.\n",
    "    \"\"\"\n",
    "    formulas_data = []\n",
    "    base_path = Path(base_dir)\n",
    "\n",
    "    for folder in base_path.iterdir():\n",
    "        if folder.is_dir():\n",
    "            folder_name = folder.name.lower()\n",
    "            if folder_name.startswith(\"uf\") and not folder_name.startswith(\"uuf\"):\n",
    "                label = True  # satisfiable\n",
    "            elif folder_name.startswith(\"uuf\"):\n",
    "                label = False  # unsatisfiable\n",
    "            else:\n",
    "                print(f\"Skipping unknown folder: {folder_name}\")\n",
    "                continue\n",
    "\n",
    "            for file_path in folder.glob(\"*.cnf\"):\n",
    "                with open(file_path, 'r') as file:\n",
    "                    dimacs_lines = file.readlines()\n",
    "                try:\n",
    "                    formula = Formula.from_dimacs(dimacs_lines)\n",
    "                    formulas_data.append({\n",
    "                        'formula': formula,\n",
    "                        'is_tautology': label\n",
    "                    })\n",
    "                except Exception as e:\n",
    "                    print(f\"Error parsing {file_path.name}: {e}\")\n",
    "\n",
    "    return pd.DataFrame(formulas_data)\n",
    "\n",
    "# base_dir = \"/Users/nicolabalestra/Desktop/DeepSAT/theorem_prover/theorem_prover_core/ICTCS_notebooks/dimacs_formulas_datasets\"\n",
    "base_dir = \"/home/labeconomia/nbalestra/theorem_prover/theorem_prover_core/ICTCS_notebooks/dimacs_formulas_datasets\"\n",
    "df_satlib = parse_dimacs_files(base_dir=base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2f487c36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T13:40:36.946140Z",
     "iopub.status.busy": "2025-05-28T13:40:36.945708Z",
     "iopub.status.idle": "2025-05-28T13:40:36.955731Z",
     "shell.execute_reply": "2025-05-28T13:40:36.954643Z",
     "shell.execute_reply.started": "2025-05-28T13:40:36.946108Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_tautology\n",
       "True     2000\n",
       "False    1000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_satlib.is_tautology.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "63f0ccee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T13:40:38.008089Z",
     "iopub.status.busy": "2025-05-28T13:40:38.006994Z",
     "iopub.status.idle": "2025-05-28T13:40:38.034008Z",
     "shell.execute_reply": "2025-05-28T13:40:38.032858Z",
     "shell.execute_reply.started": "2025-05-28T13:40:38.008051Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>formula</th>\n",
       "      <th>is_tautology</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2531</th>\n",
       "      <td>(A42 ∨ ¬A12 ∨ A27) ∧ (A24 ∨ A9 ∨ ¬A42) ∧ (¬A38...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2532</th>\n",
       "      <td>(¬A9 ∨ ¬A46 ∨ ¬A19) ∧ (¬A22 ∨ A17 ∨ A48) ∧ (¬A...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2669</th>\n",
       "      <td>(¬A22 ∨ A1 ∨ A43) ∧ (A6 ∨ ¬A15 ∨ ¬A4) ∧ (A39 ∨...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2202</th>\n",
       "      <td>(A46 ∨ A32 ∨ A37) ∧ (A36 ∨ ¬A1 ∨ ¬A46) ∧ (A25 ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2608</th>\n",
       "      <td>(A18 ∨ A27 ∨ A30) ∧ (A35 ∨ ¬A12 ∨ ¬A23) ∧ (A17...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                formula  is_tautology\n",
       "2531  (A42 ∨ ¬A12 ∨ A27) ∧ (A24 ∨ A9 ∨ ¬A42) ∧ (¬A38...         False\n",
       "2532  (¬A9 ∨ ¬A46 ∨ ¬A19) ∧ (¬A22 ∨ A17 ∨ A48) ∧ (¬A...         False\n",
       "2669  (¬A22 ∨ A1 ∨ A43) ∧ (A6 ∨ ¬A15 ∨ ¬A4) ∧ (A39 ∨...         False\n",
       "2202  (A46 ∨ A32 ∨ A37) ∧ (A36 ∨ ¬A1 ∨ ¬A46) ∧ (A25 ...         False\n",
       "2608  (A18 ∨ A27 ∨ A30) ∧ (A35 ∨ ¬A12 ∨ ¬A23) ∧ (A17...         False"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspecting some sampled unsatisfable formulas\n",
    "df_satlib[df_satlib['is_tautology'] == False].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "72e4d622",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T13:40:40.196247Z",
     "iopub.status.busy": "2025-05-28T13:40:40.194615Z",
     "iopub.status.idle": "2025-05-28T13:40:40.220497Z",
     "shell.execute_reply": "2025-05-28T13:40:40.218692Z",
     "shell.execute_reply.started": "2025-05-28T13:40:40.196204Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>formula</th>\n",
       "      <th>is_tautology</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>(A26 ∨ ¬A27 ∨ ¬A46) ∧ (A19 ∨ A6 ∨ A25) ∧ (¬A36...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1173</th>\n",
       "      <td>(A9 ∨ A1 ∨ A7) ∧ (¬A16 ∨ A0 ∨ A11) ∧ (A11 ∨ ¬A...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1302</th>\n",
       "      <td>(¬A1 ∨ A11 ∨ ¬A15) ∧ (¬A3 ∨ A11 ∨ A5) ∧ (A9 ∨ ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1703</th>\n",
       "      <td>(¬A3 ∨ A6 ∨ ¬A7) ∧ (¬A14 ∨ ¬A2 ∨ ¬A0) ∧ (¬A17 ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>(¬A24 ∨ ¬A31 ∨ A3) ∧ (¬A16 ∨ A41 ∨ A35) ∧ (A2 ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                formula  is_tautology\n",
       "836   (A26 ∨ ¬A27 ∨ ¬A46) ∧ (A19 ∨ A6 ∨ A25) ∧ (¬A36...          True\n",
       "1173  (A9 ∨ A1 ∨ A7) ∧ (¬A16 ∨ A0 ∨ A11) ∧ (A11 ∨ ¬A...          True\n",
       "1302  (¬A1 ∨ A11 ∨ ¬A15) ∧ (¬A3 ∨ A11 ∨ A5) ∧ (A9 ∨ ...          True\n",
       "1703  (¬A3 ∨ A6 ∨ ¬A7) ∧ (¬A14 ∨ ¬A2 ∨ ¬A0) ∧ (¬A17 ...          True\n",
       "30    (¬A24 ∨ ¬A31 ∨ A3) ∧ (¬A16 ∨ A41 ∨ A35) ∧ (A2 ...          True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspecting some sampled satisfable formulas \n",
    "df_satlib[df_satlib['is_tautology'] == True].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e21850a5-708e-457b-8518-7d492b1f274a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T13:40:42.493183Z",
     "iopub.status.busy": "2025-05-28T13:40:42.492088Z",
     "iopub.status.idle": "2025-05-28T13:40:42.501895Z",
     "shell.execute_reply": "2025-05-28T13:40:42.500483Z",
     "shell.execute_reply.started": "2025-05-28T13:40:42.493144Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(¬A27 ∨ A42 ∨ A28) ∧ (¬A49 ∨ A37 ∨ A9) ∧ (¬A38 ∨ ¬A26 ∨ A40) ∧ (¬A40 ∨ ¬A13 ∨ A35) ∧ (A45 ∨ ¬A23 ∨ ¬A28) ∧ (A31 ∨ A12 ∨ A39) ∧ (¬A35 ∨ A7 ∨ A46) ∧ (¬A8 ∨ ¬A42 ∨ ¬A29) ∧ (¬A11 ∨ A29 ∨ ¬A42) ∧ (¬A14 ∨ ¬A18 ∨ ¬A5) ∧ (¬A40 ∨ ¬A16 ∨ A4) ∧ (¬A38 ∨ A12 ∨ ¬A20) ∧ (A36 ∨ A15 ∨ A17) ∧ (¬A44 ∨ A25 ∨ A36) ∧ (¬A19 ∨ ¬A37 ∨ A27) ∧ (A16 ∨ A20 ∨ A29) ∧ (A34 ∨ A38 ∨ ¬A19) ∧ (¬A29 ∨ A8 ∨ A41) ∧ (¬A4 ∨ A18 ∨ A32) ∧ (¬A0 ∨ ¬A24 ∨ A42) ∧ (A41 ∨ ¬A16 ∨ ¬A44) ∧ (¬A26 ∨ ¬A21 ∨ A32) ∧ (A21 ∨ A6 ∨ ¬A13) ∧ (A19 ∨ ¬A8 ∨ A7) ∧ (¬A7 ∨ ¬A0 ∨ ¬A37) ∧ (A23 ∨ ¬A19 ∨ ¬A3) ∧ (¬A11 ∨ A16 ∨ ¬A12) ∧ (A48 ∨ ¬A34 ∨ ¬A44) ∧ (A0 ∨ A18 ∨ A7) ∧ (A19 ∨ ¬A28 ∨ ¬A7) ∧ (¬A43 ∨ A1 ∨ ¬A6) ∧ (¬A37 ∨ A30 ∨ ¬A13) ∧ (¬A37 ∨ ¬A22 ∨ A10) ∧ (¬A31 ∨ ¬A34 ∨ ¬A27) ∧ (A46 ∨ A11 ∨ A26) ∧ (¬A39 ∨ A11 ∨ A5) ∧ (A42 ∨ ¬A45 ∨ ¬A4) ∧ (¬A31 ∨ A32 ∨ ¬A0) ∧ (¬A1 ∨ ¬A45 ∨ A19) ∧ (A28 ∨ ¬A30 ∨ ¬A23) ∧ (A9 ∨ A24 ∨ A3) ∧ (¬A40 ∨ A12 ∨ A6) ∧ (A23 ∨ ¬A48 ∨ ¬A33) ∧ (A9 ∨ ¬A43 ∨ ¬A29) ∧ (A1 ∨ ¬A9 ∨ A14) ∧ (¬A17 ∨ ¬A18 ∨ A8) ∧ (A23 ∨ A0 ∨ ¬A27) ∧ (A42 ∨ A16 ∨ A12) ∧ (A26 ∨ ¬A1 ∨ ¬A3) ∧ (A47 ∨ ¬A26 ∨ ¬A42) ∧ (¬A17 ∨ ¬A1 ∨ ¬A4) ∧ (A46 ∨ ¬A8 ∨ A42) ∧ (A1 ∨ ¬A19 ∨ ¬A27) ∧ (¬A23 ∨ A13 ∨ A36) ∧ (A10 ∨ ¬A17 ∨ A38) ∧ (¬A39 ∨ A45 ∨ A24) ∧ (¬A36 ∨ ¬A17 ∨ ¬A29) ∧ (A43 ∨ A14 ∨ A16) ∧ (A31 ∨ ¬A15 ∨ A38) ∧ (A19 ∨ ¬A2 ∨ A38) ∧ (A11 ∨ ¬A26 ∨ ¬A36) ∧ (A41 ∨ A16 ∨ A12) ∧ (¬A10 ∨ A1 ∨ A22) ∧ (¬A28 ∨ A39 ∨ A17) ∧ (¬A17 ∨ A27 ∨ A6) ∧ (A1 ∨ ¬A35 ∨ A4) ∧ (A47 ∨ A0 ∨ A13) ∧ (A28 ∨ A9 ∨ A43) ∧ (A34 ∨ A6 ∨ ¬A7) ∧ (¬A19 ∨ A22 ∨ A9) ∧ (¬A44 ∨ A14 ∨ ¬A2) ∧ (A49 ∨ ¬A18 ∨ ¬A36) ∧ (¬A33 ∨ A15 ∨ A3) ∧ (A44 ∨ A5 ∨ ¬A27) ∧ (¬A33 ∨ A27 ∨ A4) ∧ (A9 ∨ ¬A48 ∨ A31) ∧ (¬A48 ∨ A47 ∨ A21) ∧ (¬A29 ∨ A44 ∨ ¬A23) ∧ (¬A4 ∨ A16 ∨ A1) ∧ (A14 ∨ ¬A1 ∨ ¬A35) ∧ (A36 ∨ A4 ∨ ¬A37) ∧ (¬A21 ∨ A15 ∨ ¬A32) ∧ (A0 ∨ A30 ∨ A37) ∧ (A19 ∨ A18 ∨ ¬A26) ∧ (A29 ∨ ¬A14 ∨ ¬A45) ∧ (¬A4 ∨ ¬A20 ∨ A44) ∧ (A27 ∨ A10 ∨ ¬A26) ∧ (¬A3 ∨ A7 ∨ A41) ∧ (A47 ∨ ¬A39 ∨ A27) ∧ (A47 ∨ ¬A3 ∨ A17) ∧ (A17 ∨ ¬A8 ∨ A1) ∧ (¬A37 ∨ A8 ∨ A40) ∧ (¬A1 ∨ ¬A15 ∨ ¬A25) ∧ (A43 ∨ A41 ∨ A35) ∧ (A42 ∨ A8 ∨ A28) ∧ (A16 ∨ ¬A39 ∨ A23) ∧ (A31 ∨ ¬A36 ∨ ¬A29) ∧ (A39 ∨ ¬A35 ∨ A6) ∧ (¬A10 ∨ ¬A21 ∨ A42) ∧ (¬A21 ∨ ¬A34 ∨ ¬A11) ∧ (¬A15 ∨ ¬A11 ∨ A22) ∧ (¬A10 ∨ ¬A11 ∨ ¬A8) ∧ (¬A31 ∨ ¬A23 ∨ A27) ∧ (¬A39 ∨ ¬A48 ∨ A26) ∧ (¬A36 ∨ A16 ∨ ¬A4) ∧ (A31 ∨ ¬A9 ∨ ¬A3) ∧ (A31 ∨ ¬A0 ∨ ¬A33) ∧ (¬A4 ∨ ¬A7 ∨ A3) ∧ (A33 ∨ ¬A43 ∨ A35) ∧ (A2 ∨ A5 ∨ A9) ∧ (¬A31 ∨ A2 ∨ A18) ∧ (¬A10 ∨ ¬A5 ∨ ¬A8) ∧ (A19 ∨ ¬A32 ∨ ¬A0) ∧ (A32 ∨ ¬A9 ∨ ¬A39) ∧ (¬A22 ∨ ¬A28 ∨ A33) ∧ (A41 ∨ ¬A9 ∨ ¬A7) ∧ (¬A17 ∨ ¬A4 ∨ A36) ∧ (A19 ∨ ¬A18 ∨ A47) ∧ (A16 ∨ ¬A23 ∨ A33) ∧ (A34 ∨ ¬A14 ∨ A36) ∧ (¬A23 ∨ ¬A38 ∨ A24) ∧ (¬A11 ∨ ¬A14 ∨ A23) ∧ (A13 ∨ ¬A10 ∨ ¬A40) ∧ (A34 ∨ A46 ∨ ¬A5) ∧ (A26 ∨ A37 ∨ A11) ∧ (A28 ∨ A29 ∨ ¬A46) ∧ (¬A21 ∨ A22 ∨ ¬A8) ∧ (A16 ∨ ¬A34 ∨ ¬A9) ∧ (¬A39 ∨ ¬A30 ∨ ¬A36) ∧ (A41 ∨ ¬A24 ∨ ¬A27) ∧ (A11 ∨ A16 ∨ A12) ∧ (A2 ∨ ¬A40 ∨ A45) ∧ (A10 ∨ A2 ∨ ¬A1) ∧ (¬A10 ∨ ¬A48 ∨ ¬A27) ∧ (A37 ∨ ¬A35 ∨ ¬A0) ∧ (A47 ∨ A49 ∨ A4) ∧ (¬A33 ∨ A9 ∨ ¬A13) ∧ (¬A46 ∨ A31 ∨ A1) ∧ (A44 ∨ A13 ∨ A9) ∧ (¬A48 ∨ ¬A38 ∨ A12) ∧ (¬A26 ∨ A40 ∨ A20) ∧ (A43 ∨ ¬A27 ∨ ¬A33) ∧ (¬A46 ∨ A27 ∨ A49) ∧ (A48 ∨ ¬A45 ∨ A23) ∧ (A39 ∨ ¬A42 ∨ ¬A33) ∧ (¬A41 ∨ ¬A19 ∨ A14) ∧ (¬A19 ∨ ¬A10 ∨ ¬A2) ∧ (¬A31 ∨ A14 ∨ ¬A10) ∧ (A42 ∨ A0 ∨ A28) ∧ (A37 ∨ A41 ∨ ¬A15) ∧ (¬A14 ∨ A48 ∨ ¬A13) ∧ (A47 ∨ ¬A43 ∨ ¬A7) ∧ (¬A33 ∨ A9 ∨ ¬A44) ∧ (¬A33 ∨ A12 ∨ ¬A6) ∧ (A36 ∨ A6 ∨ ¬A44) ∧ (A21 ∨ ¬A11 ∨ ¬A2) ∧ (¬A48 ∨ A29 ∨ A7) ∧ (¬A32 ∨ A18 ∨ A11) ∧ (A4 ∨ ¬A42 ∨ A35) ∧ (¬A40 ∨ ¬A27 ∨ A7) ∧ (¬A23 ∨ A7 ∨ A31) ∧ (¬A25 ∨ A6 ∨ A47) ∧ (¬A35 ∨ A37 ∨ ¬A24) ∧ (A19 ∨ ¬A18 ∨ A25) ∧ (A6 ∨ A20 ∨ ¬A44) ∧ (A33 ∨ A29 ∨ ¬A36) ∧ (¬A32 ∨ A31 ∨ A1) ∧ (A36 ∨ ¬A49 ∨ A44) ∧ (A43 ∨ A15 ∨ A28) ∧ (¬A35 ∨ ¬A27 ∨ ¬A29) ∧ (¬A9 ∨ ¬A24 ∨ A15) ∧ (¬A41 ∨ A22 ∨ A2) ∧ (¬A49 ∨ ¬A38 ∨ A15) ∧ (¬A3 ∨ A43 ∨ ¬A27) ∧ (A39 ∨ ¬A48 ∨ A25) ∧ (A4 ∨ ¬A38 ∨ ¬A40) ∧ (¬A40 ∨ A26 ∨ A1) ∧ (¬A9 ∨ A18 ∨ ¬A43) ∧ (A37 ∨ ¬A15 ∨ ¬A36) ∧ (¬A12 ∨ A37 ∨ ¬A47) ∧ (¬A3 ∨ ¬A10 ∨ ¬A14) ∧ (¬A23 ∨ A20 ∨ ¬A25) ∧ (A29 ∨ ¬A23 ∨ A11) ∧ (A15 ∨ A36 ∨ ¬A39) ∧ (¬A1 ∨ A12 ∨ ¬A23) ∧ (¬A25 ∨ ¬A3 ∨ A40) ∧ (A38 ∨ ¬A20 ∨ A41) ∧ (A7 ∨ ¬A25 ∨ ¬A28) ∧ (¬A43 ∨ A14 ∨ A13) ∧ (¬A20 ∨ A18 ∨ ¬A25) ∧ (A24 ∨ ¬A43 ∨ ¬A29) ∧ (¬A34 ∨ ¬A22 ∨ ¬A47) ∧ (A30 ∨ A43 ∨ A19) ∧ (¬A36 ∨ ¬A6 ∨ ¬A32) ∧ (¬A12 ∨ A9 ∨ ¬A17) ∧ (¬A14 ∨ ¬A27 ∨ A29) ∧ (A21 ∨ A27 ∨ A35) ∧ (¬A12 ∨ ¬A34 ∨ ¬A14) ∧ (¬A0 ∨ ¬A29 ∨ A33) ∧ (¬A31 ∨ ¬A41 ∨ ¬A33) ∧ (A35 ∨ ¬A44 ∨ A14) ∧ (A27 ∨ ¬A9 ∨ ¬A34) ∧ (¬A33 ∨ A41 ∨ A21) ∧ (A25 ∨ A23 ∨ A44) ∧ (A33 ∨ ¬A37 ∨ ¬A14) ∧ (A3 ∨ ¬A22 ∨ ¬A38) ∧ (A25 ∨ ¬A14 ∨ A36) ∧ (A46 ∨ A11 ∨ ¬A6) ∧ (¬A33 ∨ ¬A35 ∨ A4) ∧ (A1 ∨ ¬A28 ∨ ¬A48) ∧ (¬A11 ∨ A48 ∨ ¬A7) ∧ (A26 ∨ A41 ∨ ¬A9) ∧ (¬A28 ∨ A47 ∨ A48) ∧ (A15 ∨ ¬A49 ∨ ¬A43) ∧ (¬A30 ∨ ¬A29 ∨ A16) ∧ (A14 ∨ A7 ∨ ¬A9) ∧ (¬A16 ∨ ¬A33 ∨ A17) ∧ (A12 ∨ A24 ∨ ¬A14)\n"
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "random_idx = random.choice(range(len(df_satlib)))\n",
    "print(df_satlib.iloc[random_idx]['formula'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1f4ac7f9-8c19-4b89-8b2d-e71fa9643977",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T13:40:43.734739Z",
     "iopub.status.busy": "2025-05-28T13:40:43.733833Z",
     "iopub.status.idle": "2025-05-28T13:40:43.742759Z",
     "shell.execute_reply": "2025-05-28T13:40:43.741145Z",
     "shell.execute_reply.started": "2025-05-28T13:40:43.734700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(¬((A0 → A1) → ¬A2 ∧ (A3 → A4) ∧ ¬¬A5) ∨ ((¬(A0 ∨ A1 → A2) ∨ A3) ∧ (A4 ∨ A5) ∧ A6 ∧ A7 ∧ A0) → (¬((A0 → A1) → ¬A2 ∧ (A3 → A4) ∧ ¬¬A5) ∨ ((¬(A0 ∨ A1 → A2) ∨ A3) ∧ (A4 ∨ A5) ∧ A6 ∧ A7)) ∧ (¬((A0 → A1) → ¬A2 ∧ (A3 → A4) ∧ ¬¬A5) ∨ A0)) ∧ ((¬((A0 → A1) → ¬A2 ∧ (A3 → A4) ∧ ¬¬A5) ∨ ((¬(A0 ∨ A1 → A2) ∨ A3) ∧ (A4 ∨ A5) ∧ A6 ∧ A7)) ∧ (¬((A0 → A1) → ¬A2 ∧ (A3 → A4) ∧ ¬¬A5) ∨ A0) → ¬((A0 → A1) → ¬A2 ∧ (A3 → A4) ∧ ¬¬A5) ∨ ((¬(A0 ∨ A1 → A2) ∨ A3) ∧ (A4 ∨ A5) ∧ A6 ∧ A7 ∧ A0))\n"
     ]
    }
   ],
   "source": [
    "random.seed(7)\n",
    "random_idx = random.choice(range(len(dataset)))\n",
    "print(dataset.iloc[random_idx]['formula'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "023c11a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T13:40:44.702859Z",
     "iopub.status.busy": "2025-05-28T13:40:44.701711Z",
     "iopub.status.idle": "2025-05-28T13:40:55.507120Z",
     "shell.execute_reply": "2025-05-28T13:40:55.505915Z",
     "shell.execute_reply.started": "2025-05-28T13:40:44.702815Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>formula</th>\n",
       "      <th>is_tautology</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(¬A0 ∨ ¬A1 ∨ ¬A2) ∧ (A3 ∨ A4 ∨ ¬A5) ∧ (¬A6 ∨ ¬...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(¬A0 ∨ ¬A1 ∨ ¬A2) ∧ (¬A3 ∨ A4 ∨ ¬A5) ∧ (¬A6 ∨ ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(A0 ∨ A1 ∨ A2) ∧ (¬A3 ∨ ¬A4 ∨ A5) ∧ (¬A6 ∨ A7 ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(A0 ∨ A1 ∨ A2) ∧ (¬A3 ∨ A4 ∨ ¬A5) ∧ (¬A6 ∨ ¬A7...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(A0 ∨ ¬A1 ∨ ¬A2) ∧ (A0 ∨ ¬A3 ∨ A4) ∧ (A5 ∨ A6 ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             formula  is_tautology\n",
       "0  (¬A0 ∨ ¬A1 ∨ ¬A2) ∧ (A3 ∨ A4 ∨ ¬A5) ∧ (¬A6 ∨ ¬...          True\n",
       "1  (¬A0 ∨ ¬A1 ∨ ¬A2) ∧ (¬A3 ∨ A4 ∨ ¬A5) ∧ (¬A6 ∨ ...          True\n",
       "2  (A0 ∨ A1 ∨ A2) ∧ (¬A3 ∨ ¬A4 ∨ A5) ∧ (¬A6 ∨ A7 ...          True\n",
       "3  (A0 ∨ A1 ∨ A2) ∧ (¬A3 ∨ A4 ∨ ¬A5) ∧ (¬A6 ∨ ¬A7...          True\n",
       "4  (A0 ∨ ¬A1 ∨ ¬A2) ∧ (A0 ∨ ¬A3 ∨ A4) ∧ (A5 ∨ A6 ...          True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Normalizing new formulas ---\n",
    "df_satlib['formula'] = df_satlib['formula'].apply(lambda f: str(Normalizer().normalize(f)))\n",
    "df_satlib[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e82dd447",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T13:40:56.553742Z",
     "iopub.status.busy": "2025-05-28T13:40:56.552947Z",
     "iopub.status.idle": "2025-05-28T13:40:56.891295Z",
     "shell.execute_reply": "2025-05-28T13:40:56.889843Z",
     "shell.execute_reply.started": "2025-05-28T13:40:56.553700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Dataset saved to: /home/labeconomia/nbalestra/theorem_prover/theorem_prover_core/ICTCS_notebooks/datasets/combined_with-dimacs_formulas_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# --- Concateating datasets and shuffling ---\n",
    "dataset_composed = pd.concat([dataset, df_satlib], ignore_index=True)\n",
    "dataset_composed = dataset_composed.sample(frac=1, random_state=42).reset_index(drop=True) # frac=1 means shuffle all rows\n",
    "                                                                                           # reset_index(drop=True) removes the old index\n",
    "\n",
    "# Saving new dataset in cvs format \n",
    "dataset_composed.to_csv('datasets/combined_with_dimacs_formulas_dataset.csv', index=False)\n",
    "print(f\"[INFO] Dataset saved to: {os.path.abspath('datasets/combined_with_dimacs_formulas_dataset.csv')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "577739db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T13:40:57.667698Z",
     "iopub.status.busy": "2025-05-28T13:40:57.666240Z",
     "iopub.status.idle": "2025-05-28T13:40:57.681627Z",
     "shell.execute_reply": "2025-05-28T13:40:57.680451Z",
     "shell.execute_reply.started": "2025-05-28T13:40:57.667657Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "formula         16000\n",
      "is_tautology    16000\n",
      "dtype: int64\n",
      "\n",
      "Number of True and False formulas: \n",
      "is_tautology\n",
      "False    10576\n",
      "True      5424\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Percentage of tautologies in the dataset: 33.90%\n"
     ]
    }
   ],
   "source": [
    "print(dataset_composed.count())\n",
    "count = dataset_composed.is_tautology.value_counts()\n",
    "print(f\"\\nNumber of True and False formulas: \\n{count}\\n\")\n",
    "\n",
    "total = len(dataset_composed)\n",
    "tautologies = dataset_composed[\"is_tautology\"].sum()\n",
    "percentage = (tautologies / total) * 100\n",
    "print(f\"Percentage of tautologies in the dataset: {percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f6a498",
   "metadata": {},
   "source": [
    "--- \n",
    "#### **2.2 Preparing Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0d470e3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T13:41:00.052777Z",
     "iopub.status.busy": "2025-05-28T13:41:00.051974Z",
     "iopub.status.idle": "2025-05-28T13:41:00.074624Z",
     "shell.execute_reply": "2025-05-28T13:41:00.073318Z",
     "shell.execute_reply.started": "2025-05-28T13:41:00.052738Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¬A0 ∨ A1\n",
      "¬(A0 ∨ A1)\n",
      "¬A0 ∨ A1 == ¬(A0 ∨ A1) shoud be false and is: False\n",
      "\n",
      "¬(A0 ∧ A1) → ¬A0 ∨ ¬A1\n",
      "¬(A0 ∨ A1) → ¬A0 ∧ ¬A1\n",
      "A0 ∧ (A1 ∨ A2) → (A0 ∧ A1) ∨ (A0 ∧ A2)\n"
     ]
    }
   ],
   "source": [
    "# --- Parser Module ---\n",
    "# Parses a string representation of a formula\n",
    "\n",
    "# Operator symbol to class map\n",
    "OPERATOR_CLASSES = {\n",
    "    '¬': Negation,\n",
    "    '∧': Conjunction,\n",
    "    '∨': Disjunction,\n",
    "    #'⊻': ExclusiveDisjunction,\n",
    "    '→': Implication\n",
    "}\n",
    "\n",
    "def tokenize(formula: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Splits a logical formula string into a list of tokens.\n",
    "\n",
    "    Supported tokens:\n",
    "        - Propositional letters: A0, A1, ...\n",
    "        - Connectives: ¬, ∧, ∨, ⊻, →\n",
    "        - Falsity: ⊥\n",
    "        - Parentheses: (,)\n",
    "\n",
    "    Args:\n",
    "        formula (str): A logical formula in string format.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: A list of string tokens (e.g. ['¬', '(', 'A0', '∧', 'A1', ')'])\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the formula contains an unrecognized character.  \n",
    "    \"\"\"\n",
    "    tokens = []\n",
    "    i = 0\n",
    "    # Iterate over each character\n",
    "    while i < len(formula):\n",
    "        c = formula[i]\n",
    "        # Skip whitespace\n",
    "        if c.isspace():\n",
    "            i += 1\n",
    "        elif c in '()¬∧∨⊻':\n",
    "            tokens.append(c)\n",
    "            i += 1\n",
    "        elif formula[i:i+1] == '→':  \n",
    "            tokens.append('→')\n",
    "            i += 1\n",
    "        elif c == 'A':\n",
    "            j = i + 1\n",
    "            while j < len(formula) and formula[j].isdigit():\n",
    "                j += 1\n",
    "            tokens.append(formula[i:j])\n",
    "            i = j\n",
    "        elif c == '⊥':\n",
    "            tokens.append('⊥')\n",
    "            i += 1\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected character: {c}\")\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def parse_formula_string(formula_string: str) -> Formula:\n",
    "    \"\"\"\n",
    "    Parses a string representation of a propositional logic formula into a\n",
    "    structured Formula object, respecting operator precedence and associativity.\n",
    "\n",
    "    Precedence and associativity are extracted directly from the formula classes.\n",
    "\n",
    "    Args:\n",
    "        formula_string (str): The input logical formula in string form.\n",
    "\n",
    "    Returns:\n",
    "        Formula: The parsed Formula object (e.g., Conjunction, Implication, etc.).\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the formula contains invalid or unexpected tokens.\n",
    "    \"\"\"\n",
    "    tokens = tokenize(formula_string)\n",
    "\n",
    "    def parse_expr(tokens: List[str], min_prec: int = 0) -> Formula:\n",
    "        \"\"\"\n",
    "        Recursively parses an expression using a precedence climbing strategy.\n",
    "\n",
    "        Args:\n",
    "            tokens (List[str]): List of tokens.\n",
    "            min_prec (int): Minimum precedence required to continue parsing.\n",
    "\n",
    "        Returns:\n",
    "            Formula: A Formula object representing the parsed structure.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: For invalid token sequences or unexpected syntax.\n",
    "        \"\"\"\n",
    "        if not tokens:\n",
    "            raise ValueError(\"Empty expression\")\n",
    "        \n",
    "        # Pick the first element of the list\n",
    "        token = tokens.pop(0)\n",
    "\n",
    "        # Base cases: atomic formulas\n",
    "        if token == '(':\n",
    "            # Handle parentheses by recursing on the subexpression\n",
    "            sub_tokens = []\n",
    "            depth = 1\n",
    "            while tokens:\n",
    "                t = tokens.pop(0)\n",
    "                if t == '(':\n",
    "                    depth += 1\n",
    "                elif t == ')':\n",
    "                    depth -= 1\n",
    "                    if depth == 0:\n",
    "                        break\n",
    "                sub_tokens.append(t)\n",
    "            node = parse_expr(sub_tokens)\n",
    "\n",
    "        elif token == '⊥':\n",
    "            node = Falsity()\n",
    "\n",
    "        elif token.startswith('A') and token[1:].isdigit():\n",
    "            node = Letter(int(token[1:]))\n",
    "\n",
    "        elif token == '¬':\n",
    "            # Unary operator\n",
    "            cls = Negation\n",
    "            right = parse_expr(tokens, cls.priority)\n",
    "            node = cls(right)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected token: {token}\")\n",
    "\n",
    "        # After parsing an atomic or unary expression, handle binary connectives\n",
    "        while tokens and tokens[0] in OPERATOR_CLASSES:\n",
    "            op = tokens[0]\n",
    "            cls = OPERATOR_CLASSES[op]\n",
    "            prec = cls.priority\n",
    "            assoc = cls.associativity\n",
    "\n",
    "            if prec < min_prec:\n",
    "                break\n",
    "\n",
    "            tokens.pop(0)  # consume the operator\n",
    "            \n",
    "            # Recursively parse the right-hand expression, and combine it with the \n",
    "            # left node into a full binary Formula\n",
    "            # Adjust min_prec depending on associativity\n",
    "            next_min_prec = prec + 1 if assoc == 'left' else prec\n",
    "\n",
    "            right = parse_expr(tokens, next_min_prec)\n",
    "            node = cls(node, right)\n",
    "\n",
    "        return node\n",
    "\n",
    "    return parse_expr(tokens)\n",
    "\n",
    "\n",
    "# Example 1: \n",
    "f1 = parse_formula_string(\"¬A0 ∨ A1\")\n",
    "f2 = parse_formula_string(\"¬(A0 ∨ A1)\")\n",
    "\n",
    "print(f1)  # (¬A0 ∨ A1)\n",
    "print(f2)  # ¬(A0 ∨ A1)\n",
    "print(f\"{f1} == {f2} shoud be false and is: {f1 == f2}\\n\")  # False — correct\n",
    "\n",
    "# Example 2:\n",
    "list_of_str = [\n",
    "    \"¬(A0 ∧ A1) → (¬A0 ∨ ¬A1)\",\n",
    "    \"¬(A0 ∨ A1) → (¬A0 ∧ ¬A1)\",\n",
    "    \"(A0 ∧ (A1 ∨ A2)) → ((A0 ∧ A1) ∨ (A0 ∧ A2))\"\n",
    "]\n",
    "\n",
    "for formula_str in list_of_str:\n",
    "    parsed_formulas = parse_formula_string(formula_str)\n",
    "    print(parsed_formulas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "de141204",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T13:41:01.491093Z",
     "iopub.status.busy": "2025-05-28T13:41:01.490611Z",
     "iopub.status.idle": "2025-05-28T13:41:01.502478Z",
     "shell.execute_reply": "2025-05-28T13:41:01.501387Z",
     "shell.execute_reply.started": "2025-05-28T13:41:01.491053Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000, 16000)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Formulas and Truth Values lists ---\n",
    "Formulas = dataset_composed['formula'].tolist()\n",
    "Truth_values = dataset_composed['is_tautology'].tolist()\n",
    "\n",
    "len(Formulas), len(Truth_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c086fad6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T13:41:01.997400Z",
     "iopub.status.busy": "2025-05-28T13:41:01.996949Z",
     "iopub.status.idle": "2025-05-28T13:41:02.021270Z",
     "shell.execute_reply": "2025-05-28T13:41:02.020180Z",
     "shell.execute_reply.started": "2025-05-28T13:41:01.997365Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16000"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formula_set = set(Formulas)\n",
    "len(formula_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "96c3a3f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T13:41:03.487169Z",
     "iopub.status.busy": "2025-05-28T13:41:03.486665Z",
     "iopub.status.idle": "2025-05-28T13:41:23.902904Z",
     "shell.execute_reply": "2025-05-28T13:41:23.901699Z",
     "shell.execute_reply.started": "2025-05-28T13:41:03.487134Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed second formula: (¬((A0 → A1 ∨ A2 ∨ A3) ∨ A0) → ¬(A0 → A1 ∨ A2 ∨ A3) ∧ ¬A0) ∧ (¬(A0 → A1 ∨ A2 ∨ A3) ∧ ¬A0 → ¬((A0 → A1 ∨ A2 ∨ A3) ∨ A0))\n",
      "Total parsed formulas: 16000\n",
      "Number of distinct parsed formulas: 16000\n"
     ]
    }
   ],
   "source": [
    "# --- Parse Dataset's formulas ---\n",
    "parsed_formulas = [parse_formula_string(f) for f in Formulas]\n",
    "\n",
    "print(f\"Parsed second formula: {parsed_formulas[1]}\")\n",
    "print(f\"Total parsed formulas: {len(parsed_formulas)}\")\n",
    "\n",
    "distinct_formulas = set(parsed_formulas)\n",
    "print(f\"Number of distinct parsed formulas: {len(distinct_formulas)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4ed07844",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T13:41:23.905432Z",
     "iopub.status.busy": "2025-05-28T13:41:23.905140Z",
     "iopub.status.idle": "2025-05-28T13:41:23.922172Z",
     "shell.execute_reply": "2025-05-28T13:41:23.921210Z",
     "shell.execute_reply.started": "2025-05-28T13:41:23.905400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 12800 samples\n",
      "Test set: 3200 samples\n"
     ]
    }
   ],
   "source": [
    "# Data splitting: 80% of the data is reserved for training the model. \n",
    "# Test Sets: 20% of the data is used for testing the model.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(parsed_formulas, \n",
    "                                                    Truth_values, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)\n",
    "\n",
    "print(f\"Training set: {len(X_train)} samples\")\n",
    "print(f\"Test set: {len(X_test)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "54b0e8f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T13:41:23.923861Z",
     "iopub.status.busy": "2025-05-28T13:41:23.923589Z",
     "iopub.status.idle": "2025-05-28T13:41:23.950224Z",
     "shell.execute_reply": "2025-05-28T13:41:23.949243Z",
     "shell.execute_reply.started": "2025-05-28T13:41:23.923831Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Convert symbols in numbers ---\n",
    "class CustomTokenizer:\n",
    "    \"\"\"\n",
    "    Custom tokenizer class for logical formulas.\n",
    "    This class converts formulas into tokenized integer representations,\n",
    "    and supports detokenizing back into Formula objects.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.token_to_formula: Dict[int, Formula] = {}\n",
    "        self.formula_to_token: Dict[Formula, int] = {}\n",
    "\n",
    "        self.connective_map = {\n",
    "            'Conjunction': 100,\n",
    "            'Disjunction': 101,\n",
    "            'Negation': 102,\n",
    "            'Implication': 103,\n",
    "            #'Exclusive Disjunction': 104\n",
    "        }\n",
    "\n",
    "        self.special_map = {\n",
    "            '(': 106,\n",
    "            ')': 107\n",
    "        }\n",
    "\n",
    "        self.falsity_token = 105\n",
    "\n",
    "    def fit(self, formulas: List[Formula]):\n",
    "        \"\"\"\n",
    "        Fit the tokenizer on a list of formulas, deriving tokens for each formula.\n",
    "        \"\"\"\n",
    "        for formula in formulas:\n",
    "            self._derive_tokens(formula)\n",
    "\n",
    "    def _derive_tokens(self, formula: Formula):\n",
    "        \"\"\"\n",
    "        Recursively derive tokens for all subcomponents of a formula.\n",
    "        \"\"\"\n",
    "        if isinstance(formula, Falsity):\n",
    "            if formula not in self.formula_to_token:\n",
    "                self.formula_to_token[formula] = self.falsity_token\n",
    "                self.token_to_formula[self.falsity_token] = formula\n",
    "\n",
    "        elif isinstance(formula, Letter):\n",
    "            letter_index = formula.n\n",
    "            if formula not in self.formula_to_token:\n",
    "                token = letter_index + 1  # Start letters from 1\n",
    "                self.formula_to_token[formula] = token\n",
    "                self.token_to_formula[token] = formula\n",
    "\n",
    "        elif isinstance(formula, UnaryConnectiveFormula):\n",
    "            self._derive_tokens(formula.formula)\n",
    "\n",
    "        elif isinstance(formula, BinaryConnectiveFormula):\n",
    "            self._derive_tokens(formula.left)\n",
    "            self._derive_tokens(formula.right)\n",
    "\n",
    "    def tokenize(self, formula: Formula) -> List[int]:\n",
    "        \"\"\"\n",
    "        Convert a formula into a list of integer tokens.\n",
    "        \"\"\"\n",
    "        tokens = []\n",
    "        self._tokenize_helper(formula, tokens)\n",
    "        return tokens\n",
    "\n",
    "    def _tokenize_helper(self, formula: Formula, tokens: List[int]):\n",
    "        \"\"\"\n",
    "        Helper method for recursive token generation.\n",
    "        \"\"\"\n",
    "        if formula in self.formula_to_token:\n",
    "            tokens.append(self.formula_to_token[formula])\n",
    "            return\n",
    "\n",
    "        if isinstance(formula, BinaryConnectiveFormula):\n",
    "            tokens.append(self.special_map['('])\n",
    "            self._tokenize_helper(formula.left, tokens)\n",
    "            tokens.append(self.connective_map[type(formula).__name__])\n",
    "            self._tokenize_helper(formula.right, tokens)\n",
    "            tokens.append(self.special_map[')'])\n",
    "\n",
    "        elif isinstance(formula, UnaryConnectiveFormula):\n",
    "            tokens.append(self.special_map['('])\n",
    "            tokens.append(self.connective_map[type(formula).__name__])\n",
    "            tokens.append(self.special_map['('])\n",
    "            self._tokenize_helper(formula.formula, tokens)\n",
    "            tokens.append(self.special_map[')'])\n",
    "            tokens.append(self.special_map[')'])\n",
    "\n",
    "        elif isinstance(formula, Falsity):\n",
    "            tokens.append(self.falsity_token)\n",
    "\n",
    "        elif isinstance(formula, Letter):\n",
    "            tokens.append(self.formula_to_token[formula])\n",
    "\n",
    "    def detokenize(self, tokens: List[int]) -> Formula:\n",
    "        \"\"\"\n",
    "        Convert a list of tokens (possibly padded) back into a Formula object.\n",
    "        \"\"\"\n",
    "        # Remove trailing padding\n",
    "        tokens = [t for t in tokens if t != 0]\n",
    "\n",
    "        def parse_expr(pos: int) -> Tuple[Formula, int]:\n",
    "            token = tokens[pos]\n",
    "\n",
    "            if token == self.falsity_token:\n",
    "                return Falsity(), pos + 1\n",
    "\n",
    "            elif token in self.token_to_formula:\n",
    "                return self.token_to_formula[token], pos + 1\n",
    "\n",
    "            elif token == self.special_map['(']:\n",
    "                next_token = tokens[pos + 1]\n",
    "\n",
    "                # Handle unary connective\n",
    "                if next_token in self.connective_map.values() and tokens[pos + 2] == self.special_map['(']:\n",
    "                    op_token = next_token\n",
    "                    inner_formula, new_pos = parse_expr(pos + 3)\n",
    "                    assert tokens[new_pos] == self.special_map[')']\n",
    "                    assert tokens[new_pos + 1] == self.special_map[')']\n",
    "                    connective_class = self._connective_class(op_token)\n",
    "                    return connective_class(inner_formula), new_pos + 2\n",
    "\n",
    "                # Handle binary connective\n",
    "                else:\n",
    "                    left_formula, pos_left = parse_expr(pos + 1)\n",
    "                    op_token = tokens[pos_left]\n",
    "                    right_formula, pos_right = parse_expr(pos_left + 1)\n",
    "                    assert tokens[pos_right] == self.special_map[')']\n",
    "                    connective_class = self._connective_class(op_token)\n",
    "                    return connective_class(left_formula, right_formula), pos_right + 1\n",
    "\n",
    "            raise ValueError(f\"Unexpected token at position {pos}: {tokens[pos:]}\")\n",
    "\n",
    "        return parse_expr(0)[0]\n",
    "\n",
    "    def _connective_class(self, token: int):\n",
    "        \"\"\"\n",
    "        Resolve token ID back to the appropriate connective class.\n",
    "        \"\"\"\n",
    "        for name, code in self.connective_map.items():\n",
    "            if token == code:\n",
    "                return {\n",
    "                    'Conjunction': Conjunction,\n",
    "                    'Disjunction': Disjunction,\n",
    "                    'Negation': Negation,\n",
    "                    'Implication': Implication,\n",
    "                    #'Exclusive Disjunction': ExclusiveDisjunction\n",
    "                }[name]\n",
    "        raise ValueError(f\"Unknown connective token: {token}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cffd5762",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T13:41:23.953757Z",
     "iopub.status.busy": "2025-05-28T13:41:23.953463Z",
     "iopub.status.idle": "2025-05-28T13:41:30.063960Z",
     "shell.execute_reply": "2025-05-28T13:41:30.062952Z",
     "shell.execute_reply.started": "2025-05-28T13:41:23.953725Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: 1, Formula: A0\n",
      "Token: 2, Formula: A1\n",
      "Token: 105, Formula: ⊥\n",
      "Token: 3, Formula: A2\n",
      "Token: 4, Formula: A3\n",
      "Token: 5, Formula: A4\n",
      "Token: 6, Formula: A5\n",
      "Token: 7, Formula: A6\n",
      "Token: 8, Formula: A7\n",
      "Token: 9, Formula: A8\n",
      "Token: 10, Formula: A9\n",
      "Token: 11, Formula: A10\n",
      "Token: 12, Formula: A11\n",
      "Token: 13, Formula: A12\n",
      "Token: 14, Formula: A13\n",
      "Token: 15, Formula: A14\n",
      "Token: 16, Formula: A15\n",
      "Token: 17, Formula: A16\n",
      "Token: 18, Formula: A17\n",
      "Token: 19, Formula: A18\n",
      "Token: 20, Formula: A19\n",
      "Token: 21, Formula: A20\n",
      "Token: 22, Formula: A21\n",
      "Token: 23, Formula: A22\n",
      "Token: 24, Formula: A23\n",
      "Token: 25, Formula: A24\n",
      "Token: 26, Formula: A25\n",
      "Token: 27, Formula: A26\n",
      "Token: 28, Formula: A27\n",
      "Token: 29, Formula: A28\n",
      "Token: 30, Formula: A29\n",
      "Token: 31, Formula: A30\n",
      "Token: 32, Formula: A31\n",
      "Token: 33, Formula: A32\n",
      "Token: 34, Formula: A33\n",
      "Token: 35, Formula: A34\n",
      "Token: 36, Formula: A35\n",
      "Token: 37, Formula: A36\n",
      "Token: 38, Formula: A37\n",
      "Token: 39, Formula: A38\n",
      "Token: 40, Formula: A39\n",
      "Token: 41, Formula: A40\n",
      "Token: 42, Formula: A41\n",
      "Token: 43, Formula: A42\n",
      "Token: 44, Formula: A43\n",
      "Token: 45, Formula: A44\n",
      "Token: 46, Formula: A45\n",
      "Token: 47, Formula: A46\n",
      "Token: 48, Formula: A47\n",
      "Token: 49, Formula: A48\n",
      "Token: 50, Formula: A49\n",
      "\n",
      "Tokenized representation of (A0 ∧ ¬A1): [106, 1, 100, 106, 102, 106, 2, 107, 107, 107]\n"
     ]
    }
   ],
   "source": [
    "# Inspecting unique formula's token \n",
    "tokenizer = CustomTokenizer()\n",
    "tokenizer.fit(parsed_formulas)\n",
    "\n",
    "def print_token_mappings(tokenizer):\n",
    "    for token, formula in tokenizer.token_to_formula.items():\n",
    "        print(f\"Token: {token}, Formula: {formula}\")\n",
    "\n",
    "print_token_mappings(tokenizer)\n",
    "\n",
    "# Example\n",
    "example_formula = Conjunction(Letter(0), Negation(Letter(1)))\n",
    "tokens = tokenizer.tokenize(example_formula)\n",
    "\n",
    "print(f\"\\nTokenized representation of ({example_formula}): {tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9a175bb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T13:41:30.066849Z",
     "iopub.status.busy": "2025-05-28T13:41:30.065158Z",
     "iopub.status.idle": "2025-05-28T13:41:34.889370Z",
     "shell.execute_reply": "2025-05-28T13:41:34.888059Z",
     "shell.execute_reply.started": "2025-05-28T13:41:30.066766Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Tokenize Train Test ---\n",
    "tokenizer = CustomTokenizer()\n",
    "tokenizer.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9578736e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T13:41:34.891318Z",
     "iopub.status.busy": "2025-05-28T13:41:34.890974Z",
     "iopub.status.idle": "2025-05-28T13:41:34.899710Z",
     "shell.execute_reply": "2025-05-28T13:41:34.898570Z",
     "shell.execute_reply.started": "2025-05-28T13:41:34.891287Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Formula: (¬((¬A0 → ⊥) ∨ A0) → ¬(¬A0 → ⊥) ∧ ¬A0) ∧ (¬(¬A0 → ⊥) ∧ ¬A0 → ¬((¬A0 → ⊥) ∨ A0))\n",
      "Tokenized Version: [106, 106, 106, 102, 106, 106, 106, 106, 102, 106, 1, 107, 107, 103, 105, 107, 101, 1, 107, 107, 107, 103, 106, 106, 102, 106, 106, 106, 102, 106, 1, 107, 107, 103, 105, 107, 107, 107, 100, 106, 102, 106, 1, 107, 107, 107, 107, 100, 106, 106, 106, 102, 106, 106, 106, 102, 106, 1, 107, 107, 103, 105, 107, 107, 107, 100, 106, 102, 106, 1, 107, 107, 107, 103, 106, 102, 106, 106, 106, 106, 102, 106, 1, 107, 107, 103, 105, 107, 101, 1, 107, 107, 107, 107, 107]\n",
      "\n",
      "Original Formula: ¬((A0 ∧ (A1 → A2)) ∨ (A3 → A4) ∨ ⊥ ∨ A5)\n",
      "Tokenized Version: [106, 102, 106, 106, 106, 106, 106, 1, 100, 106, 2, 103, 3, 107, 107, 101, 106, 4, 103, 5, 107, 107, 101, 105, 107, 101, 6, 107, 107, 107]\n",
      "\n",
      "Original Formula: ¬⊥ ∨ A0 ∨ A1\n",
      "Tokenized Version: [106, 106, 106, 102, 106, 105, 107, 107, 101, 1, 107, 101, 2, 107]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test function\n",
    "def test_tokenizer(tokenizer, example_formulas):\n",
    "    for formula in example_formulas:\n",
    "        tokens = tokenizer.tokenize(formula)\n",
    "        print(f\"Original Formula: {formula}\")\n",
    "        print(f\"Tokenized Version: {tokens}\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tokenizer = CustomTokenizer()\n",
    "    example_formulas = [X_train[2], X_train[3], X_train[4]]\n",
    "    tokenizer.fit(example_formulas)\n",
    "\n",
    "    test_tokenizer(tokenizer, example_formulas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c83b70bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T13:41:34.901369Z",
     "iopub.status.busy": "2025-05-28T13:41:34.901058Z",
     "iopub.status.idle": "2025-05-28T13:41:39.888986Z",
     "shell.execute_reply": "2025-05-28T13:41:39.887700Z",
     "shell.execute_reply.started": "2025-05-28T13:41:34.901335Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique letters: 50\n",
      "Number of unique connectives: 4\n",
      "Number of spacial tokens: 2\n"
     ]
    }
   ],
   "source": [
    "tokenizer = CustomTokenizer()\n",
    "tokenizer.fit(X_train)\n",
    "\n",
    "num_letters = sum(1 for formula in tokenizer.formula_to_token if isinstance(formula, Letter))\n",
    "num_connectives = len(tokenizer.connective_map)\n",
    "num_parenthesis = sum(1 for formula in tokenizer.special_map)\n",
    "\n",
    "print(f\"Number of unique letters: {num_letters}\")\n",
    "print(f\"Number of unique connectives: {num_connectives}\")\n",
    "print(f\"Number of spacial tokens: {num_parenthesis}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7ccfce9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T13:41:39.890751Z",
     "iopub.status.busy": "2025-05-28T13:41:39.890396Z",
     "iopub.status.idle": "2025-05-28T13:43:21.532833Z",
     "shell.execute_reply": "2025-05-28T13:43:21.531592Z",
     "shell.execute_reply.started": "2025-05-28T13:41:39.890719Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Tokenize Train and Test formulas ---\n",
    "tokenizer = CustomTokenizer()\n",
    "tokenizer.fit(X_train)\n",
    "\n",
    "X_train_seq = [tokenizer.tokenize(formula) for formula in X_train]\n",
    "X_test_seq = [tokenizer.tokenize(formula) for formula in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "117ead9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T13:43:21.534539Z",
     "iopub.status.busy": "2025-05-28T13:43:21.534183Z",
     "iopub.status.idle": "2025-05-28T13:43:23.197090Z",
     "shell.execute_reply": "2025-05-28T13:43:23.195799Z",
     "shell.execute_reply.started": "2025-05-28T13:43:21.534506Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Convert lists of int into tensors ---\n",
    "X_train_tensors = [torch.tensor(seq, dtype=torch.long) for seq in X_train_seq]\n",
    "X_test_tensors = [torch.tensor(seq, dtype=torch.long) for seq in X_test_seq]\n",
    "\n",
    "# --- Pad sequences (fill with 0s) ---\n",
    "X_train_padded = pad_sequence(X_train_tensors, batch_first=True, padding_value=0) # With batch_first = True, Shape: (batch_size, seq_len, features)\n",
    "X_test_padded = pad_sequence(X_test_tensors, batch_first=True, padding_value=0)\n",
    "\n",
    "# --- Convert labels to tensors --- \n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b4300c25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T13:43:23.201202Z",
     "iopub.status.busy": "2025-05-28T13:43:23.200870Z",
     "iopub.status.idle": "2025-05-28T13:43:23.207545Z",
     "shell.execute_reply": "2025-05-28T13:43:23.206418Z",
     "shell.execute_reply.started": "2025-05-28T13:43:23.201170Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_padded shape: torch.Size([12800, 4468]) -> [num_of_tokenized_formulas, num_of_tokens_per_formula])\n",
      "y_train_tensor shape: torch.Size([12800]) -> [num_of_labels]\n",
      "\n",
      "X_test_padded shape: torch.Size([3200, 4433]) -> [num_of_tokenized_formulas, num_of_tokens_per_formula])\n",
      "y_test_tensor shape: torch.Size([12800]) -> [num_of_labels]\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train_padded shape: {X_train_padded.shape} -> [num_of_tokenized_formulas, num_of_tokens_per_formula])\")\n",
    "print(f\"y_train_tensor shape: {y_train_tensor.shape} -> [num_of_labels]\")\n",
    "\n",
    "print(f\"\\nX_test_padded shape: {X_test_padded.shape} -> [num_of_tokenized_formulas, num_of_tokens_per_formula])\")\n",
    "print(f\"y_test_tensor shape: {y_train_tensor.shape} -> [num_of_labels]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08aabed",
   "metadata": {},
   "source": [
    "--- \n",
    "#### **2.3 Getting a PyTorch Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e26cd479",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T13:43:23.209043Z",
     "iopub.status.busy": "2025-05-28T13:43:23.208759Z",
     "iopub.status.idle": "2025-05-28T13:43:23.219856Z",
     "shell.execute_reply": "2025-05-28T13:43:23.218470Z",
     "shell.execute_reply.started": "2025-05-28T13:43:23.209013Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset FormulaDataset\n",
      "  Number of datapoints: 12800\n",
      "  Input shape: torch.Size([4468])\n",
      "  Target type: torch.float32\n",
      " \n",
      "Dataset FormulaDataset\n",
      "  Number of datapoints: 3200\n",
      "  Input shape: torch.Size([4433])\n",
      "  Target type: torch.float32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Create a PyTorch Dataset ---\n",
    "class FormulaDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "        # Define class label info\n",
    "        self.classes = ['non-tautology', 'tautology']\n",
    "        self.class_to_idx = {label: i for i, label in enumerate(self.classes)}\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (\n",
    "            f\"Dataset FormulaDataset\\n\"\n",
    "            f\"  Number of datapoints: {len(self)}\\n\"\n",
    "            f\"  Input shape: {self.X[0].shape if len(self.X) > 0 else 'N/A'}\\n\"\n",
    "            f\"  Target type: {self.y.dtype}\\n\"\n",
    "        )\n",
    "\n",
    "\n",
    "train_data = FormulaDataset(X_train_padded, y_train_tensor)\n",
    "test_data = FormulaDataset(X_test_padded, y_test_tensor)\n",
    "\n",
    "print(f\"{train_data} \\n{test_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6a0d34b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T13:43:23.221975Z",
     "iopub.status.busy": "2025-05-28T13:43:23.221583Z",
     "iopub.status.idle": "2025-05-28T13:43:23.233108Z",
     "shell.execute_reply": "2025-05-28T13:43:23.231898Z",
     "shell.execute_reply.started": "2025-05-28T13:43:23.221928Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train class counts: Counter({False: 8484, True: 4316})\n",
      "Test class counts: Counter({False: 2092, True: 1108})\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "train_class_counts = collections.Counter(y_train)\n",
    "test_class_counts = collections.Counter(y_test)\n",
    "\n",
    "print(f\"Train class counts: {train_class_counts}\")\n",
    "print(f\"Test class counts: {test_class_counts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "72234fab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T13:43:23.234868Z",
     "iopub.status.busy": "2025-05-28T13:43:23.234565Z",
     "iopub.status.idle": "2025-05-28T13:43:23.241566Z",
     "shell.execute_reply": "2025-05-28T13:43:23.240435Z",
     "shell.execute_reply.started": "2025-05-28T13:43:23.234836Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set (15360 samples): False = 66.28 % and True = 33.72 %\n",
      "Test set (240samples): False = 65.38% and True = 34.62%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train set (15360 samples): False = {(8484/12800)*100:.2f} % and True = {(4316/12800)* 100:.2f} %\")\n",
    "print(f\"Test set (240samples): False = {(2092/3200)*100:.2f}% and True = {(1108/3200)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2a61c642",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T13:43:23.243130Z",
     "iopub.status.busy": "2025-05-28T13:43:23.242846Z",
     "iopub.status.idle": "2025-05-28T13:43:23.249689Z",
     "shell.execute_reply": "2025-05-28T13:43:23.248501Z",
     "shell.execute_reply.started": "2025-05-28T13:43:23.243100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['non-tautology', 'tautology']\n",
      "{'non-tautology': 0, 'tautology': 1}\n"
     ]
    }
   ],
   "source": [
    "# Classes Names and Labels Map\n",
    "class_names = train_data.classes\n",
    "class_to_idx = train_data.class_to_idx\n",
    "print(class_names)\n",
    "print(class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8d8e40a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T13:43:23.251224Z",
     "iopub.status.busy": "2025-05-28T13:43:23.250932Z",
     "iopub.status.idle": "2025-05-28T13:43:23.263794Z",
     "shell.execute_reply": "2025-05-28T13:43:23.262633Z",
     "shell.execute_reply.started": "2025-05-28T13:43:23.251194Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random formula: tensor([106, 106, 106,  ...,   0,   0,   0]), \n",
      "\n",
      "Label: 1.0\n",
      "Reconstructed formula: (A0 ∧ ((A0 ∧ (A1 ∧ ⊥ → A2 ∨ ⊥ → ¬A3) → A4 ∧ A5 ∧ A0) ∨ A0) → (A0 ∧ (A0 ∧ (A1 ∧ ⊥ → A2 ∨ ⊥ → ¬A3) → A4 ∧ A5 ∧ A0)) ∨ (A0 ∧ A0)) ∧ ((A0 ∧ (A0 ∧ (A1 ∧ ⊥ → A2 ∨ ⊥ → ¬A3) → A4 ∧ A5 ∧ A0)) ∨ (A0 ∧ A0) → A0 ∧ ((A0 ∧ (A1 ∧ ⊥ → A2 ∨ ⊥ → ¬A3) → A4 ∧ A5 ∧ A0) ∨ A0))\n",
      "\n",
      "Tautology status: tautology\n"
     ]
    }
   ],
   "source": [
    "# Visualize a random sampled formula\n",
    "torch.manual_seed(41)\n",
    "random_idx = torch.randint(0, len(train_data), size=[1]).item()\n",
    "\n",
    "random_formula, label = train_data[random_idx]\n",
    "print(f\"Random formula: {random_formula}, \\n\\nLabel: {label}\")\n",
    "\n",
    "# Convert tensor to list of token IDs (needed by detokenize)\n",
    "token_list = random_formula.tolist()\n",
    "# Reconstruct the original Formula\n",
    "reconstructed_formula = tokenizer.detokenize(token_list)\n",
    "print(f\"Reconstructed formula: {reconstructed_formula}\")\n",
    "print(f\"\\nTautology status: {class_names[int(label.item())]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84980426",
   "metadata": {},
   "source": [
    "---\n",
    "#### **2.4 DataLoader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4fda7706",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T13:43:23.265415Z",
     "iopub.status.busy": "2025-05-28T13:43:23.265126Z",
     "iopub.status.idle": "2025-05-28T13:43:23.273636Z",
     "shell.execute_reply": "2025-05-28T13:43:23.272313Z",
     "shell.execute_reply.started": "2025-05-28T13:43:23.265385Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloaders: (<torch.utils.data.dataloader.DataLoader object at 0x7fed58b565f0>, <torch.utils.data.dataloader.DataLoader object at 0x7fed58b56f80>)\n",
      "Length of train dataloader: 800 batches of 16\n",
      "Length of test dataloader: 200 batches of 16\n"
     ]
    }
   ],
   "source": [
    "# Setup the batch size hyperparameter\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# Turn datasets into iterables (batches)\n",
    "train_dataloader = DataLoader(train_data, # dataset to turn into iterable\n",
    "                              batch_size=BATCH_SIZE, # how many samples per batch? \n",
    "                              shuffle=True # shuffle data every epoch?\n",
    "                                           # This removes the data order, so the model does not learn it \n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(test_data,\n",
    "                             batch_size=BATCH_SIZE,\n",
    "                             shuffle=False # don't necessarily have to shuffle the testing data\n",
    ")\n",
    "\n",
    "# Let's check out what we've created\n",
    "print(f\"Dataloaders: {train_dataloader, test_dataloader}\") \n",
    "print(f\"Length of train dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}\")\n",
    "print(f\"Length of test dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "48a03460",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T13:43:23.275556Z",
     "iopub.status.busy": "2025-05-28T13:43:23.275228Z",
     "iopub.status.idle": "2025-05-28T13:43:23.285664Z",
     "shell.execute_reply": "2025-05-28T13:43:23.284436Z",
     "shell.execute_reply.started": "2025-05-28T13:43:23.275524Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(torch.Size([16, 4468]), torch.Size([16])) -> [batch_size, num_of_tokens_per_formula], [bach_size]\n"
     ]
    }
   ],
   "source": [
    "# Checking out what's inside the training dataloader\n",
    "train_features_batch, train_labels_batch = next(iter(train_dataloader)) # next() grabs the first batch from the iterator\n",
    "print(f\"{train_features_batch.shape, train_labels_batch.shape} -> [batch_size, num_of_tokens_per_formula], [bach_size]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c27562b",
   "metadata": {},
   "source": [
    "--- \n",
    "#### **2.5 Set up device agnostic-code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6b1ac9af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T13:43:23.287805Z",
     "iopub.status.busy": "2025-05-28T13:43:23.287476Z",
     "iopub.status.idle": "2025-05-28T13:43:23.437169Z",
     "shell.execute_reply": "2025-05-28T13:43:23.435921Z",
     "shell.execute_reply.started": "2025-05-28T13:43:23.287772Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c5b644",
   "metadata": {},
   "source": [
    "--- \n",
    "#### **2.5 Reproducibility**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3e2fecad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T13:43:23.439767Z",
     "iopub.status.busy": "2025-05-28T13:43:23.439307Z",
     "iopub.status.idle": "2025-05-28T13:43:23.445826Z",
     "shell.execute_reply": "2025-05-28T13:43:23.444500Z",
     "shell.execute_reply.started": "2025-05-28T13:43:23.439732Z"
    }
   },
   "outputs": [],
   "source": [
    "def set_seeds(seed: int=42):\n",
    "    \"\"\"Sets random sets for torch operations.\n",
    "\n",
    "    Args:\n",
    "        seed (int, optional): Random seed to set. Defaults to 42.\n",
    "    \"\"\"\n",
    "    # Set the seed for general torch operations\n",
    "    torch.manual_seed(seed)\n",
    "    # Set the seed for CUDA torch operations (ones that happen on the GPU)\n",
    "    #torch.mps.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf6e111",
   "metadata": {},
   "source": [
    "--- \n",
    "#### **2.6 `train_step()`, `test_test()`, and `train_()` functions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e7dc857d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T13:43:23.448053Z",
     "iopub.status.busy": "2025-05-28T13:43:23.447751Z",
     "iopub.status.idle": "2025-05-28T13:43:23.468740Z",
     "shell.execute_reply": "2025-05-28T13:43:23.467640Z",
     "shell.execute_reply.started": "2025-05-28T13:43:23.448023Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Functions for training and testing a PyTorch model ---\n",
    "\n",
    "def train_step(model: torch.nn.Module, \n",
    "               dataloader: torch.utils.data.DataLoader, \n",
    "               loss_fn: torch.nn.Module, \n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               device: torch.device) -> Tuple[float, float]:\n",
    "  \"\"\"Trains a PyTorch model for a single epoch.\n",
    "\n",
    "  Turns a target PyTorch model to training mode and then\n",
    "  runs through all of the required training steps (forward\n",
    "  pass, loss calculation, optimizer step).\n",
    "\n",
    "  Args:\n",
    "    model: A PyTorch model to be trained.\n",
    "    dataloader: A DataLoader instance for the model to be trained on.\n",
    "    loss_fn: A PyTorch loss function to minimize.\n",
    "    optimizer: A PyTorch optimizer to help minimize the loss function.\n",
    "    device: A target device to compute on.\n",
    "\n",
    "  Returns:\n",
    "    A tuple of training loss and training accuracy metrics.\n",
    "    In the form (train_loss, train_accuracy).\n",
    "    \n",
    "  \"\"\"\n",
    "  # Put model in train mode\n",
    "  model.train()\n",
    "  \n",
    "  # Setup train loss and train accuracy values\n",
    "  train_loss, train_acc = 0, 0\n",
    "  \n",
    "  # Loop through data loader data batches\n",
    "  for batch, (X, y) in enumerate(dataloader):\n",
    "      # Send data to target device\n",
    "      X, y = X.to(device), y.to(device)\n",
    "\n",
    "      # 1. Forward pass\n",
    "      y_logits = model(X).squeeze(dim=1)\n",
    "      y_preds = torch.round(torch.sigmoid(y_logits))\n",
    "\n",
    "      # 2. Calculate  and accumulate loss\n",
    "      loss = loss_fn(y_logits, y)\n",
    "      train_loss += loss.item() \n",
    "\n",
    "      # 3. Optimizer zero grad\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      # 4. Loss backward\n",
    "      loss.backward()\n",
    "\n",
    "      # 5. Optimizer step\n",
    "      optimizer.step()\n",
    "\n",
    "      # Calculate and accumulate accuracy metric across all batches\n",
    "      train_acc += (y_preds == y).sum().item()/len(y_preds)\n",
    "\n",
    "  # Adjust metrics to get average loss and accuracy per batch \n",
    "  train_loss = train_loss / len(dataloader)\n",
    "  train_acc = train_acc / len(dataloader)\n",
    "  return train_loss, train_acc\n",
    "\n",
    "def test_step(model: torch.nn.Module, \n",
    "              dataloader: torch.utils.data.DataLoader, \n",
    "              loss_fn: torch.nn.Module,\n",
    "              device: torch.device) -> Tuple[float, float]:\n",
    "  \"\"\"Tests a PyTorch model for a single epoch.\n",
    "\n",
    "  Turns a target PyTorch model to \"eval\" mode and then performs\n",
    "  a forward pass on a testing dataset.\n",
    "\n",
    "  Args:\n",
    "    model: A PyTorch model to be tested.\n",
    "    dataloader: A DataLoader instance for the model to be tested on.\n",
    "    loss_fn: A PyTorch loss function to calculate loss on the test data.\n",
    "    device: A target device to compute on.\n",
    "\n",
    "  Returns:\n",
    "    A tuple of testing loss and testing accuracy metrics.\n",
    "    In the form (test_loss, test_accuracy). \n",
    "    \n",
    "  \"\"\"\n",
    "  # Put model in eval mode\n",
    "  model.eval() \n",
    "  \n",
    "  # Setup test loss and test accuracy values\n",
    "  test_loss, test_acc = 0, 0\n",
    "  \n",
    "  # Turn on inference context manager\n",
    "  with torch.inference_mode():\n",
    "      # Loop through DataLoader batches\n",
    "      for batch, (X, y) in enumerate(dataloader):\n",
    "          # Send data to target device\n",
    "          X, y = X.to(device), y.to(device)\n",
    "  \n",
    "          # 1. Forward pass\n",
    "          test_pred_logits = model(X).squeeze(dim=1)\n",
    "          preds = torch.round(torch.sigmoid(test_pred_logits))\n",
    "\n",
    "          # 2. Calculate and accumulate loss\n",
    "          loss = loss_fn(test_pred_logits, y)\n",
    "          test_loss += loss.item()\n",
    "          \n",
    "          # Calculate and accumulate accuracy\n",
    "          test_pred_labels = preds\n",
    "          test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
    "          \n",
    "  # Adjust metrics to get average loss and accuracy per batch \n",
    "  test_loss = test_loss / len(dataloader)\n",
    "  test_acc = test_acc / len(dataloader)\n",
    "  return test_loss, test_acc\n",
    "\n",
    "def train(model: torch.nn.Module, \n",
    "          train_dataloader: torch.utils.data.DataLoader, \n",
    "          test_dataloader: torch.utils.data.DataLoader, \n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          loss_fn: torch.nn.Module,\n",
    "          epochs: int,\n",
    "          device: torch.device) -> Dict[str, List]:\n",
    "  \"\"\"Trains and tests a PyTorch model.\n",
    "\n",
    "  Passes a target PyTorch models through train_step() and test_step()\n",
    "  functions for a number of epochs, training and testing the model\n",
    "  in the same epoch loop.\n",
    "\n",
    "  Calculates, prints and stores evaluation metrics throughout.\n",
    "\n",
    "  Args:\n",
    "    model: A PyTorch model to be trained and tested.\n",
    "    train_dataloader: A DataLoader instance for the model to be trained on.\n",
    "    test_dataloader: A DataLoader instance for the model to be tested on.\n",
    "    optimizer: A PyTorch optimizer to help minimize the loss function.\n",
    "    loss_fn: A PyTorch loss function to calculate loss on both datasets.\n",
    "    epochs: An integer indicating how many epochs to train for.\n",
    "    device: A target device to compute on.\n",
    "\n",
    "  Returns:\n",
    "    A dictionary of training and testing loss as well as training and\n",
    "    testing accuracy metrics. Each metric has a value in a list for \n",
    "    each epoch.\n",
    "    In the form: {train_loss: [...],\n",
    "                  train_acc: [...],\n",
    "                  test_loss: [...],\n",
    "                  test_acc: [...]} \n",
    "\n",
    "  \"\"\"\n",
    "  # Create empty results dictionary\n",
    "  results = {\"train_loss\": [],\n",
    "             \"train_acc\": [],\n",
    "             \"test_loss\": [],\n",
    "             \"test_acc\": []\n",
    "  }\n",
    "  \n",
    "  # Loop through training and testing steps for a number of epochs\n",
    "  for epoch in tqdm(range(epochs)):\n",
    "      train_loss, train_acc = train_step(model=model,\n",
    "                                          dataloader=train_dataloader,\n",
    "                                          loss_fn=loss_fn,\n",
    "                                          optimizer=optimizer,\n",
    "                                          device=device)\n",
    "      test_loss, test_acc = test_step(model=model,\n",
    "          dataloader=test_dataloader,\n",
    "          loss_fn=loss_fn,\n",
    "          device=device)\n",
    "      \n",
    "      # Print out what's happening\n",
    "      print(\n",
    "          f\"Epoch: {epoch+1} | \"\n",
    "          f\"train_loss: {train_loss:.4f} | \"\n",
    "          f\"train_acc: {train_acc:.4f} | \"\n",
    "          f\"test_loss: {test_loss:.4f} | \"\n",
    "          f\"test_acc: {test_acc:.4f}\"\n",
    "      )\n",
    "\n",
    "      # Update results dictionary\n",
    "      results[\"train_loss\"].append(train_loss)\n",
    "      results[\"train_acc\"].append(train_acc)\n",
    "      results[\"test_loss\"].append(test_loss)\n",
    "      results[\"test_acc\"].append(test_acc)\n",
    "\n",
    "  # Return the filled results at the end of the epochs\n",
    "  return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78835400",
   "metadata": {},
   "source": [
    "--- \n",
    "#### **2.7 Function to save a model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "acc44a7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T13:43:23.470545Z",
     "iopub.status.busy": "2025-05-28T13:43:23.470200Z",
     "iopub.status.idle": "2025-05-28T13:43:23.478072Z",
     "shell.execute_reply": "2025-05-28T13:43:23.477043Z",
     "shell.execute_reply.started": "2025-05-28T13:43:23.470513Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_model(model: torch.nn.Module,\n",
    "               target_dir: str,\n",
    "               model_name: str):\n",
    "  \"\"\"Saves a PyTorch model to a target directory.\n",
    "\n",
    "  Args:\n",
    "    model: A target PyTorch model to save.\n",
    "    target_dir: A directory for saving the model to.\n",
    "    model_name: A filename for the saved model. Should include\n",
    "      either \".pth\" or \".pt\" as the file extension.\n",
    "  \n",
    "  Example usage:\n",
    "    save_model(model=model_0,\n",
    "               target_dir=\"models\",\n",
    "               model_name=\"05_going_modular_tingvgg_model.pth\")\n",
    "  \"\"\"\n",
    "  # Create target directory\n",
    "  target_dir_path = Path(target_dir)\n",
    "  target_dir_path.mkdir(parents=True,\n",
    "                        exist_ok=True)\n",
    "  \n",
    "  # Create model save path\n",
    "  assert model_name.endswith(\".pth\") or model_name.endswith(\".pt\"), \"model_name should end with '.pt' or '.pth'\"\n",
    "  model_save_path = target_dir_path / model_name\n",
    "\n",
    "  # Save the model state_dict()\n",
    "  print(f\"[INFO] Saving model to: {model_save_path}\")\n",
    "  torch.save(obj=model.state_dict(),\n",
    "             f=model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3d7be9",
   "metadata": {},
   "source": [
    "---\n",
    "#### **2.8 Hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c2ce63e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T13:43:23.480020Z",
     "iopub.status.busy": "2025-05-28T13:43:23.479732Z",
     "iopub.status.idle": "2025-05-28T13:43:23.502220Z",
     "shell.execute_reply": "2025-05-28T13:43:23.501078Z",
     "shell.execute_reply.started": "2025-05-28T13:43:23.479989Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size (including padding token): 108\n",
      "Max index in batch: 107\n"
     ]
    }
   ],
   "source": [
    "# --- Hyperparameters --- \n",
    "# Determine the vocabulary size for the embedding layer and add 1 for padding index (0)\n",
    "all_token_indices = (\n",
    "    list(tokenizer.formula_to_token.values()) +\n",
    "    list(tokenizer.connective_map.values()) +\n",
    "    list(tokenizer.special_map.values()) +\n",
    "    [tokenizer.falsity_token]\n",
    ")\n",
    "\n",
    "VOCAB_SIZE = max(all_token_indices) + 1  \n",
    "print(f\"Vocabulary size (including padding token): {VOCAB_SIZE}\")\n",
    "print(\"Max index in batch:\", train_features_batch.max().item())\n",
    "assert train_features_batch.max().item() < VOCAB_SIZE, \"Some token indices exceed the embedding size!\"\n",
    "\n",
    "EMBEDDING_DIM = 32\n",
    "LR = 0.0005"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c16ca0",
   "metadata": {},
   "source": [
    "---\n",
    "#### **2.9 Build Model 4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8d0c116c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T10:13:51.280395Z",
     "iopub.status.busy": "2025-05-28T10:13:51.279599Z",
     "iopub.status.idle": "2025-05-28T10:13:51.290348Z",
     "shell.execute_reply": "2025-05-28T10:13:51.289327Z",
     "shell.execute_reply.started": "2025-05-28T10:13:51.280357Z"
    }
   },
   "outputs": [],
   "source": [
    "class BidirectionalGRU(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim=32):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "\n",
    "        self.gru1 = nn.GRU(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=128,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "\n",
    "        self.gru2 = nn.GRU(\n",
    "            input_size=128 * 2,  # Because bidirectional doubles output size\n",
    "            hidden_size=64,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Linear(64 * 2, 32)  # 64*2 because second GRU is bidirectional\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.fc2 = nn.Linear(32, 1)  # Binary classification output (logit)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [batch_size, seq_len]\n",
    "        x = self.embedding(x)              # [batch_size, seq_len, embed_dim]\n",
    "\n",
    "        out1, _ = self.gru1(x)             # [batch_size, seq_len, 256]\n",
    "        out2, _ = self.gru2(out1)          # [batch_size, seq_len, 128]\n",
    "\n",
    "        out2_last = out2[:, -1, :]         # Use the last timestep's features\n",
    "        x = self.relu(self.fc1(out2_last)) # [batch_size, 32]\n",
    "        output = self.fc2(x)               # [batch_size, 1]\n",
    "\n",
    "        return output  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e59a0c50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T02:53:03.193618Z",
     "iopub.status.busy": "2025-05-27T02:53:03.193324Z",
     "iopub.status.idle": "2025-05-27T02:53:03.210469Z",
     "shell.execute_reply": "2025-05-27T02:53:03.209294Z",
     "shell.execute_reply.started": "2025-05-27T02:53:03.193589Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BidirectionalGRU(\n",
       "  (embedding): Embedding(108, 32, padding_idx=0)\n",
       "  (gru1): GRU(32, 128, batch_first=True, bidirectional=True)\n",
       "  (gru2): GRU(256, 64, batch_first=True, bidirectional=True)\n",
       "  (fc1): Linear(in_features=128, out_features=32, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4 = BidirectionalGRU(vocab_size=VOCAB_SIZE, embedding_dim=EMBEDDING_DIM).to(device)\n",
    "model_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e2fdd823-10bb-4dd2-9ec3-f4e080bba29c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T02:53:03.212241Z",
     "iopub.status.busy": "2025-05-27T02:53:03.211929Z",
     "iopub.status.idle": "2025-05-27T02:53:03.220911Z",
     "shell.execute_reply": "2025-05-27T02:53:03.219399Z",
     "shell.execute_reply.started": "2025-05-27T02:53:03.212209Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Checking correct device ---\n",
    "next(model_4.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "6b5d7ca3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T02:53:03.222668Z",
     "iopub.status.busy": "2025-05-27T02:53:03.222332Z",
     "iopub.status.idle": "2025-05-27T02:53:03.236142Z",
     "shell.execute_reply": "2025-05-27T02:53:03.234084Z",
     "shell.execute_reply.started": "2025-05-27T02:53:03.222637Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Asymmetric Focal Loss for Binary Classification ---\n",
    "\n",
    "# Due to the class imbalance in our dataset (~24% tautologies), the model may bias toward \n",
    "# predicting the majority class (non-tautologies). This leads to high accuracy but poor recall \n",
    "# on the minority class, which is undesirable in many reasoning or safety-critical settings.\n",
    "\n",
    "# To address this, we use an Asymmetric Focal Loss, a refined version of the standard focal loss.\n",
    "# The core idea is to:\n",
    "# - Assign higher weight (α) to the minority class (tautologies) to penalize false negatives more.\n",
    "# - Apply a modulating factor (1 - p)^γ to focus learning on hard examples.\n",
    "# - Use separate α and γ values for each class for better control.\n",
    "\n",
    "# Loss formula:\n",
    "# L(y, ŷ) = \n",
    "#   - α_pos * y * (1 - ŷ)^γ_pos * log(ŷ)\n",
    "#   - α_neg * (1 - y)^γ_neg * log(1 - ŷ)\n",
    "# where:\n",
    "#   - y is the true label (0 or 1)\n",
    "#   - ŷ is the predicted probability (after sigmoid)\n",
    "#   - α_pos/neg control class weighting\n",
    "#   - γ_pos/neg control the focus on hard examples\n",
    "\n",
    "\n",
    "class AsymmetricFocalLoss(nn.Module):\n",
    "    def __init__(self, alpha_pos=1.0, alpha_neg=1.0, gamma_pos=2.0, gamma_neg=2.0, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.alpha_pos = alpha_pos\n",
    "        self.alpha_neg = alpha_neg\n",
    "        self.gamma_pos = gamma_pos\n",
    "        self.gamma_neg = gamma_neg\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        probs = torch.sigmoid(logits)\n",
    "        probs = torch.clamp(probs, 1e-6, 1 - 1e-6)  # Avoid log(0)\n",
    "\n",
    "        # Loss for positive (tautology)\n",
    "        pos_loss = self.alpha_pos * (1 - probs) ** self.gamma_pos * torch.log(probs)\n",
    "        # Loss for negative (non-tautology)\n",
    "        neg_loss = self.alpha_neg * (probs) ** self.gamma_neg * torch.log(1 - probs)\n",
    "\n",
    "        # Full loss\n",
    "        loss = -targets * pos_loss - (1 - targets) * neg_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return loss.sum()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "24aa0ac1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T02:53:03.238418Z",
     "iopub.status.busy": "2025-05-27T02:53:03.238048Z",
     "iopub.status.idle": "2025-05-27T02:53:03.246255Z",
     "shell.execute_reply": "2025-05-27T02:53:03.244841Z",
     "shell.execute_reply.started": "2025-05-27T02:53:03.238377Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Loss and Optimizer Functions ---\n",
    "loss_fn = AsymmetricFocalLoss(\n",
    "    alpha_pos=0.3,  # minority (tautology)\n",
    "    alpha_neg=0.7,  # majority\n",
    "    gamma_pos=3.0,\n",
    "    gamma_neg=1.5\n",
    ")\n",
    "optimizer = torch.optim.Adam(params=model_4.parameters(), \n",
    "                            lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "46a2eb90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T02:53:03.248541Z",
     "iopub.status.busy": "2025-05-27T02:53:03.247923Z",
     "iopub.status.idle": "2025-05-27T02:53:03.267626Z",
     "shell.execute_reply": "2025-05-27T02:53:03.266160Z",
     "shell.execute_reply.started": "2025-05-27T02:53:03.248505Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "========================================================================================================================\n",
       "Layer (type (var_name))                  Input Shape          Output Shape         Param #              Trainable\n",
       "========================================================================================================================\n",
       "BidirectionalGRU (BidirectionalGRU)      [16, 4468]           [16, 1]              --                   True\n",
       "├─Embedding (embedding)                  [16, 4468]           [16, 4468, 32]       3,456                True\n",
       "├─GRU (gru1)                             [16, 4468, 32]       [16, 4468, 256]      124,416              True\n",
       "├─GRU (gru2)                             [16, 4468, 256]      [16, 4468, 128]      123,648              True\n",
       "├─Linear (fc1)                           [16, 128]            [16, 32]             4,128                True\n",
       "├─ReLU (relu)                            [16, 32]             [16, 32]             --                   --\n",
       "├─Linear (fc2)                           [16, 32]             [16, 1]              33                   True\n",
       "========================================================================================================================\n",
       "Total params: 255,681\n",
       "Trainable params: 255,681\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 17.73\n",
       "========================================================================================================================\n",
       "Input size (MB): 0.57\n",
       "Forward/backward pass size (MB): 237.92\n",
       "Params size (MB): 1.02\n",
       "Estimated Total Size (MB): 239.51\n",
       "========================================================================================================================"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a summary of Model_4\n",
    "summary(model_4, \n",
    "         input_size=train_features_batch.shape, # [batch_size, seq_len]\n",
    "         dtypes=[torch.long],\n",
    "         verbose=0,\n",
    "         col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "         col_width=20,\n",
    "         row_settings=[\"var_names\"],\n",
    "         device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "02511b5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T02:56:07.053178Z",
     "iopub.status.busy": "2025-05-27T02:56:07.052527Z",
     "iopub.status.idle": "2025-05-27T03:16:34.964165Z",
     "shell.execute_reply": "2025-05-27T03:16:34.962526Z",
     "shell.execute_reply.started": "2025-05-27T02:56:07.053102Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f01446ae659247d48541f70d7ec3e683",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 0.0689 | train_acc: 0.6562 | test_loss: 0.0609 | test_acc: 0.6538\n",
      "Epoch: 2 | train_loss: 0.0364 | train_acc: 0.8113 | test_loss: 0.0248 | test_acc: 0.9078\n",
      "Epoch: 3 | train_loss: 0.0249 | train_acc: 0.9049 | test_loss: 0.0233 | test_acc: 0.9078\n",
      "Epoch: 4 | train_loss: 0.0274 | train_acc: 0.8899 | test_loss: 0.0234 | test_acc: 0.8819\n",
      "Epoch: 5 | train_loss: 0.0244 | train_acc: 0.8959 | test_loss: 0.0214 | test_acc: 0.9087\n",
      "Epoch: 6 | train_loss: 0.0220 | train_acc: 0.9065 | test_loss: 0.0202 | test_acc: 0.9100\n",
      "Epoch: 7 | train_loss: 0.0212 | train_acc: 0.9075 | test_loss: 0.0207 | test_acc: 0.9116\n",
      "Epoch: 8 | train_loss: 0.0205 | train_acc: 0.9094 | test_loss: 0.0194 | test_acc: 0.9116\n",
      "Epoch: 9 | train_loss: 0.0202 | train_acc: 0.9088 | test_loss: 0.0189 | test_acc: 0.9128\n",
      "Epoch: 10 | train_loss: 0.0192 | train_acc: 0.9113 | test_loss: 0.0175 | test_acc: 0.9116\n",
      "Epoch: 11 | train_loss: 0.0182 | train_acc: 0.9110 | test_loss: 0.0167 | test_acc: 0.9141\n",
      "Epoch: 12 | train_loss: 0.0173 | train_acc: 0.9117 | test_loss: 0.0169 | test_acc: 0.9150\n",
      "Epoch: 13 | train_loss: 0.0168 | train_acc: 0.9120 | test_loss: 0.0159 | test_acc: 0.9156\n",
      "Epoch: 14 | train_loss: 0.0162 | train_acc: 0.9126 | test_loss: 0.0157 | test_acc: 0.9159\n",
      "Epoch: 15 | train_loss: 0.0159 | train_acc: 0.9138 | test_loss: 0.0152 | test_acc: 0.9153\n",
      "Epoch: 16 | train_loss: 0.0153 | train_acc: 0.9134 | test_loss: 0.0159 | test_acc: 0.9147\n",
      "Epoch: 17 | train_loss: 0.0153 | train_acc: 0.9133 | test_loss: 0.0154 | test_acc: 0.9169\n",
      "Epoch: 18 | train_loss: 0.0147 | train_acc: 0.9143 | test_loss: 0.0159 | test_acc: 0.9159\n",
      "Epoch: 19 | train_loss: 0.0145 | train_acc: 0.9160 | test_loss: 0.0163 | test_acc: 0.9116\n",
      "Epoch: 20 | train_loss: 0.0141 | train_acc: 0.9178 | test_loss: 0.0149 | test_acc: 0.9181\n"
     ]
    }
   ],
   "source": [
    "# --- Train and Test Model_4 ---\n",
    "set_seeds()\n",
    "results = train(model=model_4,\n",
    "                train_dataloader=train_dataloader,\n",
    "                test_dataloader=test_dataloader,\n",
    "                optimizer=optimizer,\n",
    "                loss_fn=loss_fn,\n",
    "                epochs=20,\n",
    "                device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "706fe6e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T03:16:34.967193Z",
     "iopub.status.busy": "2025-05-27T03:16:34.966812Z",
     "iopub.status.idle": "2025-05-27T03:16:34.982714Z",
     "shell.execute_reply": "2025-05-27T03:16:34.981247Z",
     "shell.execute_reply.started": "2025-05-27T03:16:34.967157Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saving model to: models/Bidirectional_GRU_trained_with_dimacs_formulas_1.pth\n"
     ]
    }
   ],
   "source": [
    "save_model(model=model_4,\n",
    "           target_dir=\"models\",\n",
    "           model_name=\"Bidirectional_GRU_trained_with_dimacs_formulas_1.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2077e028-bfd0-4ff1-bbdf-9761cea73910",
   "metadata": {},
   "source": [
    "---\n",
    "#### **2.10 Build Model 5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "293b4286-1d57-4fd8-910c-091b613528d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T03:16:34.984714Z",
     "iopub.status.busy": "2025-05-27T03:16:34.984375Z",
     "iopub.status.idle": "2025-05-27T03:16:34.996197Z",
     "shell.execute_reply": "2025-05-27T03:16:34.994938Z",
     "shell.execute_reply.started": "2025-05-27T03:16:34.984679Z"
    }
   },
   "outputs": [],
   "source": [
    "# Adding more hidden layers\n",
    "class BidirectionalGRU_V2(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim=32):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "\n",
    "        self.gru1 = nn.GRU(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=128,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "\n",
    "        self.gru2 = nn.GRU(\n",
    "            input_size=128 * 2,  # Because bidirectional doubles output size\n",
    "            hidden_size=128,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Linear(128 * 2, 64)  # 128*2 because second GRU is bidirectional\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.fc2 = nn.Linear(64, 1)  # Binary classification output (logit)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [batch_size, seq_len]\n",
    "        x = self.embedding(x)              # [batch_size, seq_len, embed_dim]\n",
    "\n",
    "        out1, _ = self.gru1(x)             # [batch_size, seq_len, 256]\n",
    "        out2, _ = self.gru2(out1)          # [batch_size, seq_len, 128]\n",
    "\n",
    "        out2_last = out2[:, -1, :]         # Use the last timestep's features\n",
    "        x = self.relu(self.fc1(out2_last)) # [batch_size, 32]\n",
    "        output = self.fc2(x)               # [batch_size, 1]\n",
    "\n",
    "        return output  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8b71661d-cf7e-4fd9-bd91-2a95cd573018",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T03:16:34.999357Z",
     "iopub.status.busy": "2025-05-27T03:16:34.999002Z",
     "iopub.status.idle": "2025-05-27T03:16:35.019796Z",
     "shell.execute_reply": "2025-05-27T03:16:35.018516Z",
     "shell.execute_reply.started": "2025-05-27T03:16:34.999324Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BidirectionalGRU_V2(\n",
       "  (embedding): Embedding(108, 32, padding_idx=0)\n",
       "  (gru1): GRU(32, 128, batch_first=True, bidirectional=True)\n",
       "  (gru2): GRU(256, 128, batch_first=True, bidirectional=True)\n",
       "  (fc1): Linear(in_features=256, out_features=64, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5 = BidirectionalGRU_V2(vocab_size=VOCAB_SIZE, embedding_dim=EMBEDDING_DIM).to(device)\n",
    "model_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ab9c2dce-d923-4351-a82b-9d4b46716854",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T03:16:35.021648Z",
     "iopub.status.busy": "2025-05-27T03:16:35.021305Z",
     "iopub.status.idle": "2025-05-27T03:16:35.029560Z",
     "shell.execute_reply": "2025-05-27T03:16:35.028108Z",
     "shell.execute_reply.started": "2025-05-27T03:16:35.021615Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Loss and Optimizer Functions ---\n",
    "loss_fn = AsymmetricFocalLoss(\n",
    "    alpha_pos=0.3,  # minority (tautology)\n",
    "    alpha_neg=0.7,  # majority\n",
    "    gamma_pos=3.0,\n",
    "    gamma_neg=1.5\n",
    ")\n",
    "optimizer = torch.optim.Adam(params=model_5.parameters(), \n",
    "                            lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ca886d2d-a0c5-4bcb-8a12-3c048ff91141",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T03:16:35.031863Z",
     "iopub.status.busy": "2025-05-27T03:16:35.031501Z",
     "iopub.status.idle": "2025-05-27T03:16:35.051245Z",
     "shell.execute_reply": "2025-05-27T03:16:35.049996Z",
     "shell.execute_reply.started": "2025-05-27T03:16:35.031831Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=============================================================================================================================\n",
       "Layer (type (var_name))                       Input Shape          Output Shape         Param #              Trainable\n",
       "=============================================================================================================================\n",
       "BidirectionalGRU_V2 (BidirectionalGRU_V2)     [16, 4468]           [16, 1]              --                   True\n",
       "├─Embedding (embedding)                       [16, 4468]           [16, 4468, 32]       3,456                True\n",
       "├─GRU (gru1)                                  [16, 4468, 32]       [16, 4468, 256]      124,416              True\n",
       "├─GRU (gru2)                                  [16, 4468, 256]      [16, 4468, 256]      296,448              True\n",
       "├─Linear (fc1)                                [16, 256]            [16, 64]             16,448               True\n",
       "├─ReLU (relu)                                 [16, 64]             [16, 64]             --                   --\n",
       "├─Linear (fc2)                                [16, 64]             [16, 1]              65                   True\n",
       "=============================================================================================================================\n",
       "Total params: 440,833\n",
       "Trainable params: 440,833\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 30.09\n",
       "=============================================================================================================================\n",
       "Input size (MB): 0.57\n",
       "Forward/backward pass size (MB): 311.12\n",
       "Params size (MB): 1.76\n",
       "Estimated Total Size (MB): 313.46\n",
       "============================================================================================================================="
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a summary of Model_5\n",
    "summary(model_5, \n",
    "         input_size=train_features_batch.shape, # [batch_size, seq_len]\n",
    "         dtypes=[torch.long],\n",
    "         verbose=0,\n",
    "         col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "         col_width=20,\n",
    "         row_settings=[\"var_names\"],\n",
    "         device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "33858d5d-5a9d-410b-88b5-78169b5b5620",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T03:16:35.053227Z",
     "iopub.status.busy": "2025-05-27T03:16:35.052911Z",
     "iopub.status.idle": "2025-05-27T03:42:30.097975Z",
     "shell.execute_reply": "2025-05-27T03:42:30.096650Z",
     "shell.execute_reply.started": "2025-05-27T03:16:35.053195Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f602f73fa8804a889b279646d561acb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 0.0701 | train_acc: 0.6606 | test_loss: 0.0692 | test_acc: 0.6538\n",
      "Epoch: 2 | train_loss: 0.0690 | train_acc: 0.6629 | test_loss: 0.0692 | test_acc: 0.6534\n",
      "Epoch: 3 | train_loss: 0.0689 | train_acc: 0.6629 | test_loss: 0.0696 | test_acc: 0.6534\n",
      "Epoch: 4 | train_loss: 0.0689 | train_acc: 0.6629 | test_loss: 0.0697 | test_acc: 0.6534\n",
      "Epoch: 5 | train_loss: 0.0688 | train_acc: 0.6629 | test_loss: 0.0694 | test_acc: 0.6534\n",
      "Epoch: 6 | train_loss: 0.0681 | train_acc: 0.6628 | test_loss: 0.0680 | test_acc: 0.6534\n",
      "Epoch: 7 | train_loss: 0.0400 | train_acc: 0.8049 | test_loss: 0.0229 | test_acc: 0.9094\n",
      "Epoch: 8 | train_loss: 0.0231 | train_acc: 0.9054 | test_loss: 0.0215 | test_acc: 0.9053\n",
      "Epoch: 9 | train_loss: 0.0219 | train_acc: 0.9061 | test_loss: 0.0210 | test_acc: 0.9087\n",
      "Epoch: 10 | train_loss: 0.0201 | train_acc: 0.9085 | test_loss: 0.0193 | test_acc: 0.9056\n",
      "Epoch: 11 | train_loss: 0.0194 | train_acc: 0.9084 | test_loss: 0.0187 | test_acc: 0.9084\n",
      "Epoch: 12 | train_loss: 0.0185 | train_acc: 0.9104 | test_loss: 0.0175 | test_acc: 0.9134\n",
      "Epoch: 13 | train_loss: 0.0183 | train_acc: 0.9104 | test_loss: 0.0177 | test_acc: 0.9131\n",
      "Epoch: 14 | train_loss: 0.0178 | train_acc: 0.9110 | test_loss: 0.0178 | test_acc: 0.9147\n",
      "Epoch: 15 | train_loss: 0.0174 | train_acc: 0.9113 | test_loss: 0.0175 | test_acc: 0.9147\n",
      "Epoch: 16 | train_loss: 0.0171 | train_acc: 0.9119 | test_loss: 0.0178 | test_acc: 0.9128\n",
      "Epoch: 17 | train_loss: 0.0169 | train_acc: 0.9104 | test_loss: 0.0193 | test_acc: 0.8891\n",
      "Epoch: 18 | train_loss: 0.0169 | train_acc: 0.9107 | test_loss: 0.0170 | test_acc: 0.9137\n",
      "Epoch: 19 | train_loss: 0.0162 | train_acc: 0.9128 | test_loss: 0.0177 | test_acc: 0.9141\n",
      "Epoch: 20 | train_loss: 0.0160 | train_acc: 0.9123 | test_loss: 0.0168 | test_acc: 0.9150\n"
     ]
    }
   ],
   "source": [
    "# --- Train and Test Model_5 ---\n",
    "set_seeds()\n",
    "results = train(model=model_5,\n",
    "                train_dataloader=train_dataloader,\n",
    "                test_dataloader=test_dataloader,\n",
    "                optimizer=optimizer,\n",
    "                loss_fn=loss_fn,\n",
    "                epochs=20,\n",
    "                device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f7951057-935e-4533-bf1c-4a9ee3603694",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T03:42:30.100138Z",
     "iopub.status.busy": "2025-05-27T03:42:30.099794Z",
     "iopub.status.idle": "2025-05-27T03:42:30.116209Z",
     "shell.execute_reply": "2025-05-27T03:42:30.114641Z",
     "shell.execute_reply.started": "2025-05-27T03:42:30.100103Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saving model to: models/Bidirectional_GRU_trained_with_dimacs_formulas_2.pth\n"
     ]
    }
   ],
   "source": [
    "save_model(model=model_5,\n",
    "           target_dir=\"models\",\n",
    "           model_name=\"Bidirectional_GRU_trained_with_dimacs_formulas_2.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be69656c-5a6e-4939-9bdc-2fdf93435b92",
   "metadata": {},
   "source": [
    "**Possible reasons why the More Complex Model performs worst:**\n",
    "\n",
    "- *Potential Overfitting*:\n",
    "An increased number of hidden units results in higher model capacity, which in turn raises the risk of overfitting to the training data.\n",
    "Evidence of overfitting is observable in the decline of test accuracy during the final epochs (epochs 17–19).\n",
    "\n",
    "- *Insufficient or Insufficiently Complex Training Data*:\n",
    "The dataset employed (synthetic data combined with selected SATLIB instances) may not be sufficiently rich or complex to fully exploit the added capacity of the second model. In scenarios where the data is relatively simple or homogeneous, a less complex model could generalizes more effectively.\n",
    "\n",
    "- *Slow Initial Convergence*:\n",
    "The second model exhibits slow learning progress during the initial epochs (1–6).\n",
    "This behavior may suggest that the choice of activation function or optimization algorithm is not well suited to the increased model depth or capacity.\n",
    "\n",
    "- *Suboptimal GRU Configuration*:\n",
    "Employing a 128 to 128 GRU stack can lead to highly redundant output representations. In the absence of mechanisms designed to emphasize relevant components of the input, the model may struggle to maintain focus, resulting in reduced effectiveness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3119aa8b-1f62-4b24-9ef2-856f8a26dfaf",
   "metadata": {},
   "source": [
    "---\n",
    "#### **2.11 Best Model's prformance analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0a9a6d36-344a-47e3-8104-a0a820cec88c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T10:20:50.820295Z",
     "iopub.status.busy": "2025-05-28T10:20:50.819820Z",
     "iopub.status.idle": "2025-05-28T10:20:50.867569Z",
     "shell.execute_reply": "2025-05-28T10:20:50.865976Z",
     "shell.execute_reply.started": "2025-05-28T10:20:50.820259Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model:\n",
      "BidirectionalGRU(\n",
      "  (embedding): Embedding(108, 32, padding_idx=0)\n",
      "  (gru1): GRU(32, 128, batch_first=True, bidirectional=True)\n",
      "  (gru2): GRU(256, 64, batch_first=True, bidirectional=True)\n",
      "  (fc1): Linear(in_features=128, out_features=32, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n",
      "Model on device:\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# --- Loading Model 4 ---\n",
    "# Instantiate a fresh instance of BidirectionalGRU()\n",
    "model = BidirectionalGRU(vocab_size=VOCAB_SIZE, embedding_dim=EMBEDDING_DIM)\n",
    "\n",
    "# Load model state dict \n",
    "MODEL_SAVE_PATH = 'models/Bidirectional_GRU_trained_with_dimacs_formulas_1.pth'\n",
    "model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
    "\n",
    "# Put model to target device (if your data is on GPU, model will have to be on GPU to make predictions)\n",
    "model.to(device)\n",
    "\n",
    "print(f\"Loaded model:\\n{model}\")\n",
    "print(f\"Model on device:\\n{next(model.parameters()).device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "58c2fe11-821a-4add-b31a-c00602b95cb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T11:15:21.909109Z",
     "iopub.status.busy": "2025-05-28T11:15:21.907479Z",
     "iopub.status.idle": "2025-05-28T11:15:21.918356Z",
     "shell.execute_reply": "2025-05-28T11:15:21.917132Z",
     "shell.execute_reply.started": "2025-05-28T11:15:21.909068Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Adding a column 'source' to combined dataset to distinguish between synthetic formulas and dimacs formulas ---\n",
    "dataset['source'] = 'synthetic'\n",
    "df_satlib['source'] = 'satlib'\n",
    "\n",
    "df_full = pd.concat([dataset, df_satlib], ignore_index=True)\n",
    "\n",
    "# --- Adding indices to dataset---\n",
    "df_full['index'] = df_full.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d9bd7e46-ca84-42ff-bab8-d61413d7bf74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T11:15:26.516190Z",
     "iopub.status.busy": "2025-05-28T11:15:26.515724Z",
     "iopub.status.idle": "2025-05-28T11:15:26.536141Z",
     "shell.execute_reply": "2025-05-28T11:15:26.534970Z",
     "shell.execute_reply.started": "2025-05-28T11:15:26.516156Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                formula  is_tautology  \\\n",
      "9791  (¬((¬A0 → ¬(A1 ∨ A2)) ∨ A3 ∨ A4 ∨ A0) → ¬((¬A0...          True   \n",
      "\n",
      "         source  index  \n",
      "9791  synthetic   9791  \n",
      "\n",
      "                                                 formula  is_tautology  \\\n",
      "14138  (¬A0 ∨ A1 ∨ A2) ∧ (A3 ∨ ¬A4 ∨ A0) ∧ (¬A2 ∨ A5 ...          True   \n",
      "\n",
      "       source  index  \n",
      "14138  satlib  14138  \n"
     ]
    }
   ],
   "source": [
    "print(f\"{df_full[df_full['source'] == 'synthetic'].sample(1)}\")\n",
    "print(f\"\\n{df_full[df_full['source'] == 'satlib'].sample(1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6cf0f8b7-1912-468b-9ce8-499ad2b9cec3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T11:19:42.989129Z",
     "iopub.status.busy": "2025-05-28T11:19:42.988237Z",
     "iopub.status.idle": "2025-05-28T11:19:43.003102Z",
     "shell.execute_reply": "2025-05-28T11:19:43.001454Z",
     "shell.execute_reply.started": "2025-05-28T11:19:42.989088Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Preparing Data ---\n",
    "# Functionalize pipeline\n",
    "def prepare_formula_dataset(dataset: pd.DataFrame,\n",
    "                             test_size: float,\n",
    "                             batch_size: int,\n",
    "                             seed: int = 42\n",
    "                            ) -> Tuple[DataLoader, DataLoader, CustomTokenizer, List[Formula], List[Formula]]:\n",
    "    \"\"\"\n",
    "    General pipeline to parse, tokenize, and convert a dataset of formulas\n",
    "    into PyTorch dataloaders for training/testing.\n",
    "\n",
    "    Args:\n",
    "        dataset (pd.DataFrame): DataFrame with columns 'formula' and 'is_tautology'.\n",
    "        test_size (float): Proportion for test split.\n",
    "        batch_size (int): Batch size for DataLoaders.\n",
    "        seed (int): Random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        Tuple containing:\n",
    "            - train_dataloader\n",
    "            - test_dataloader\n",
    "            - tokenizer (CustomTokenizer)\n",
    "            - X_train (parsed formulas)\n",
    "            - X_test (parsed formulas)\n",
    "    \"\"\"\n",
    "    # Parse formulas\n",
    "    parsed_formulas = [parse_formula_string(f) for f in dataset['formula']]\n",
    "    truth_values = dataset['is_tautology'].tolist()\n",
    "\n",
    "    if 'original_index' in dataset.columns:\n",
    "        original_indices = dataset['original_index'].tolist()\n",
    "    else:\n",
    "        original_indices = list(range(len(dataset)))\n",
    "\n",
    "    # Train/test split\n",
    "    X_train, X_test, y_train, y_test, idx_train, idx_test = train_test_split(\n",
    "        parsed_formulas, truth_values, original_indices,\n",
    "        test_size=test_size,\n",
    "        random_state=seed\n",
    "    )\n",
    "\n",
    "    # Tokenizer\n",
    "    tokenizer = CustomTokenizer()\n",
    "    tokenizer.fit(X_train)\n",
    "\n",
    "    X_train_seq = [tokenizer.tokenize(f) for f in X_train]\n",
    "    X_test_seq = [tokenizer.tokenize(f) for f in X_test]\n",
    "\n",
    "    X_train_tensors = [torch.tensor(seq, dtype=torch.long) for seq in X_train_seq]\n",
    "    X_test_tensors = [torch.tensor(seq, dtype=torch.long) for seq in X_test_seq]\n",
    "\n",
    "    X_train_padded = pad_sequence(X_train_tensors, batch_first=True, padding_value=0)\n",
    "    X_test_padded = pad_sequence(X_test_tensors, batch_first=True, padding_value=0)\n",
    "\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "    y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "    train_data = FormulaDataset(X_train_padded, y_train_tensor)\n",
    "    test_data = FormulaDataset(X_test_padded, y_test_tensor)\n",
    "\n",
    "    train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_dataloader, test_dataloader, X_train, X_test, y_train, y_test, idx_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c86166f8-7bce-4597-9523-a64b4ad15f6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T11:22:00.151762Z",
     "iopub.status.busy": "2025-05-28T11:22:00.150991Z",
     "iopub.status.idle": "2025-05-28T11:24:09.600408Z",
     "shell.execute_reply": "2025-05-28T11:24:09.599128Z",
     "shell.execute_reply.started": "2025-05-28T11:22:00.151724Z"
    }
   },
   "outputs": [],
   "source": [
    "exp_train_dataloader, exp_test_dataloader, exp_X_train, exp_X_test, exp_y_train, exp_y_test, exp_idx_test = prepare_formula_dataset(\n",
    "    dataset = df_full,\n",
    "    test_size = 0.2,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    seed = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "281f2a38-ef6d-4cf9-bdbc-eba846dfa317",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T11:24:19.912993Z",
     "iopub.status.busy": "2025-05-28T11:24:19.912163Z",
     "iopub.status.idle": "2025-05-28T11:24:19.920024Z",
     "shell.execute_reply": "2025-05-28T11:24:19.918832Z",
     "shell.execute_reply.started": "2025-05-28T11:24:19.912958Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloaders: (<torch.utils.data.dataloader.DataLoader object at 0x7f5fb60c1090>, <torch.utils.data.dataloader.DataLoader object at 0x7f5fb60c1030>)\n",
      "Length of train dataloader: 800 batches of 16\n",
      "Length of test dataloader: 200 batches of 16\n"
     ]
    }
   ],
   "source": [
    "# Let's check out what we've created\n",
    "print(f\"Dataloaders: {exp_train_dataloader, exp_test_dataloader}\") \n",
    "print(f\"Length of train dataloader: {len(exp_train_dataloader)} batches of {BATCH_SIZE}\")\n",
    "print(f\"Length of test dataloader: {len(exp_test_dataloader)} batches of {BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "136c97b2-a9d1-44ad-9f2e-eec32f96ec94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T11:24:23.239298Z",
     "iopub.status.busy": "2025-05-28T11:24:23.238074Z",
     "iopub.status.idle": "2025-05-28T11:24:23.247230Z",
     "shell.execute_reply": "2025-05-28T11:24:23.246051Z",
     "shell.execute_reply.started": "2025-05-28T11:24:23.239261Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset FormulaDataset\n",
       "   Number of datapoints: 12800\n",
       "   Input shape: torch.Size([4468])\n",
       "   Target type: torch.float32,\n",
       " Dataset FormulaDataset\n",
       "   Number of datapoints: 3200\n",
       "   Input shape: torch.Size([4433])\n",
       "   Target type: torch.float32)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d9636204-0121-452c-9d45-3ed3cc039a25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T11:27:48.384824Z",
     "iopub.status.busy": "2025-05-28T11:27:48.384338Z",
     "iopub.status.idle": "2025-05-28T11:27:53.232916Z",
     "shell.execute_reply": "2025-05-28T11:27:53.231627Z",
     "shell.execute_reply.started": "2025-05-28T11:27:48.384786Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Model's predictions on Test set tracking indices ---\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "all_sources = []\n",
    "\n",
    "with torch.inference_mode():\n",
    "    for i, (x_batch, y_batch) in enumerate(exp_test_dataloader):\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        logits = model(x_batch)\n",
    "        probs = torch.sigmoid(logits).squeeze()\n",
    "        preds = (probs > 0.5).float()\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_targets.extend(y_batch.cpu().numpy())\n",
    "\n",
    "# Taking original 'sources' using idx_test\n",
    "source_series = df_full.loc[exp_idx_test, 'source']\n",
    "all_sources = source_series.tolist()\n",
    "\n",
    "# Create a DataFrame\n",
    "eval_df = pd.DataFrame({\n",
    "    'source': all_sources,\n",
    "    'y_true': all_targets,\n",
    "    'y_pred': all_preds\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e6998733-b3b6-4512-8edc-ca2ca0042753",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T11:32:32.782650Z",
     "iopub.status.busy": "2025-05-28T11:32:32.782141Z",
     "iopub.status.idle": "2025-05-28T11:32:32.798668Z",
     "shell.execute_reply": "2025-05-28T11:32:32.797288Z",
     "shell.execute_reply.started": "2025-05-28T11:32:32.782616Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         source  y_true  y_pred\n",
      "1002  synthetic     1.0     1.0\n",
      "      source  y_true  y_pred\n",
      "2378  satlib     1.0     0.0\n"
     ]
    }
   ],
   "source": [
    "sampled_pred_synt = eval_df[eval_df['source'] == 'synthetic'].sample(n=1, random_state=42)\n",
    "sampled_pred_sat = eval_df[eval_df['source'] == 'satlib'].sample(n=1, random_state=41)\n",
    "print(sampled_pred_synt)\n",
    "print(sampled_pred_sat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a8d0d019-7698-443c-9dd9-c97bd00ba8c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T11:37:07.813717Z",
     "iopub.status.busy": "2025-05-28T11:37:07.813244Z",
     "iopub.status.idle": "2025-05-28T11:37:07.830044Z",
     "shell.execute_reply": "2025-05-28T11:37:07.828523Z",
     "shell.execute_reply.started": "2025-05-28T11:37:07.813682Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy per source: \n",
      "source\n",
      "satlib       0.677064\n",
      "synthetic    0.970998\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# --- Analyzing Accuracy per source --- \n",
    "accuracy_per_source = eval_df.groupby('source')[['y_true', 'y_pred']].apply(\n",
    "    lambda x: (x['y_true'] == x['y_pred']).mean()\n",
    ")\n",
    "print(f\"Accuracy per source: \\n{accuracy_per_source}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfba050-62ba-42c7-9833-d419e5abc90a",
   "metadata": {},
   "source": [
    "From the previous results we can observe that the model is significantly more accurate on synthetic formulas (97%) compared to those from SATLIB (67%). This suggests a generalization gap when dealing with structurally different formulas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1ac53198-9b4f-43e6-b14c-dbed1864fbeb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T11:40:38.351781Z",
     "iopub.status.busy": "2025-05-28T11:40:38.350540Z",
     "iopub.status.idle": "2025-05-28T11:40:38.361189Z",
     "shell.execute_reply": "2025-05-28T11:40:38.359781Z",
     "shell.execute_reply.started": "2025-05-28T11:40:38.351726Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of false positives: 3\n",
      "Number of false negatives: 250\n"
     ]
    }
   ],
   "source": [
    "# --- False negatives and False positives analysis ---\n",
    "false_positives = eval_df[(eval_df['y_pred'] == 1.0) & (eval_df['y_true'] == 0.0)]\n",
    "false_negatives = eval_df[(eval_df['y_pred'] == 0.0) & (eval_df['y_true'] == 1.0)]\n",
    "\n",
    "print(f\"Number of false positives: {len(false_positives)}\")\n",
    "print(f\"Number of false negatives: {len(false_negatives)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68a11ae-86bd-45e1-bfbc-dcbff805d62b",
   "metadata": {},
   "source": [
    "These results indicate a highly conservative model that prefers to classify a formula as a non-tautology rather than risk a false positive:\n",
    "The model struggles to correctly identify many tautologies, likely due to one or more of the following reasons:\n",
    "\n",
    "- The representation of tautologies is less frequent in the data (~ 34% of tautologies in the dataset).\n",
    "- The model has learned a bias toward the majority class (non-tautologies).\n",
    "- The tautologies in SATLIB (synthetic or DIMACS) differ significantly from synthetic ones, which are the majority."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd30ab5-868e-47b7-8f2d-b3e58b69fbcf",
   "metadata": {},
   "source": [
    "#### **2.12 Build Model 6**\n",
    "Since Model 4 performed bettera than Model 5, we try to improve its performances addind a Multihead Attention Layer and Positional Encoding to try to focus on the more relevant parts of input formulas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "715ba7aa-c712-4d22-9675-6bc18a65b4e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T13:43:41.868317Z",
     "iopub.status.busy": "2025-05-28T13:43:41.866674Z",
     "iopub.status.idle": "2025-05-28T13:43:41.881166Z",
     "shell.execute_reply": "2025-05-28T13:43:41.880087Z",
     "shell.execute_reply.started": "2025-05-28T13:43:41.868277Z"
    }
   },
   "outputs": [],
   "source": [
    "import math \n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(1)  # [max_len, 1, d_model]\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return x\n",
    "\n",
    "class BidirectionalGRU_Multi_Att(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_heads): \n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=128,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "\n",
    "        self.pos_encoder = PositionalEncoding(d_model=128 * 2)\n",
    "\n",
    "        self.attn = nn.MultiheadAttention(embed_dim=128 * 2, num_heads=n_heads, batch_first=False)\n",
    "\n",
    "        self.fc1 = nn.Linear(128 * 2, 32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)              # [batch_size, seq_len, embedding_dim]\n",
    "        gru_out, _ = self.gru(x)           # [batch_size, seq_len, hidden_dim*2]\n",
    "        gru_out = gru_out.transpose(0, 1)  # [seq_len, batch_size, hidden_dim*2]\n",
    "\n",
    "        # Add positional encoding\n",
    "        gru_out = self.pos_encoder(gru_out)\n",
    "\n",
    "        # Self-attention\n",
    "        attn_output, _ = self.attn(gru_out, gru_out, gru_out)\n",
    "        attn_output = attn_output.mean(dim=0)  # [batch_size, hidden_dim*2]\n",
    "        attn_output[0]\n",
    "\n",
    "        x = self.relu(self.fc1(attn_output))\n",
    "        output = self.fc2(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1d28be81-fffa-422b-b770-a9b9ca9958ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T13:43:42.830992Z",
     "iopub.status.busy": "2025-05-28T13:43:42.830298Z",
     "iopub.status.idle": "2025-05-28T13:43:43.137223Z",
     "shell.execute_reply": "2025-05-28T13:43:43.136007Z",
     "shell.execute_reply.started": "2025-05-28T13:43:42.830943Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BidirectionalGRU_Multi_Att(\n",
       "  (embedding): Embedding(108, 32, padding_idx=0)\n",
       "  (gru): GRU(32, 128, batch_first=True, bidirectional=True)\n",
       "  (pos_encoder): PositionalEncoding()\n",
       "  (attn): MultiheadAttention(\n",
       "    (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "  )\n",
       "  (fc1): Linear(in_features=256, out_features=32, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_6 = BidirectionalGRU_Multi_Att(vocab_size=VOCAB_SIZE, \n",
    "                                     embedding_dim=EMBEDDING_DIM, \n",
    "                                     n_heads=4  \n",
    "                                    ).to(device)\n",
    "\n",
    "model_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9a9458cd-3fe2-473d-a181-08a914f1bc46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T13:43:51.374884Z",
     "iopub.status.busy": "2025-05-28T13:43:51.373646Z",
     "iopub.status.idle": "2025-05-28T13:43:51.385951Z",
     "shell.execute_reply": "2025-05-28T13:43:51.384705Z",
     "shell.execute_reply.started": "2025-05-28T13:43:51.374847Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Asymmetric Focal Loss for Binary Classification ---\n",
    "\n",
    "# Due to the class imbalance in our dataset (~24% tautologies), the model may bias toward \n",
    "# predicting the majority class (non-tautologies). This leads to high accuracy but poor recall \n",
    "# on the minority class, which is undesirable in many reasoning or safety-critical settings.\n",
    "\n",
    "# To address this, we use an Asymmetric Focal Loss, a refined version of the standard focal loss.\n",
    "# The core idea is to:\n",
    "# - Assign higher weight (α) to the minority class (tautologies) to penalize false negatives more.\n",
    "# - Apply a modulating factor (1 - p)^γ to focus learning on hard examples.\n",
    "# - Use separate α and γ values for each class for better control.\n",
    "\n",
    "# Loss formula:\n",
    "# L(y, ŷ) = \n",
    "#   - α_pos * y * (1 - ŷ)^γ_pos * log(ŷ)\n",
    "#   - α_neg * (1 - y)^γ_neg * log(1 - ŷ)\n",
    "# where:\n",
    "#   - y is the true label (0 or 1)\n",
    "#   - ŷ is the predicted probability (after sigmoid)\n",
    "#   - α_pos/neg control class weighting\n",
    "#   - γ_pos/neg control the focus on hard examples\n",
    "\n",
    "\n",
    "class AsymmetricFocalLoss(nn.Module):\n",
    "    def __init__(self, alpha_pos=1.0, alpha_neg=1.0, gamma_pos=2.0, gamma_neg=2.0, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.alpha_pos = alpha_pos\n",
    "        self.alpha_neg = alpha_neg\n",
    "        self.gamma_pos = gamma_pos\n",
    "        self.gamma_neg = gamma_neg\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        probs = torch.sigmoid(logits)\n",
    "        probs = torch.clamp(probs, 1e-6, 1 - 1e-6)  # Avoid log(0)\n",
    "\n",
    "        # Loss for positive (tautology)\n",
    "        pos_loss = self.alpha_pos * (1 - probs) ** self.gamma_pos * torch.log(probs)\n",
    "        # Loss for negative (non-tautology)\n",
    "        neg_loss = self.alpha_neg * (probs) ** self.gamma_neg * torch.log(1 - probs)\n",
    "\n",
    "        # Full loss\n",
    "        loss = -targets * pos_loss - (1 - targets) * neg_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return loss.sum()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d0686ee7-cf3f-4307-8880-07bbe5680f63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T13:43:53.738012Z",
     "iopub.status.busy": "2025-05-28T13:43:53.737540Z",
     "iopub.status.idle": "2025-05-28T13:43:53.745420Z",
     "shell.execute_reply": "2025-05-28T13:43:53.744230Z",
     "shell.execute_reply.started": "2025-05-28T13:43:53.737979Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Loss and Optimizer Functions ---\n",
    "loss_fn = AsymmetricFocalLoss(\n",
    "    alpha_pos=0.3,  # minority (tautology)\n",
    "    alpha_neg=0.7,  # majority\n",
    "    gamma_pos=3.0,\n",
    "    gamma_neg=1.5\n",
    ")\n",
    "optimizer = torch.optim.Adam(params=model_6.parameters(), \n",
    "                            lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c2f0c10b-550c-4ccc-a5f0-2ca6b0fc2ddb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T13:43:59.311162Z",
     "iopub.status.busy": "2025-05-28T13:43:59.309864Z",
     "iopub.status.idle": "2025-05-28T13:43:59.746151Z",
     "shell.execute_reply": "2025-05-28T13:43:59.744976Z",
     "shell.execute_reply.started": "2025-05-28T13:43:59.311108Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "============================================================================================================================================\n",
       "Layer (type (var_name))                                      Input Shape          Output Shape         Param #              Trainable\n",
       "============================================================================================================================================\n",
       "BidirectionalGRU_Multi_Att (BidirectionalGRU_Multi_Att)      [16, 4468]           [16, 1]              --                   True\n",
       "├─Embedding (embedding)                                      [16, 4468]           [16, 4468, 32]       3,456                True\n",
       "├─GRU (gru)                                                  [16, 4468, 32]       [16, 4468, 256]      124,416              True\n",
       "├─PositionalEncoding (pos_encoder)                           [4468, 16, 256]      [4468, 16, 256]      --                   --\n",
       "├─MultiheadAttention (attn)                                  [4468, 16, 256]      [4468, 16, 256]      263,168              True\n",
       "├─Linear (fc1)                                               [16, 256]            [16, 32]             8,224                True\n",
       "├─ReLU (relu)                                                [16, 32]             [16, 32]             --                   --\n",
       "├─Linear (fc2)                                               [16, 32]             [16, 1]              33                   True\n",
       "============================================================================================================================================\n",
       "Total params: 399,297\n",
       "Trainable params: 399,297\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 8.89\n",
       "============================================================================================================================================\n",
       "Input size (MB): 0.57\n",
       "Forward/backward pass size (MB): 164.71\n",
       "Params size (MB): 0.54\n",
       "Estimated Total Size (MB): 165.83\n",
       "============================================================================================================================================"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model_6, \n",
    "         input_size=train_features_batch.shape, # [batch_size, seq_len]\n",
    "         dtypes=[torch.long],\n",
    "         verbose=0,\n",
    "         col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "         col_width=20,\n",
    "         row_settings=[\"var_names\"],\n",
    "         device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2e0b7cec-7fe9-4709-8e0e-d27714259a2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T13:44:09.725849Z",
     "iopub.status.busy": "2025-05-28T13:44:09.724396Z",
     "iopub.status.idle": "2025-05-28T13:44:09.734092Z",
     "shell.execute_reply": "2025-05-28T13:44:09.732782Z",
     "shell.execute_reply.started": "2025-05-28T13:44:09.725810Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloaders: (<torch.utils.data.dataloader.DataLoader object at 0x7fed58b55750>, <torch.utils.data.dataloader.DataLoader object at 0x7fed58b54910>)\n",
      "Length of train dataloader: 3200 batches of 4\n",
      "Length of test dataloader: 800 batches of 4\n"
     ]
    }
   ],
   "source": [
    "# --- Modified BATCH_SIZE parameter to avoid OutOfMemoryError ---\n",
    "\n",
    "# Setup the batch size hyperparameter\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "# Turn datasets into iterables (batches)\n",
    "train_dataloader = DataLoader(train_data, # dataset to turn into iterable\n",
    "                              batch_size=BATCH_SIZE, # how many samples per batch? \n",
    "                              shuffle=True # shuffle data every epoch?\n",
    "                                           # This removes the data order, so the model does not learn it \n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(test_data,\n",
    "                             batch_size=BATCH_SIZE,\n",
    "                             shuffle=False # don't necessarily have to shuffle the testing data\n",
    ")\n",
    "\n",
    "# Let's check out what we've created\n",
    "print(f\"Dataloaders: {train_dataloader, test_dataloader}\") \n",
    "print(f\"Length of train dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}\")\n",
    "print(f\"Length of test dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4431f23b-96b3-48d6-9616-b3c35d366d96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T13:44:12.335216Z",
     "iopub.status.busy": "2025-05-28T13:44:12.334726Z",
     "iopub.status.idle": "2025-05-28T16:00:41.224633Z",
     "shell.execute_reply": "2025-05-28T16:00:41.219155Z",
     "shell.execute_reply.started": "2025-05-28T13:44:12.335181Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a547a458cf6247a7a67c3680958da036",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 0.0310 | train_acc: 0.8752 | test_loss: 0.0366 | test_acc: 0.8906\n",
      "Epoch: 2 | train_loss: 0.0255 | train_acc: 0.8862 | test_loss: 0.0241 | test_acc: 0.8909\n",
      "Epoch: 3 | train_loss: 0.0232 | train_acc: 0.8918 | test_loss: 0.0218 | test_acc: 0.8988\n",
      "Epoch: 4 | train_loss: 0.0207 | train_acc: 0.8967 | test_loss: 0.0192 | test_acc: 0.9075\n",
      "Epoch: 5 | train_loss: 0.0189 | train_acc: 0.9035 | test_loss: 0.0229 | test_acc: 0.8869\n",
      "Epoch: 6 | train_loss: 0.0183 | train_acc: 0.9047 | test_loss: 0.0194 | test_acc: 0.9069\n",
      "Epoch: 7 | train_loss: 0.0177 | train_acc: 0.9061 | test_loss: 0.0168 | test_acc: 0.9106\n",
      "Epoch: 8 | train_loss: 0.0167 | train_acc: 0.9079 | test_loss: 0.0168 | test_acc: 0.9094\n",
      "Epoch: 9 | train_loss: 0.0158 | train_acc: 0.9104 | test_loss: 0.0176 | test_acc: 0.9103\n",
      "Epoch: 10 | train_loss: 0.0155 | train_acc: 0.9093 | test_loss: 0.0161 | test_acc: 0.9178\n",
      "Epoch: 11 | train_loss: 0.0148 | train_acc: 0.9120 | test_loss: 0.0155 | test_acc: 0.9147\n",
      "Epoch: 12 | train_loss: 0.0143 | train_acc: 0.9156 | test_loss: 0.0174 | test_acc: 0.9175\n",
      "Epoch: 13 | train_loss: 0.0145 | train_acc: 0.9120 | test_loss: 0.0158 | test_acc: 0.9184\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# --- Train and Test Model_6 ---\u001b[39;00m\n\u001b[1;32m      2\u001b[0m set_seeds()\n\u001b[0;32m----> 3\u001b[0m results_model_6 \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_6\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                  \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[55], line 155\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_dataloader, test_dataloader, optimizer, loss_fn, epochs, device)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;66;03m# Loop through training and testing steps for a number of epochs\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(epochs)):\n\u001b[0;32m--> 155\u001b[0m     train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m     test_loss, test_acc \u001b[38;5;241m=\u001b[39m test_step(model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    161\u001b[0m         dataloader\u001b[38;5;241m=\u001b[39mtest_dataloader,\n\u001b[1;32m    162\u001b[0m         loss_fn\u001b[38;5;241m=\u001b[39mloss_fn,\n\u001b[1;32m    163\u001b[0m         device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# Print out what's happening\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[55], line 43\u001b[0m, in \u001b[0;36mtrain_step\u001b[0;34m(model, dataloader, loss_fn, optimizer, device)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# 2. Calculate  and accumulate loss\u001b[39;00m\n\u001b[1;32m     42\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(y_logits, y)\n\u001b[0;32m---> 43\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# 3. Optimizer zero grad\u001b[39;00m\n\u001b[1;32m     46\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# --- Train and Test Model_6 ---\n",
    "set_seeds()\n",
    "results_model_6 = train(model=model_6,\n",
    "                  train_dataloader=train_dataloader,\n",
    "                  test_dataloader=test_dataloader,\n",
    "                  optimizer=optimizer,\n",
    "                  loss_fn=loss_fn,\n",
    "                  epochs=20,\n",
    "                  device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "323ba9b5-87c3-47c9-a9ef-e744dc33f2e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T18:29:01.333661Z",
     "iopub.status.busy": "2025-05-29T18:29:01.332095Z",
     "iopub.status.idle": "2025-05-29T18:29:01.339306Z",
     "shell.execute_reply": "2025-05-29T18:29:01.338072Z",
     "shell.execute_reply.started": "2025-05-29T18:29:01.333615Z"
    }
   },
   "outputs": [],
   "source": [
    "truth_values = dataset['is_tautology'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "23961f63-25cf-4670-80a6-225c23970fc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T18:29:03.202063Z",
     "iopub.status.busy": "2025-05-29T18:29:03.200766Z",
     "iopub.status.idle": "2025-05-29T18:29:03.228138Z",
     "shell.execute_reply": "2025-05-29T18:29:03.226537Z",
     "shell.execute_reply.started": "2025-05-29T18:29:03.202022Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Tree Node representation for Tree-LSTM ---\n",
    "from typing import Optional, List, Tuple\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class TreeNode:\n",
    "    def __init__(self, label: int, left: Optional['TreeNode'] = None, right: Optional['TreeNode'] = None):\n",
    "        self.label = label\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "\n",
    "# --- Convert logical Formula into TreeNode structure ---\n",
    "def formula_to_tree(formula, tokenizer) -> TreeNode:\n",
    "    if isinstance(formula, Letter):\n",
    "        return TreeNode(tokenizer.formula_to_token[formula])\n",
    "    elif isinstance(formula, Falsity):\n",
    "        return TreeNode(tokenizer.falsity_token)\n",
    "    elif isinstance(formula, UnaryConnectiveFormula):\n",
    "        child = formula_to_tree(formula.formula, tokenizer)\n",
    "        return TreeNode(tokenizer.connective_map[type(formula).__name__], left=child)\n",
    "    elif isinstance(formula, BinaryConnectiveFormula):\n",
    "        left = formula_to_tree(formula.left, tokenizer)\n",
    "        right = formula_to_tree(formula.right, tokenizer)\n",
    "        return TreeNode(tokenizer.connective_map[type(formula).__name__], left=left, right=right)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown formula type\")\n",
    "\n",
    "# --- Custom Dataset ---\n",
    "class TreeFormulaDataset(Dataset):\n",
    "    def __init__(self, formulas, labels, tokenizer):\n",
    "        self.trees = [formula_to_tree(f, tokenizer) for f in formulas]\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.trees)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.trees[idx], torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "\n",
    "# --- Binary Tree-LSTM Cell ---\n",
    "class BinaryTreeLSTMCell(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.in_dim = in_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.W_iou = nn.Linear(in_dim, 3 * hidden_dim)\n",
    "        self.U_iou = nn.Linear(2 * hidden_dim, 3 * hidden_dim)\n",
    "        self.W_f = nn.Linear(in_dim, 2 * hidden_dim)\n",
    "        self.U_f = nn.Linear(2 * hidden_dim, 2 * hidden_dim)\n",
    "\n",
    "    def forward(self, x, left, right):\n",
    "        h_l, c_l = left\n",
    "        h_r, c_r = right\n",
    "\n",
    "        h_cat = torch.cat([h_l, h_r], dim=-1)\n",
    "\n",
    "        iou = self.W_iou(x) + self.U_iou(h_cat)\n",
    "        i, o, u = torch.chunk(torch.sigmoid(iou), 3, dim=-1)\n",
    "\n",
    "        f = torch.sigmoid(self.W_f(x) + self.U_f(h_cat))\n",
    "        f_l, f_r = torch.chunk(f, 2, dim=-1)\n",
    "\n",
    "        c = i * torch.tanh(u) + f_l * c_l + f_r * c_r\n",
    "        h = o * torch.tanh(c)\n",
    "\n",
    "        return h, c\n",
    "\n",
    "# --- TreeLSTM Classifier ---\n",
    "class TreeLSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.tree_lstm_cell = BinaryTreeLSTMCell(embedding_dim, hidden_dim)\n",
    "        self.fc1 = nn.Linear(hidden_dim, 32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, tree: TreeNode):\n",
    "        def recurse(node: TreeNode):\n",
    "            x = self.embedding(torch.tensor(node.label).to(next(self.parameters()).device))\n",
    "            if node.left and node.right:\n",
    "                h_l, c_l = recurse(node.left)\n",
    "                h_r, c_r = recurse(node.right)\n",
    "                return self.tree_lstm_cell(x, (h_l, c_l), (h_r, c_r))\n",
    "            elif node.left:\n",
    "                h_l, c_l = recurse(node.left)\n",
    "                zero = torch.zeros_like(h_l)\n",
    "                return self.tree_lstm_cell(x, (h_l, c_l), (zero, zero))\n",
    "            else:\n",
    "                zero = torch.zeros((self.tree_lstm_cell.hidden_dim,), device=x.device)\n",
    "                return self.tree_lstm_cell(x, (zero, zero), (zero, zero))\n",
    "\n",
    "        h_root, _ = recurse(tree)\n",
    "        x = self.relu(self.fc1(h_root))\n",
    "        return self.fc2(x).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8cd97867-f7cb-4a44-9f75-69f787cf4809",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T18:29:03.882348Z",
     "iopub.status.busy": "2025-05-29T18:29:03.881083Z",
     "iopub.status.idle": "2025-05-29T18:29:03.906498Z",
     "shell.execute_reply": "2025-05-29T18:29:03.905284Z",
     "shell.execute_reply.started": "2025-05-29T18:29:03.882308Z"
    }
   },
   "outputs": [],
   "source": [
    "# Re-import necessary components due to state reset\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from typing import Optional, List\n",
    "\n",
    "# Define TreeNode class\n",
    "class TreeNode:\n",
    "    def __init__(self, label: int, left: Optional['TreeNode'] = None, right: Optional['TreeNode'] = None):\n",
    "        self.label = label\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "\n",
    "# Define TreeFormulaDataset\n",
    "class TreeFormulaDataset(Dataset):\n",
    "    def __init__(self, formulas, labels, tokenizer):\n",
    "        self.trees = [self.formula_to_tree(f, tokenizer) for f in formulas]\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.trees)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.trees[idx], torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "\n",
    "    def formula_to_tree(self, formula, tokenizer) -> TreeNode:\n",
    "        if isinstance(formula, str):\n",
    "            formula = eval(formula)  # Assumes string eval is safe here\n",
    "        if formula.__class__.__name__ == 'Letter':\n",
    "            return TreeNode(tokenizer.formula_to_token[formula])\n",
    "        elif formula.__class__.__name__ == 'Falsity':\n",
    "            return TreeNode(tokenizer.falsity_token)\n",
    "        elif 'UnaryConnectiveFormula' in [base.__name__ for base in formula.__class__.__bases__]:\n",
    "            child = self.formula_to_tree(formula.formula, tokenizer)\n",
    "            return TreeNode(tokenizer.connective_map[formula.__class__.__name__], left=child)\n",
    "        elif 'BinaryConnectiveFormula' in [base.__name__ for base in formula.__class__.__bases__]:\n",
    "            left = self.formula_to_tree(formula.left, tokenizer)\n",
    "            right = self.formula_to_tree(formula.right, tokenizer)\n",
    "            return TreeNode(tokenizer.connective_map[formula.__class__.__name__], left=left, right=right)\n",
    "        else:\n",
    "            raise ValueError(\"Unknown formula type\")\n",
    "\n",
    "# Prepare data loaders\n",
    "def prepare_tree_dataset(parsed_formulas, truth_values, tokenizer, test_size=0.2, batch_size=32, seed=42):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        parsed_formulas, truth_values, test_size=test_size, random_state=seed)\n",
    "\n",
    "    train_dataset = TreeFormulaDataset(X_train, y_train, tokenizer)\n",
    "    test_dataset = TreeFormulaDataset(X_test, y_test, tokenizer)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=lambda x: x)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=lambda x: x)\n",
    "\n",
    "    return train_loader, test_loader, X_train, X_test, y_train, y_test\n",
    "\n",
    "# Training function\n",
    "def train_tree_lstm(model, train_loader, test_loader, optimizer, loss_fn, epochs, device):\n",
    "    model.to(device)\n",
    "    results = {\"train_loss\": [], \"train_acc\": [], \"test_loss\": [], \"test_acc\": []}\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss, train_correct = 0, 0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            trees, labels = zip(*batch)\n",
    "            optimizer.zero_grad()\n",
    "            preds = torch.stack([model(tree) for tree in trees])\n",
    "            labels_tensor = torch.tensor(labels, dtype=torch.float32, device=device)\n",
    "            loss = loss_fn(preds, labels_tensor)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            train_correct += (torch.round(torch.sigmoid(preds)) == labels_tensor).sum().item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        train_acc = train_correct / len(train_loader.dataset)\n",
    "\n",
    "        model.eval()\n",
    "        test_loss, test_correct = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                trees, labels = zip(*batch)\n",
    "                preds = torch.stack([model(tree) for tree in trees])\n",
    "                labels_tensor = torch.tensor(labels, dtype=torch.float32, device=device)\n",
    "                loss = loss_fn(preds, labels_tensor)\n",
    "                test_loss += loss.item()\n",
    "                test_correct += (torch.round(torch.sigmoid(preds)) == labels_tensor).sum().item()\n",
    "\n",
    "        test_loss /= len(test_loader)\n",
    "        test_acc = test_correct / len(test_loader.dataset)\n",
    "\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        results[\"test_loss\"].append(test_loss)\n",
    "        results[\"test_acc\"].append(test_acc)\n",
    "\n",
    "        print(f\"Epoch {epoch+1} | Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, \"\n",
    "              f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}\")\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2941bb19-0b05-4468-a9fc-a0f6a669ddbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T18:29:04.537348Z",
     "iopub.status.busy": "2025-05-29T18:29:04.536851Z",
     "iopub.status.idle": "2025-05-29T18:29:06.880515Z",
     "shell.execute_reply": "2025-05-29T18:29:06.879287Z",
     "shell.execute_reply.started": "2025-05-29T18:29:04.537315Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1500: indexSelectSmallIndex: block: [0,0,0], thread: [0,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1500: indexSelectSmallIndex: block: [0,0,0], thread: [1,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1500: indexSelectSmallIndex: block: [0,0,0], thread: [2,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1500: indexSelectSmallIndex: block: [0,0,0], thread: [3,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1500: indexSelectSmallIndex: block: [0,0,0], thread: [4,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1500: indexSelectSmallIndex: block: [0,0,0], thread: [5,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1500: indexSelectSmallIndex: block: [0,0,0], thread: [6,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1500: indexSelectSmallIndex: block: [0,0,0], thread: [7,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1500: indexSelectSmallIndex: block: [0,0,0], thread: [8,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1500: indexSelectSmallIndex: block: [0,0,0], thread: [9,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1500: indexSelectSmallIndex: block: [0,0,0], thread: [10,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1500: indexSelectSmallIndex: block: [0,0,0], thread: [11,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1500: indexSelectSmallIndex: block: [0,0,0], thread: [12,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1500: indexSelectSmallIndex: block: [0,0,0], thread: [13,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1500: indexSelectSmallIndex: block: [0,0,0], thread: [14,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1500: indexSelectSmallIndex: block: [0,0,0], thread: [15,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1500: indexSelectSmallIndex: block: [0,0,0], thread: [16,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1500: indexSelectSmallIndex: block: [0,0,0], thread: [17,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1500: indexSelectSmallIndex: block: [0,0,0], thread: [18,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1500: indexSelectSmallIndex: block: [0,0,0], thread: [19,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1500: indexSelectSmallIndex: block: [0,0,0], thread: [20,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1500: indexSelectSmallIndex: block: [0,0,0], thread: [21,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1500: indexSelectSmallIndex: block: [0,0,0], thread: [22,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1500: indexSelectSmallIndex: block: [0,0,0], thread: [23,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1500: indexSelectSmallIndex: block: [0,0,0], thread: [24,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1500: indexSelectSmallIndex: block: [0,0,0], thread: [25,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1500: indexSelectSmallIndex: block: [0,0,0], thread: [26,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1500: indexSelectSmallIndex: block: [0,0,0], thread: [27,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1500: indexSelectSmallIndex: block: [0,0,0], thread: [28,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1500: indexSelectSmallIndex: block: [0,0,0], thread: [29,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1500: indexSelectSmallIndex: block: [0,0,0], thread: [30,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1500: indexSelectSmallIndex: block: [0,0,0], thread: [31,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# 4. Addestra il modello\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_tree_lstm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[48], line 69\u001b[0m, in \u001b[0;36mtrain_tree_lstm\u001b[0;34m(model, train_loader, test_loader, optimizer, loss_fn, epochs, device)\u001b[0m\n\u001b[1;32m     67\u001b[0m trees, labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch)\n\u001b[1;32m     68\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 69\u001b[0m preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([model(tree) \u001b[38;5;28;01mfor\u001b[39;00m tree \u001b[38;5;129;01min\u001b[39;00m trees])\n\u001b[1;32m     70\u001b[0m labels_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(labels, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m     71\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(preds, labels_tensor)\n",
      "Cell \u001b[0;32mIn[48], line 69\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     67\u001b[0m trees, labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch)\n\u001b[1;32m     68\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 69\u001b[0m preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtree\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m tree \u001b[38;5;129;01min\u001b[39;00m trees])\n\u001b[1;32m     70\u001b[0m labels_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(labels, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m     71\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(preds, labels_tensor)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[47], line 95\u001b[0m, in \u001b[0;36mTreeLSTMClassifier.forward\u001b[0;34m(self, tree)\u001b[0m\n\u001b[1;32m     92\u001b[0m         zero \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_lstm_cell\u001b[38;5;241m.\u001b[39mhidden_dim,), device\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     93\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_lstm_cell(x, (zero, zero), (zero, zero))\n\u001b[0;32m---> 95\u001b[0m h_root, _ \u001b[38;5;241m=\u001b[39m \u001b[43mrecurse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtree\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(h_root))\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x)\u001b[38;5;241m.\u001b[39msqueeze()\n",
      "Cell \u001b[0;32mIn[47], line 84\u001b[0m, in \u001b[0;36mTreeLSTMClassifier.forward.<locals>.recurse\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m     82\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(torch\u001b[38;5;241m.\u001b[39mtensor(node\u001b[38;5;241m.\u001b[39mlabel)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameters())\u001b[38;5;241m.\u001b[39mdevice))\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m node\u001b[38;5;241m.\u001b[39mleft \u001b[38;5;129;01mand\u001b[39;00m node\u001b[38;5;241m.\u001b[39mright:\n\u001b[0;32m---> 84\u001b[0m     h_l, c_l \u001b[38;5;241m=\u001b[39m \u001b[43mrecurse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mleft\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m     h_r, c_r \u001b[38;5;241m=\u001b[39m recurse(node\u001b[38;5;241m.\u001b[39mright)\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_lstm_cell(x, (h_l, c_l), (h_r, c_r))\n",
      "Cell \u001b[0;32mIn[47], line 82\u001b[0m, in \u001b[0;36mTreeLSTMClassifier.forward.<locals>.recurse\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrecurse\u001b[39m(node: TreeNode):\n\u001b[0;32m---> 82\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m node\u001b[38;5;241m.\u001b[39mleft \u001b[38;5;129;01mand\u001b[39;00m node\u001b[38;5;241m.\u001b[39mright:\n\u001b[1;32m     84\u001b[0m         h_l, c_l \u001b[38;5;241m=\u001b[39m recurse(node\u001b[38;5;241m.\u001b[39mleft)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# 1. Prepara i dati\n",
    "train_loader, test_loader, X_train, X_test, y_train, y_test = prepare_tree_dataset(\n",
    "    parsed_formulas, truth_values, tokenizer, test_size=0.2, batch_size=32)\n",
    "\n",
    "# 2. Inizializza il modello\n",
    "model = TreeLSTMClassifier(\n",
    "    vocab_size=len(tokenizer.formula_to_token) + 10,  # aggiungi margine\n",
    "    embedding_dim=32,\n",
    "    hidden_dim=64\n",
    ")\n",
    "\n",
    "# 3. Imposta optimizer e loss\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 4. Addestra il modello\n",
    "results = train_tree_lstm(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    optimizer=optimizer,\n",
    "    loss_fn=loss_fn,\n",
    "    epochs=10,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae4c8dd-3a08-4efa-894d-dce842f1ffcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949aaadf-9b8f-4acf-af45-5ac41ab4da2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
